{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Use NN to predict disease from chemicals using Opa2Vec vectors\n",
    "<b> Author: </b> Ian Coleman <br>\n",
    "<b> Purpose: </b> Take the vectors created in the opa2vec notebook. This took chemical go functions\n",
    "    and disease go function, creating vectors for each. Train a NN to predict positive chem-dis relationships from these vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from pandas_ml import ConfusionMatrix\n",
    "import json\n",
    "import subprocess\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "#Set random seed\n",
    "np.random.seed(1606)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_usage(pandas_obj):\n",
    "    if isinstance(pandas_obj,pd.DataFrame):\n",
    "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "    else: # we assume if not a df it's a series\n",
    "        usage_b = pandas_obj.memory_usage(deep=True)\n",
    "    usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes\n",
    "    return \"{:03.2f} MB\".format(usage_mb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Vectors and Pre-Process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gofunc vec file\n",
    "with open('go-gofuncs.lst', 'r') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "# Strip and split vector data into list of lists [chem, vec]\n",
    "text = text.replace('\\n', '')\n",
    "text = text.split(']')\n",
    "text = [item.strip().split(' [') for item in text]\n",
    "\n",
    "# Turn it into a data frame\n",
    "df = pd.DataFrame(text)\n",
    "df.columns = ['ID', 'Vector']\n",
    "\n",
    "# Clean\n",
    "df = df.dropna()\n",
    "df['Vector'] = df.Vector.map(lambda x: x.rstrip().lstrip().replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n",
    "\n",
    "# Turn vector column into a list\n",
    "df['Vector'] = df.Vector.map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH:D012559</td>\n",
       "      <td>[1.76247600e-02, -1.05403718e-02, -4.61959302e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESH:D009404</td>\n",
       "      <td>[0.01795662, 0.13640046, 0.03051887, -0.100085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESH:D001749</td>\n",
       "      <td>[-8.68742093e-02, 8.83234814e-02, -2.54237115e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESH:D011471</td>\n",
       "      <td>[-0.00926186, 0.04098112, -0.4911138, -0.22025...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MESH:D008106</td>\n",
       "      <td>[-0.12722802, 0.07976454, -0.5775048, -0.28237...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                             Vector\n",
       "0  MESH:D012559  [1.76247600e-02, -1.05403718e-02, -4.61959302e...\n",
       "1  MESH:D009404  [0.01795662, 0.13640046, 0.03051887, -0.100085...\n",
       "2  MESH:D001749  [-8.68742093e-02, 8.83234814e-02, -2.54237115e...\n",
       "3  MESH:D011471  [-0.00926186, 0.04098112, -0.4911138, -0.22025...\n",
       "4  MESH:D008106  [-0.12722802, 0.07976454, -0.5775048, -0.28237..."
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create DF for NN\n",
    "Munge the df into the following columns:<br>\n",
    "ChemID DisID ChemVec DisVec PositiveAssociationExists(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C112297</td>\n",
       "      <td>MESH:D006948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C112297</td>\n",
       "      <td>MESH:D012640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C425777</td>\n",
       "      <td>MESH:D006948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C013567</td>\n",
       "      <td>MESH:D006333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C418863</td>\n",
       "      <td>MESH:D013262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ChemicalID     DiseaseID\n",
       "0    C112297  MESH:D006948\n",
       "1    C112297  MESH:D012640\n",
       "2    C425777  MESH:D006948\n",
       "3    C013567  MESH:D006333\n",
       "4    C418863  MESH:D013262"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Import file of proven chem-dis positive associations (created in ctd-to-nt notebook from ctd data)\n",
    "chem_dis = pd.read_csv('../ctd-to-nt/chem-dis-pos-assocs.csv')\n",
    "chem_dis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of any chems/diseases that don't have a vector\n",
    "chem_dis['DiseaseID'] = chem_dis['DiseaseID'].astype(str)\n",
    "df['ID'] = df['ID'].astype(str)\n",
    "id_list = df.ID.tolist() # list of chems+diseases with vecs\n",
    "\n",
    "chem_dis['hasDVec'] = chem_dis.DiseaseID.map(lambda x: x in id_list)\n",
    "chem_dis['hasCVec'] = chem_dis.ChemicalID.map(lambda x: x in id_list)\n",
    "chem_dis = chem_dis.loc[(chem_dis['hasDVec'] == True) & (chem_dis['hasCVec'] == True)]\n",
    "chem_dis = chem_dis.drop(['hasDVec','hasCVec'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all info into one df\n",
    "# this df now contains only correlated diseases and vecs\n",
    "df_d = df.copy()\n",
    "df_d.columns= ['DiseaseID', 'DVec']\n",
    "df_c = df.copy()\n",
    "df_c.columns= ['ChemicalID', 'CVec']\n",
    "df1 = pd.merge(chem_dis, df_d, on='DiseaseID')\n",
    "df1 = pd.merge(df1, df_c, on='ChemicalID')\n",
    "\n",
    "df1['Correlation'] = 1 # currently only have correlated in there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>DVec</th>\n",
       "      <th>CVec</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C028474</td>\n",
       "      <td>MESH:D006528</td>\n",
       "      <td>[-0.08689959, 0.06080057, -0.04620415, -0.1237...</td>\n",
       "      <td>[0.01018825, 0.08274926, 0.05085841, -0.117527...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C028474</td>\n",
       "      <td>MESH:D005355</td>\n",
       "      <td>[-4.32693306e-03, 1.35906458e-01, -1.91942360e...</td>\n",
       "      <td>[0.01018825, 0.08274926, 0.05085841, -0.117527...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C028474</td>\n",
       "      <td>MESH:D006529</td>\n",
       "      <td>[-0.02542116, 0.0981225, -0.01938446, -0.14929...</td>\n",
       "      <td>[0.01018825, 0.08274926, 0.05085841, -0.117527...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C028474</td>\n",
       "      <td>MESH:D006965</td>\n",
       "      <td>[-0.01135238, 0.143319, 0.04601676, -0.1474806...</td>\n",
       "      <td>[0.01018825, 0.08274926, 0.05085841, -0.117527...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C028474</td>\n",
       "      <td>MESH:D008114</td>\n",
       "      <td>[-0.10265561, 0.03210206, -0.13152453, -0.0728...</td>\n",
       "      <td>[0.01018825, 0.08274926, 0.05085841, -0.117527...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ChemicalID     DiseaseID                                               DVec  \\\n",
       "0    C028474  MESH:D006528  [-0.08689959, 0.06080057, -0.04620415, -0.1237...   \n",
       "1    C028474  MESH:D005355  [-4.32693306e-03, 1.35906458e-01, -1.91942360e...   \n",
       "2    C028474  MESH:D006529  [-0.02542116, 0.0981225, -0.01938446, -0.14929...   \n",
       "3    C028474  MESH:D006965  [-0.01135238, 0.143319, 0.04601676, -0.1474806...   \n",
       "4    C028474  MESH:D008114  [-0.10265561, 0.03210206, -0.13152453, -0.0728...   \n",
       "\n",
       "                                                CVec  Correlation  \n",
       "0  [0.01018825, 0.08274926, 0.05085841, -0.117527...            1  \n",
       "1  [0.01018825, 0.08274926, 0.05085841, -0.117527...            1  \n",
       "2  [0.01018825, 0.08274926, 0.05085841, -0.117527...            1  \n",
       "3  [0.01018825, 0.08274926, 0.05085841, -0.117527...            1  \n",
       "4  [0.01018825, 0.08274926, 0.05085841, -0.117527...            1  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3137"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8651, 2)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chem_dis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate dfs of dis-vecs and chem-vecs ( in order to generate additional rows for df1)\n",
    "dis = df.ID.map(lambda x: ('MESH' in x) | ('OMIM' in x))\n",
    "chems = df.ID.map(lambda x: ('MESH' not in x) & ('OMIM' not in x))\n",
    "\n",
    "df_chems = df[chems]\n",
    "df_dis = df[dis]\n",
    "df_chems = df_chems.reset_index(drop=True)\n",
    "df_dis = df_dis.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  8650\n",
      "(17301, 5)\n",
      "(17145, 5)\n"
     ]
    }
   ],
   "source": [
    "# Add unrelated pairs to df1\n",
    "no_rows = (df1.shape[0]-1)   # This is a parameter to be tuned --> how many uncorrelated pairs do we want\n",
    "print('shape: ', no_rows)\n",
    "\n",
    "# Randomly select chems and diseases (as many as there are related pairs)\n",
    "no_chems = len(df_chems) -1\n",
    "no_dis = len(df_dis) -1\n",
    "rand_chems = np.random.choice(no_chems, no_rows, replace=True)\n",
    "rand_dis = np.random.choice(no_dis, no_rows, replace=True)\n",
    "\n",
    "# Add the new pairs as rows\n",
    "for x in range(0, no_rows):\n",
    "    int1 = rand_chems[x]\n",
    "    int2 = rand_dis[x]\n",
    "    chem, chemvec = df_chems.loc[int1, 'ID'], df_chems.loc[int1, 'Vector']\n",
    "    dis, disvec = df_dis.loc[int2, 'ID'], df_dis.loc[int2, 'Vector']\n",
    "    df1 = df1.append({'ChemicalID':chem, 'DiseaseID':dis, 'CVec':chemvec, 'DVec':disvec, 'Correlation':0}, ignore_index=True)\n",
    "\n",
    "print(df1.shape)\n",
    "# Drop any duplicates (removes known correlated pairs accidentally generated as uncorrelated)\n",
    "df1 = df1.drop_duplicates(subset=['ChemicalID', 'DiseaseID'], keep=False)\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the elements of the vectors to actual numbers\n",
    "df1['DVec'] = df1.DVec.map(lambda x: [float(i) for i in x])\n",
    "df1['CVec'] = df1.CVec.map(lambda x: [float(i) for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Phenotype Vecs\n",
    "Got a list of Chem-Phenotypes from Sara Alth, where did these come from originally?\n",
    "They have CID identifiers (Pubchem). Need to convert CTD ID to CID ID\n",
    "Use API like so \n",
    "http://pubchem.ncbi.nlm.nih.gov/rest/pug/substance/sourceid/Comparative%20Toxicogenomics%20Database/C533207/cids/TXT/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## First we'll add DOIDs for diseases and CIDs for chemicals as an intermediate for adding phenotypes\n",
    "# # Read in CSV mapping chems to CID and dis to DOID --> This file is created by phens-opa2vec.ipynb\n",
    "# mapper = pd.read_csv('entities.lst')\n",
    "\n",
    "# # Make the maps from this\n",
    "# dis_map = dict(zip(mapper.ID, mapper.DOID))\n",
    "# chem_map = dict(zip(mapper.ID, mapper.CID))\n",
    "\n",
    "# # Apply the maps to df1\n",
    "# df1['DOID'] = df1.DiseaseID.map(lambda x: dis_map.get(x))\n",
    "# df1['CID'] = df1.ChemicalID.map(lambda x: chem_map.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in the association files from Sara\n",
    "# dis_phens = pd.read_csv('Disease-PhenotypeAssocation.txt', sep=' ', names=['DOID', 'Phenotype'])\n",
    "# chem_phens =  pd.read_csv('Drug-PhenotypeAssocation.txt', sep=' ', names=['CID', 'Phenotype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The association files have a different format for each ID system than mine, homogenise these\n",
    "# # first chem\n",
    "# def cid_standardiser (cid):\n",
    "#     # Must be format CID + 9 int chars, starting with 1 seemingly\n",
    "#     cid = int(cid)\n",
    "#     output = 'CID1' + '0' * (8 - len(str(cid))) + str(cid)\n",
    "#     return output\n",
    "\n",
    "# df1['CID'] = df1.CID.map(lambda x: np.nan if math.isnan(x) else cid_standardiser(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # and now disease \n",
    "# def doid_standardiser (doid):\n",
    "#     # Must be format DOID_ + ...\n",
    "#     # I'm unsure about how well this is working so print out the DOIDs that don't match\n",
    "#     doid = doid.replace(':', '_')\n",
    "# #     output = 'CID1' + '0' * (8 - len(str(cid))) + str(cid)\n",
    "#     return doid\n",
    "\n",
    "# df1['DOID'] = df1.DOID.map(lambda x: np.nan if isinstance(x, float) else doid_standardiser(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now that the DOIDs and CIDs are theoretically standardised we can chuck in the phens to df1\n",
    "\n",
    "# First though check which DOIDs and CIDs do not match up --> SEEMS OK\n",
    "# test_doids = df1[df1.DOID.map(lambda x: isinstance(x, str))].DOID.tolist()\n",
    "# imported_doids = dis_phens.DOID.tolist()\n",
    "# for item in test_doids:\n",
    "#     if item not in imported_doids:\n",
    "#         print(item)                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's create one associations file for each ontology (I believe we need to run HP and MP separately)\n",
    "# chem_phens.columns = ['ID', 'Phen']\n",
    "# dis_phens.columns = ['ID', 'Phen']\n",
    "\n",
    "# # Maps for Split into MP/HP\n",
    "# hp_df_crit_d = dis_phens.Phen.map(lambda x: 'obolibrary.org/obo/HP' in str(x))\n",
    "# mp_df_crit_d = dis_phens.Phen.map(lambda x: 'obolibrary.org/obo/MP' in str(x))\n",
    "# hp_df_crit_c = chem_phens.Phen.map(lambda x: 'obolibrary.org/obo/HP' in str(x))\n",
    "# mp_df_crit_c = chem_phens.Phen.map(lambda x: 'obolibrary.org/obo/MP' in str(x))\n",
    "\n",
    "# total_hp = chem_phens[hp_df_crit_c].append(dis_phens[hp_df_crit_d], ignore_index=True)\n",
    "# total_mp = chem_phens[mp_df_crit_c].append(dis_phens[mp_df_crit_d], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export the association files and print some stats (more stats later)\n",
    "# np.savetxt(r'associations_hp.txt', total_hp.values, fmt='%s')\n",
    "# np.savetxt(r'associations_mp.txt', total_mp.values, fmt='%s')\n",
    "\n",
    "# print('Num HP associations: ', total_hp.shape[0])\n",
    "# print('Num MP associations: ', total_mp.shape[0])\n",
    "# print('Num ents with MP phen assocs: ', len(total_mp.ID.unique()))\n",
    "# print('Num ents with HP phen assocs: ', len(total_hp.ID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create entities.lst to inform opa2vec which entities we want vectors for\n",
    "# entities = total_mp.ID.unique().tolist()\n",
    "# np.savetxt(r'entities_mp.lst', entities, fmt='%s')\n",
    "\n",
    "# entities = total_hp.ID.unique().tolist()\n",
    "# np.savetxt(r'entities_hp.lst', entities, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run OPA2VEC for entity-phens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HP --> takes ages so commenting out\n",
    "# subprocess.check_output('(cd ../../opa2vec/ ; python2 runOPA2Vec.py -ontology ../ontologies/hp.owl -associations ../msc-thesis/opa/associations_hp.txt -entities ../msc-thesis/opa/entities_hp.lst -outfile ../msc-thesis/opa/hpvecs.lst)', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MP --> takes ages so commenting out\n",
    "# subprocess.check_output('(cd ../../opa2vec/ ; python2 runOPA2Vec.py -ontology ../ontologies/mp.owl -associations ../msc-thesis/opa/associations_mp.txt -entities ../msc-thesis/opa/entities_mp.lst -outfile ../msc-thesis/opa/mpvecs.lst)', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now import and integrate the vecs\n",
    "# # Import vec file\n",
    "# with open('hpvecs.lst', 'r') as file:\n",
    "#     text = file.read()\n",
    "    \n",
    "# # Strip and split vector data into list of lists [chem, vec]\n",
    "# text = text.replace('\\n', '')\n",
    "# text = text.split(']')\n",
    "# text = [item.strip().split(' [') for item in text]\n",
    "\n",
    "# # Turn it into a data frame\n",
    "# hp_vecs = pd.DataFrame(text)\n",
    "# hp_vecs.columns = ['ID', 'Vector']\n",
    "\n",
    "# # Clean\n",
    "# hp_vecs = hp_vecs.dropna()\n",
    "# hp_vecs['Vector'] = hp_vecs.Vector.map(lambda x: x.rstrip().lstrip().replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n",
    "\n",
    "# # Turn vector column into a list\n",
    "# hp_vecs['Vector'] = hp_vecs.Vector.map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now import and integrate the mp vecs\n",
    "# # Import vec file\n",
    "# with open('mpvecs.lst', 'r') as file:\n",
    "#     text = file.read()\n",
    "\n",
    "# # Strip and split vector data into list of lists [chem, vec]\n",
    "# text = text.replace('\\n', '')\n",
    "# text = text.split(']')\n",
    "# text = [item.strip().split(' [') for item in text]\n",
    "\n",
    "# # Turn it into a data frame\n",
    "# mp_vecs = pd.DataFrame(text)\n",
    "# mp_vecs.columns = ['ID', 'Vector']\n",
    "\n",
    "# # Clean\n",
    "# mp_vecs = mp_vecs.dropna()\n",
    "# mp_vecs['Vector'] = mp_vecs.Vector.map(lambda x: x.rstrip().lstrip().replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n",
    "\n",
    "# # Turn vector column into a list\n",
    "# mp_vecs['Vector'] = mp_vecs.Vector.map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right, now I have hp and mp vecs, match them up into df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make Maps:\n",
    "# mp_ent_to_vec = dict(zip(mp_vecs.ID, mp_vecs.Vector))\n",
    "# hp_ent_to_vec = dict(zip(hp_vecs.ID, hp_vecs.Vector))\n",
    "\n",
    "# # Map entities to vecs (one set of vecs for mp and another for hp)\n",
    "# df1['disPhenVecMP'] = df1.DOID.map(lambda x: mp_ent_to_vec.get(x))\n",
    "# df1['disPhenVecHP'] = df1.DOID.map(lambda x: hp_ent_to_vec.get(x))\n",
    "\n",
    "# df1['chemPhenVecHP'] = df1.CID.map(lambda x: hp_ent_to_vec.get(x))\n",
    "# df1['chemPhenVecMP'] = df1.CID.map(lambda x: mp_ent_to_vec.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TODO note that I have removed rows without gofuncVecs, maybe now they should be kept\n",
    "# # Print Stats\n",
    "# print('Note these numbers include both correlated and uncorrelated pairs')\n",
    "# print('Number of rows with gofuncs: ', df1.shape[0]) ##NB change this if keeping rows w/o gofunc vecs\n",
    "# print('Number of rows with dis mp vec: ', df1[df1.disPhenVecMP.map(lambda x: x is not None)].shape[0])\n",
    "# print('Number of rows with dis hp vec: ', df1[df1.disPhenVecHP.map(lambda x: x is not None)].shape[0])\n",
    "# print('Number of rows with chem mp vec: ', df1[df1.chemPhenVecMP.map(lambda x: x is not None)].shape[0])\n",
    "# print('Number of rows with chem hp vec: ', df1[df1.chemPhenVecHP.map(lambda x: x is not None)].shape[0])\n",
    "# no_dis_phen_vecs = df1.disPhenVecHP.map(lambda x: x is None) & df1.disPhenVecMP.map(lambda x: x is None)\n",
    "# no_chem_phen_vecs = df1.chemPhenVecHP.map(lambda x: x is None) & df1.chemPhenVecMP.map(lambda x: x is None)\n",
    "# no_phen_vecs = no_dis_phen_vecs & no_chem_phen_vecs\n",
    "# print('Number of rows with no phen vecs: ', df1[no_phen_vecs].shape[0])\n",
    "# all_dis_phen_vecs = df1.disPhenVecHP.map(lambda x: x is not None) & df1.disPhenVecMP.map(lambda x: x is not None)\n",
    "# all_chem_phen_vecs = df1.chemPhenVecHP.map(lambda x: x is not None) & df1.chemPhenVecMP.map(lambda x: x is not None)\n",
    "# all_vecs = all_dis_phen_vecs & all_chem_phen_vecs\n",
    "# all_vecs_pos_corr = all_vecs & df1.Correlation.map(lambda x: x == 1)\n",
    "# all_vecs_neg_corr = all_vecs & df1.Correlation.map(lambda x: x == 0)\n",
    "\n",
    "# print('Number of rows with everything', df1[all_vecs].shape[0])\n",
    "\n",
    "# print('Number of correlated pairs with everything', df1[all_vecs_pos_corr].shape[0])\n",
    "# print('Number of uncorrelated pairs with everything', df1[all_vecs_neg_corr].shape[0])\n",
    "\n",
    "# print('total pos corr', df1[df1.Correlation.map(lambda x: x == 1)].shape[0])\n",
    "# print('total neg corr', df1[df1.Correlation.map(lambda x: x == 0)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add empty vecs for rows that don't have phen vecs\n",
    "# empty_vec = [0] * 200\n",
    "\n",
    "# for col in ['disPhenVecMP', 'disPhenVecHP', 'chemPhenVecHP', 'chemPhenVecMP']:\n",
    "#     df1[col] = df1[col].map(lambda x: empty_vec if x is None else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change the Phen vec elements from string to floats\n",
    "# df1['disPhenVecHP'] = df1.disPhenVecHP.map(lambda x: [float(i) for i in x])\n",
    "# df1['disPhenVecMP'] = df1.disPhenVecMP.map(lambda x: [float(i) for i in x])\n",
    "# df1['chemPhenVecHP'] = df1.chemPhenVecHP.map(lambda x: [float(i) for i in x])\n",
    "# df1['chemPhenVecMP'] = df1.chemPhenVecMP.map(lambda x: [float(i) for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add CHEBI Vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First add CHEBI IDs for each chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chem_names = df1.ChemicalID.unique().tolist()\n",
    "# np.savetxt(r'chem_names', total_hp.values, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add chebi first need CID for ALL Chems so I made this comprehensive map:\n",
    "# Load the map from pickle object\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "ctd_cid_map = load_obj('ctd_cid_map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['CID'] = df1.ChemicalID.map(lambda x: ctd_cid_map.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>DVec</th>\n",
       "      <th>CVec</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>CID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>C017947</td>\n",
       "      <td>MESH:D008175</td>\n",
       "      <td>[-0.0498087, 0.08013102, -0.21025404, -0.14221...</td>\n",
       "      <td>[-0.0531880707, 0.0433869548, -0.196800679, -0...</td>\n",
       "      <td>1</td>\n",
       "      <td>b'443495'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>C582340</td>\n",
       "      <td>MESH:D013617</td>\n",
       "      <td>[0.05696682, 0.09369084, -0.0048688, -0.089769...</td>\n",
       "      <td>[0.03923435, 0.10083519, 0.0233496, -0.1123369...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8458</th>\n",
       "      <td>D014673</td>\n",
       "      <td>MESH:D007022</td>\n",
       "      <td>[-0.07060508, 0.08438816, -0.0596953, -0.07784...</td>\n",
       "      <td>[0.0453479178, 0.138363615, -0.0531766899, -0....</td>\n",
       "      <td>1</td>\n",
       "      <td>b'39764'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ChemicalID     DiseaseID  \\\n",
       "1341    C017947  MESH:D008175   \n",
       "9741    C582340  MESH:D013617   \n",
       "8458    D014673  MESH:D007022   \n",
       "\n",
       "                                                   DVec  \\\n",
       "1341  [-0.0498087, 0.08013102, -0.21025404, -0.14221...   \n",
       "9741  [0.05696682, 0.09369084, -0.0048688, -0.089769...   \n",
       "8458  [-0.07060508, 0.08438816, -0.0596953, -0.07784...   \n",
       "\n",
       "                                                   CVec  Correlation  \\\n",
       "1341  [-0.0531880707, 0.0433869548, -0.196800679, -0...            1   \n",
       "9741  [0.03923435, 0.10083519, 0.0233496, -0.1123369...            0   \n",
       "8458  [0.0453479178, 0.138363615, -0.0531766899, -0....            1   \n",
       "\n",
       "            CID  \n",
       "1341  b'443495'  \n",
       "9741       None  \n",
       "8458   b'39764'  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CIDS from bytes to strings and export in order to make a map from CID to CHEBI ID\n",
    "df1['CID'] = df1.CID.str.decode(\"utf-8\")\n",
    "np.savetxt(r'allCIDs.txt', df1.CID.unique(), fmt='%s')\n",
    "\n",
    "## NOTE the next step is MANUAL you need to upload this allCIDs.txt to http://cts.fiehnlab.ucdavis.edu/batch \n",
    "# and download it as ctd_chebi.csv to the current folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV mapping CID to CHEBI\n",
    "ctdChebdf = pd.read_csv('ctd_chebi.csv')\n",
    "\n",
    "# Turn it into a dict\n",
    "ctd_chebi = dict(zip(ctdChebdf['PubChem CID'], ctdChebdf['ChEBI']))\n",
    "\n",
    "# Map the cids to chebis\n",
    "df1['CHEBI'] = df1.CID.map(lambda x: ctd_chebi.get(x))\n",
    "df1['CHEBI'] = df1.CHEBI.map(lambda x: None if x == 'No result' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now make CHEBI vecs using the CHEBI IDs\n",
    "# First an association file - just linking each chebi to its own chebi entity\n",
    "\n",
    "# add uri col\n",
    "df1['CHEBI_uri'] = df1.dropna(subset=['CHEBI']).CHEBI.map(lambda x: '<http://purl.obolibrary.org/obo/' + x.replace(':', '_') + '>')\n",
    "\n",
    "# export association file from df\n",
    "np.savetxt(r'CHEBIassociations.txt', df1[['ChemicalID', 'CHEBI_uri']].dropna().drop_duplicates().values, fmt='%s')\n",
    "\n",
    "# Now an entities file\n",
    "chems_for_cheb = df1[['ChemicalID', 'CHEBI_uri']].dropna().drop_duplicates().ChemicalID.tolist()\n",
    "np.savetxt(r'CHEBIentities.txt', chems_for_cheb, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commenting this out now that I already have the vectors, you'll need it if you don't have them\n",
    "# # Now run opa2vec on it \n",
    "# subprocess.check_output('(cd ../../opa2vec/ ; python2 runOPA2Vec.py -ontology ../ontologies/chebi.owl -associations ../msc-thesis/opa/CHEBIassociations.txt -entities ../msc-thesis/opa/CHEBIentities.txt -outfile ../msc-thesis/opa/chebi-vecs.lst)', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gofunc vec file\n",
    "with open('chebi-vecs.lst', 'r') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "# Strip and split vector data into list of lists [chem, vec]\n",
    "text = text.replace('\\n', '')\n",
    "text = text.split(']')\n",
    "text = [item.strip().split(' [') for item in text]\n",
    "\n",
    "# Turn it into a data frame\n",
    "df = pd.DataFrame(text)\n",
    "df.columns = ['ID', 'Vector']\n",
    "\n",
    "# Clean\n",
    "df = df.dropna()\n",
    "df['Vector'] = df.Vector.map(lambda x: x.rstrip().lstrip().replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n",
    "\n",
    "# Turn vector column into a list\n",
    "df['Vector'] = df.Vector.map(lambda x: x.split(','))\n",
    "\n",
    "# Make a map of it (ChemID to CHEBIvec)\n",
    "chem_to_chebi_vec = dict(zip(df.ID, df.Vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a map of it (ChemID to CHEBIvec)\n",
    "chem_to_chebi_vec = dict(zip(df.ID, df.Vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['CHEBIvec'] = df1.ChemicalID.map(lambda x: chem_to_chebi_vec.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows 17145\n",
      "Total Correlated Rows 8595\n",
      "Total CHEBI vec rows 10660\n",
      "Total CHEBI vec correlated rows 5894\n",
      "Total Chems 570\n",
      "Total Chems with CHEBI Vec 316\n"
     ]
    }
   ],
   "source": [
    "# How many rows have CHEBI Vecs?\n",
    "print('Total Rows', df1.shape[0])\n",
    "print('Total Correlated Rows', df1[df1.Correlation == 1].shape[0])\n",
    "print('Total CHEBI vec rows', df1.dropna(subset=['CHEBIvec']).shape[0])\n",
    "print('Total CHEBI vec correlated rows', df1[df1.Correlation == 1].dropna(subset=['CHEBIvec']).shape[0])\n",
    "print('Total Chems', len(df1.ChemicalID.unique()))\n",
    "print('Total Chems with CHEBI Vec', len(df1.dropna(subset=['CHEBIvec']).ChemicalID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>DVec</th>\n",
       "      <th>CVec</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>CID</th>\n",
       "      <th>CHEBI</th>\n",
       "      <th>CHEBI_uri</th>\n",
       "      <th>CHEBIvec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7769</th>\n",
       "      <td>D011794</td>\n",
       "      <td>MESH:D009133</td>\n",
       "      <td>[0.03116769, 0.13587785, 0.04433348, -0.132408...</td>\n",
       "      <td>[-0.02145532, 0.06948259, -0.1081144, -0.14960...</td>\n",
       "      <td>1</td>\n",
       "      <td>5280343</td>\n",
       "      <td>CHEBI:16243</td>\n",
       "      <td>&lt;http://purl.obolibrary.org/obo/CHEBI_16243&gt;</td>\n",
       "      <td>[0.01221674, 0.05984232, 0.03748447, -0.071131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13468</th>\n",
       "      <td>C012655</td>\n",
       "      <td>MESH:D012608</td>\n",
       "      <td>[0.01731185, 0.11330543, 0.07036374, -0.148131...</td>\n",
       "      <td>[0.00528433267, 0.0889950693, 0.0519304797, -0...</td>\n",
       "      <td>0</td>\n",
       "      <td>4495</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15111</th>\n",
       "      <td>C509592</td>\n",
       "      <td>MESH:C535780</td>\n",
       "      <td>[0.01960866, 0.12501125, 0.04490718, -0.128422...</td>\n",
       "      <td>[0.00356502, 0.11017938, -0.02927761, -0.08686...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ChemicalID     DiseaseID  \\\n",
       "7769     D011794  MESH:D009133   \n",
       "13468    C012655  MESH:D012608   \n",
       "15111    C509592  MESH:C535780   \n",
       "\n",
       "                                                    DVec  \\\n",
       "7769   [0.03116769, 0.13587785, 0.04433348, -0.132408...   \n",
       "13468  [0.01731185, 0.11330543, 0.07036374, -0.148131...   \n",
       "15111  [0.01960866, 0.12501125, 0.04490718, -0.128422...   \n",
       "\n",
       "                                                    CVec  Correlation  \\\n",
       "7769   [-0.02145532, 0.06948259, -0.1081144, -0.14960...            1   \n",
       "13468  [0.00528433267, 0.0889950693, 0.0519304797, -0...            0   \n",
       "15111  [0.00356502, 0.11017938, -0.02927761, -0.08686...            0   \n",
       "\n",
       "           CID        CHEBI                                     CHEBI_uri  \\\n",
       "7769   5280343  CHEBI:16243  <http://purl.obolibrary.org/obo/CHEBI_16243>   \n",
       "13468     4495         None                                           NaN   \n",
       "15111     None         None                                           NaN   \n",
       "\n",
       "                                                CHEBIvec  \n",
       "7769   [0.01221674, 0.05984232, 0.03748447, -0.071131...  \n",
       "13468                                               None  \n",
       "15111                                               None  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add empty vecs for rows that don't have Chebi vecs\n",
    "empty_vec = [0] * 200\n",
    "df1['CHEBIvec'] = df1['CHEBIvec'].map(lambda x: empty_vec if x is None else x)\n",
    "\n",
    "# Change the Chebi vec elements from string to floats\n",
    "df1['CHEBIvec'] = df1.CHEBIvec.map(lambda x: [float(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess\n",
    "Now that we have the df ready, let's split it into train/test/validation sets and convert it into numpy arrays so it can be consumed by a Keras NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8595\n",
      "(17145, 9)\n"
     ]
    }
   ],
   "source": [
    "print(df1[df1.Correlation == 1].shape[0])\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>DVec</th>\n",
       "      <th>CVec</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>CID</th>\n",
       "      <th>CHEBI</th>\n",
       "      <th>CHEBI_uri</th>\n",
       "      <th>CHEBIvec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8456</th>\n",
       "      <td>D014673</td>\n",
       "      <td>MESH:D009336</td>\n",
       "      <td>[-0.0526574999, 0.0888598338, -0.0274056457, -...</td>\n",
       "      <td>[0.0453479178, 0.138363615, -0.0531766899, -0....</td>\n",
       "      <td>1</td>\n",
       "      <td>39764</td>\n",
       "      <td>CHEBI:9940</td>\n",
       "      <td>&lt;http://purl.obolibrary.org/obo/CHEBI_9940&gt;</td>\n",
       "      <td>[0.021671124, 0.054821689, 0.015866555, -0.062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9347</th>\n",
       "      <td>D014800</td>\n",
       "      <td>MESH:D006106</td>\n",
       "      <td>[-0.00255577127, 0.137570068, 0.0328803249, -0...</td>\n",
       "      <td>[-0.032665316, 0.00784736034, -0.240696847, -0...</td>\n",
       "      <td>0</td>\n",
       "      <td>73357729</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ChemicalID     DiseaseID  \\\n",
       "8456    D014673  MESH:D009336   \n",
       "9347    D014800  MESH:D006106   \n",
       "\n",
       "                                                   DVec  \\\n",
       "8456  [-0.0526574999, 0.0888598338, -0.0274056457, -...   \n",
       "9347  [-0.00255577127, 0.137570068, 0.0328803249, -0...   \n",
       "\n",
       "                                                   CVec  Correlation  \\\n",
       "8456  [0.0453479178, 0.138363615, -0.0531766899, -0....            1   \n",
       "9347  [-0.032665316, 0.00784736034, -0.240696847, -0...            0   \n",
       "\n",
       "           CID       CHEBI                                    CHEBI_uri  \\\n",
       "8456     39764  CHEBI:9940  <http://purl.obolibrary.org/obo/CHEBI_9940>   \n",
       "9347  73357729        None                                          NaN   \n",
       "\n",
       "                                               CHEBIvec  \n",
       "8456  [0.021671124, 0.054821689, 0.015866555, -0.062...  \n",
       "9347  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Version for phen and gofunc vecs\n",
    "# # For Keras, need to turn inputs into numpy arrays instead of pandas df\n",
    "# # First create single np array of all vecs... not pretty:\n",
    "# Dvecs = pd.DataFrame(df1.DVec.values.tolist(), index= df1.index)\n",
    "# Cvecs = pd.DataFrame(df1.CVec.values.tolist(), index= df1.index)\n",
    "# gofuncs = Dvecs.merge(Cvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# DMPvecs = pd.DataFrame(df1.disPhenVecHP.values.tolist(), index= df1.index)\n",
    "# DHPvecs = pd.DataFrame(df1.disPhenVecMP.values.tolist(), index= df1.index)\n",
    "# disPvecs = DMPvecs.merge(DHPvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# CMPvecs = pd.DataFrame(df1.chemPhenVecHP.values.tolist(), index= df1.index)\n",
    "# CHPvecs = pd.DataFrame(df1.chemPhenVecMP.values.tolist(), index= df1.index)\n",
    "# chemPvecs = CMPvecs.merge(CHPvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# phenVecs = disPvecs.merge(chemPvecs, how='outer', left_index=True, right_index=True)\n",
    "# all_X = phenVecs.merge(gofuncs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# all_X = np.array(all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version for just gofunc vecs\n",
    "# For Keras, need to turn inputs into numpy arrays instead of pandas df\n",
    "# First create single np array of all vecs... not pretty:\n",
    "Dvecs = pd.DataFrame(df1.DVec.values.tolist(), index= df1.index)\n",
    "Cvecs = pd.DataFrame(df1.CVec.values.tolist(), index= df1.index)\n",
    "all_X = Dvecs.merge(Cvecs, how='outer', left_index=True, right_index=True)\n",
    "all_X = np.array(all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Version for Chebi vecs with gofuncs\n",
    "# # For Keras, need to turn inputs into numpy arrays instead of pandas df\n",
    "# # First create single np array of all vecs... not pretty:\n",
    "# Dvecs = pd.DataFrame(df1.DVec.values.tolist(), index= df1.index)\n",
    "# Cvecs = pd.DataFrame(df1.CVec.values.tolist(), index= df1.index)\n",
    "# CHEBvecs = pd.DataFrame(df1.CHEBIvec.values.tolist(), index = df1.index)\n",
    "# gofuncs = Dvecs.merge(Cvecs, how='outer', left_index=True, right_index=True)\n",
    "# all_X = gofuncs.merge(CHEBvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# all_X = np.array(all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ## Version for just CHEBI vecs\n",
    "# # For Keras, need to turn inputs into numpy arrays instead of pandas df\n",
    "# # First create single np array of all vecs... not pretty:\n",
    "# CHEBvecs = pd.DataFrame(df1.CHEBIvec.values.tolist(), index = df1.index)\n",
    "# all_X = np.array(CHEBvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create np array of the y output\n",
    "all_y = np.array(df1.Correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  (17145,)\n",
      "X shape:  (17145, 400)\n"
     ]
    }
   ],
   "source": [
    "print('y shape: ', all_y.shape)\n",
    "print('X shape: ', all_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create training, test, val set in a way that we can later look at the rows of each BY ROWS\n",
    "# total_rows = len(all_X)\n",
    "# row_numbers = list(range(0, total_rows))\n",
    "\n",
    "# training_rows = random.sample(row_numbers, int(round(total_rows * .6)))\n",
    "# row_numbers = set(row_numbers) - set(training_rows)\n",
    "\n",
    "# test_rows = random.sample(row_numbers, int(round(total_rows * .2)))\n",
    "# row_numbers = set(row_numbers) - set(test_rows)\n",
    "\n",
    "# val_rows = list(row_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chemicals:  570\n",
      "number of dis:  2501\n",
      "342 114 114\n"
     ]
    }
   ],
   "source": [
    "# Split into train, test, val BY CHEMICAL instead of by random rows\n",
    "print('number of chemicals: ', len(df1.ChemicalID.unique()))\n",
    "print('number of dis: ', len(df1.DiseaseID.unique()))\n",
    "chems = list(df1.ChemicalID.unique())\n",
    "random.shuffle(chems)\n",
    "\n",
    "total_chems = len(chems)\n",
    "train_chems = chems[:round(total_chems * .6)]\n",
    "test_chems = chems[round(total_chems * .6):round(total_chems * .8)]\n",
    "val_chems = chems[round(total_chems * .8):]\n",
    "\n",
    "print(len(train_chems), len(test_chems), len(val_chems))\n",
    "\n",
    "# Now get the row numbers for each set of chemicals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['train'] = df1.ChemicalID.isin(train_chems)\n",
    "df1['test'] = df1.ChemicalID.isin(test_chems)\n",
    "df1['val'] = df1.ChemicalID.isin(val_chems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chemicals:  570\n",
      "number of dis:  2501\n"
     ]
    }
   ],
   "source": [
    "# Split by CHEMICAL instead of by random rows\n",
    "print('number of chemicals: ', len(df1.ChemicalID.unique()))\n",
    "print('number of dis: ', len(df1.DiseaseID.unique()))\n",
    "chems = list(df1.ChemicalID.unique())\n",
    "df1 = df1.reset_index()\n",
    "training_rows = df1.index[df1.train == True].tolist()\n",
    "test_rows = df1.index[df1.test == True].tolist()\n",
    "val_rows = df1.index[df1.val == True].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10326 3566 3253\n"
     ]
    }
   ],
   "source": [
    "# Split into train, test, val\n",
    "X_train, X_test, X_val = all_X[training_rows], all_X[test_rows], all_X[val_rows]\n",
    "y_train, y_test, y_val = all_y[training_rows], all_y[test_rows], all_y[val_rows]\n",
    "\n",
    "print(len(training_rows), len(test_rows), len(val_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split into train, test, val --> OLD WAY\n",
    "# X_train, X_test, y_train, y_test = train_test_split(all_X, all_y, test_size=0.2, random_state=1606)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1606)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Establish NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Establish the model architecture\n",
    "#it's safe to say that I don't know what I'm doing here\n",
    "model = keras.Sequential([\n",
    "#     keras.layers.Dense(400, activation=tf.nn.relu), \n",
    "    keras.layers.Dense(200, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compile the model (give it loss func, optimise func and eval metric)\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), # determines how the model is adapted based on loss func\n",
    "              loss='binary_crossentropy', # measure of accuracy during training\n",
    "              metrics=['accuracy']) # measure for train and testing steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-training, set up training params\n",
    "earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10326 samples, validate on 3253 samples\n",
      "Epoch 1/10\n",
      "10326/10326 [==============================] - 1s 131us/step - loss: 0.5597 - acc: 0.7240 - val_loss: 0.5435 - val_acc: 0.7433\n",
      "Epoch 2/10\n",
      "10326/10326 [==============================] - 1s 107us/step - loss: 0.5311 - acc: 0.7451 - val_loss: 0.5424 - val_acc: 0.7396\n",
      "Epoch 3/10\n",
      "10326/10326 [==============================] - 1s 112us/step - loss: 0.5156 - acc: 0.7546 - val_loss: 0.5291 - val_acc: 0.7525\n",
      "Epoch 4/10\n",
      "10326/10326 [==============================] - 1s 135us/step - loss: 0.5092 - acc: 0.7549 - val_loss: 0.5479 - val_acc: 0.7464\n",
      "Epoch 5/10\n",
      "10326/10326 [==============================] - 1s 124us/step - loss: 0.4992 - acc: 0.7662 - val_loss: 0.5289 - val_acc: 0.7513\n",
      "Epoch 6/10\n",
      "10326/10326 [==============================] - 1s 141us/step - loss: 0.4888 - acc: 0.7682 - val_loss: 0.5382 - val_acc: 0.7378\n",
      "Epoch 7/10\n",
      "10326/10326 [==============================] - 3s 266us/step - loss: 0.4831 - acc: 0.7702 - val_loss: 0.5353 - val_acc: 0.7433\n",
      "Epoch 8/10\n",
      "10326/10326 [==============================] - 1s 130us/step - loss: 0.4795 - acc: 0.7760 - val_loss: 0.5260 - val_acc: 0.7516\n",
      "Epoch 9/10\n",
      "10326/10326 [==============================] - 1s 117us/step - loss: 0.4709 - acc: 0.7823 - val_loss: 0.5434 - val_acc: 0.7424\n",
      "Epoch 10/10\n",
      "10326/10326 [==============================] - 1s 132us/step - loss: 0.4609 - acc: 0.7856 - val_loss: 0.5425 - val_acc: 0.7452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5901d7aeb8>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Train\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val) ) #, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3566/3566 [==============================] - 0s 58us/step\n",
      "Test accuracy: 0.7661245091537779\n"
     ]
    }
   ],
   "source": [
    "# 4. Evaluate\n",
    "# Accuracy\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get actual predictions for test set\n",
    "predictions = model.predict(X_test)\n",
    "rounded_predictions = [int(float(round(x[0]))) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "Predicted  False  True  __all__\n",
      "Actual                         \n",
      "False       1484   267     1751\n",
      "True         567  1248     1815\n",
      "__all__     2051  1515     3566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f58c515c9b0>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAHiCAYAAACne8W1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmUZVV99vHvwwwvCiiKCkRQwSG+yiSDmgRFETCKcSYOQEhYJmoc45xAHFYcX+MQh1ZUnDGOqERE1DiigiLO0oJIC4oIojLI9Hv/OKf0UlQX1d117i7qfD9r3dX37rPvOft2rdv162fvu2+qCkmSpGlYr/UAJEnSeFh4SJKkqbHwkCRJU2PhIUmSpsbCQ5IkTY2FhyRJmhoLD0mSNDUWHpIkaWosPCRJ0tRs0HoAkiSNVZKhtg8/saoOGOjc68TEQ6OW5E1J/rX1OIaSZJskX0jyuySvWofzPC/JWxdzbK0keUyST7cehzSwrVsPYHXid7VoOUvyU2Ab4BrgKuArwBOq6tyW45qWvqjaFXhYLfM3e5IdgLOBDavq6rajkRYmSSVZ9PNW1WlVtcein3gRmHhoDB5UVZsDtwZ+Cbxu6AsmWSrTmLcFvr/ci46FWkI/F2m0LDw0GlV1BfBB4C4zbUnekeTF/f19k6xK8owkFyQ5P8nhE30fmORbSX6b5NwkR08c26H/n8sRSX4GfDbJJ5M8eXIMSc5I8pC5xpfk3km+kuQ3/fkP69u3SPLOJL9Kck6SFyRZrz92WJIvJXllkouTnJ3kwJnXBhwKPCvJ75Pcb/L1Tr7micfPTvLzfmrmR0n269uPTvLuiX4PTvK9fqyfT3LniWM/TfLM/rVekuS4JJus5jUfluTLSV7dn+usJPfs28/tfw6HLuRnAHyh//M3/evdZ9b5LwKOnvk76893zyQXJtm+f3z3fhx3mmu80hCSLPptKbPw0Ggk2Qx4FHDKPN1uBWwBbAscAfxXkq36Y5cCjwe2BB4I/OMcRcRfAXcGHgAcCzx24vp37897whxj+zPgf+jSmFsAuwCn94df14/pdv35Hw8cPvH0vYAf0c3pvhw4Jkmq6jDgPcDLq2rzqvrMPK+bJHcEngTco6pu0r+Gn87Rb2fgfcBT+7GeAHw8yUYT3R4JHADsCNwNOGyeS+8FnAHcHHgv8H7gHsAd6P7+Xp9k877vfD+Dv+z/3LJ/vV+dOP9ZwC2Bl0xeuKq+ArwZODbJpsC7gBdU1Q/nGa+kdWDhoTH4aJLfAL8F7g+8Yp6+VwEvrKqrquoE4PfAHQGq6vNV9Z2quraqzqD75ftXs55/dFVdWlWXAx8DdkqyU3/sccBxVXXlHNd9DPCZqnpff+1fV9XpSdanK5aeW1W/q6qfAq/qzzXjnKp6S1VdQ1fs3JpuXcuaugbYGLhLkg2r6qdV9ZM5+j0K+GRVnVRVVwGvBDYF7jnR57VVdV5VXQR8nK6QWp2zq+rt/fiPA7an+xn8oao+DVxJV4Qs9Gcw23lV9bqqurr/ucx2NF1h93XgPOC/buB80qIy8ZCWn4dU1ZZ0v1SfBPxvklutpu+vZy1MvAzYHCDJXkk+l27K4xLgCVx/5fgfF61W1R+ADwCP7adGDqH7H/Vctgfm+iW/NbARcM5E2zl0ycmMX0xc87L+7uasoapaSZdiHA1ckOT9SW4zR9fbTI6nqq6le91zjomJv8PV+OXE/cv7c85uW5OfwWzzLiTui6d3AHcFXuV6GE2bhYe0TFXVNVX1Ybr/2d97LU7xXuB4YPuq2gJ4EzD7HT77l9axdGnGfsBlE/H/bOcCt5+j/UK6FOa2E21/Bvx8zYb+R5cCm008vk4BVlXvrap799cr4GVznOO8yfGk+1du+3UY05qY72ewuoJh3kIiybbAUcDbgVcl2XiRxippDhYeGo10Dga2An6wFqe4CXBRVV2RZE/gb2/oCX2hcS3d9Mjq0g7o1mLcL8kjk2yQ5OZJdumnHz4AvCTJTZLcFng68O55zjWf04GDktysT32eOnMgyR2T3Lf/xXsFXdJwzRzn+ADwwCT7JdkQeAbwB7qPKg9tvp/Br+j+rm+30JP1RdM7gGPo1vScD7xo0UYr3YAh0g4TD6m9jyf5Pd0aj5cAh1bV99biPP8EvDDJ74B/o/sFvBDvBP4v8xQLVfUz4CC6X+IX0RUId+8PP5kuqTgL+BLd//rfthbjh674+TbdotFP062pmLEx8FK6lOUXdIsxnzfHWH9Et+jzdX3fB9F9ZHmutSuLbbU/g36a6SXAl9N9MmXvBZzvn+nWw/xrP8VyOHB4kr9Y/KFLAjcQkwaX5PHAkf0UhiT90XrrrVcbbrjhop/3yiuvXLIbiLmZjjSgdB/h/SfgDa3HImlpWupTI4vNqRZpIEkeQLfu4Jd00yOSNHomHtJAqupE4P+0Hoekpc3EQ5IkaSDLNvFI4qpZaR6777576yFIS9ppp512YVXdYujrjC3xWLaFh6T5nXrqqa2HIC1pSc654V7rfI3RFR5OtUiSpKkx8ZAkqSETD0mSpIGYeEiS1JCJhyRJ0kBMPCRJamhsiYeFhyRJDY2t8HCqRZIkTY2JhyRJjbiBmCRJWvaSvC3JBUm+O8exZyapJFv3j5PktUlWJjkjyW4TfQ9NcmZ/O3Qh17bwkCSpoZnUYzFvC/AO4IA5xrI9cH/gZxPNBwI79bcjgTf2fW8GHAXsBewJHJVkqxu6sIWHJEkNtSg8quoLwEVzHHo18Cxg8otWDwbeWZ1TgC2T3Bp4AHBSVV1UVRcDJzFHMTObazwkSVp+tk4y+U2QK6pqxXxPSPJg4OdV9e1Zxcu2wLkTj1f1batrn5eFhyRJDQ20uPTCqtpjDcawGfB8YP+5Ds/RVvO0z8upFkmSdHtgR+DbSX4KbAd8M8mt6JKM7Sf6bgecN0/7vCw8JElqqNHi0uuoqu9U1S2raoeq2oGuqNitqn4BHA88vv90y97AJVV1PnAisH+SrfpFpfv3bfNyqkWSpEZa7eOR5H3AvnRrQVYBR1XVMavpfgJwELASuAw4HKCqLkryIuAbfb8XVtVcC1ave+2qG5yOuVFKsjxfmLRIlut7X1osSU5bk3USa2PDDTesLbfcctHPe+GFFw4+9rVl4iFJUkPuXCpJkjQQEw9Jkhoy8ZAkSRqIiYckSQ2NLfGw8JAkqaGxFR5OtUiSpKkx8ZAkqZFWG4i1ZOIhSZKmxsRDkqSGxpZ4WHhIktTQ2AoPp1okSdLUmHhIktSQiYckSdJATDwkSWpobImHhYckSY24j4ckSdKATDwkSWrIxEOSJGkgJh6SJDU0tsTDwkOSpIbGVng41SJJkqbGxEOSpIZMPCRJkgZi4iFJUiNuICZJkjQgEw9JkhoaW+Jh4SFJUkNjKzycapEkSVNj4iFJUkMmHpIkSQMx8ZAkqaGxJR4WHpIkNeI+HpIkSQMy8ZAkqSETD0mSpIGYeEiS1NDYEg8LD0mSGhpb4eFUiyRJmhoTD0mSGjLxkCRJGoiJhyRJjbiBmCRJ0oBMPCRJamhsiYeFhyRJDY2t8HCqRZIkTY2JhyRJDZl4SJIkDcTEQ5KkhsaWeFh4SJLUiPt4SJIkDcjEQ5Kkhkw8JEmSBmLiIUlSQ2NLPCw8JElqaGyFh1MtkiRpakw8JElqyMRDkiRpICYekiQ14gZikiRJAzLxkCSpobElHhYekiQ1NLbCw6kWSZJGJsnbklyQ5LsTba9I8sMkZyT5SJItJ449N8nKJD9K8oCJ9gP6tpVJnrOQa1t4SJLU0MwC08W8LcA7gANmtZ0E3LWq7gb8GHhuP767AI8G/rx/zhuSrJ9kfeC/gAOBuwCH9H3nZeEhSdLIVNUXgItmtX26qq7uH54CbNffPxh4f1X9oarOBlYCe/a3lVV1VlVdCby/7zsv13hIktTQQGs8tk5y6sTjFVW1Yg2e/3fAcf39bekKkRmr+jaAc2e173VDJ7bwkCSpkQH38biwqvZYmycmeT5wNfCemaY5uhVzz5rUDZ3fwkOSJAGQ5FDgr4H9qmqmiFgFbD/RbTvgvP7+6tpXyzUekiQ11Ghx6VzjOAB4NvDgqrps4tDxwKOTbJxkR2An4OvAN4CdkuyYZCO6BajH39B1TDwkSRqZJO8D9qVbC7IKOIruUywbAyf1xcspVfWEqvpekg8A36ebgnliVV3Tn+dJwInA+sDbqup7N3RtCw9JkhpqsYFYVR0yR/Mx8/R/CfCSOdpPAE5Yk2tbeEiS1JA7l0qSJA3ExEOSpIZMPCRJkgZi4iFJUiMDbiC2ZJl4SJKkqTHxkCSpobElHoMVHkmuAb4z0fSQqvrpavruAHyiqu461HgkSVqKLDwWz+VVtcuA55ckSTcyU13jkWSHJF9M8s3+ds85+vx5kq8nOT3JGUl26tsfO9H+5iTrT3PskiQNYal8V8u0DFl4bNoXCacn+UjfdgFw/6raDXgU8No5nvcE4DV9WrIHsCrJnfv+9+rbrwEeM/uJSY5McmqSU4d4QZIkad1Me6plQ+D1SWaKh53neN5Xgecn2Q74cFWdmWQ/YHfgG30ltyldEXMdVbUCWAGQpGYflyRpqVnqCcVim/anWp4G/BK4O13acsXsDlX13iRfAx4InJjk74EAx1bVc6c5WEmShnRjmBpZbNPex2ML4PyquhZ4HN3X6F5HktsBZ1XVa4HjgbsBJwMPT3LLvs/Nktx2esOWJEmLYdqJxxuADyV5BPA54NI5+jwKeGySq4BfAC+sqouSvAD4dJL1gKuAJwLnTGnckiQNYmyJR6qW51II13hI81uu731psSQ5rar2GPIaW2yxRe2zzz6Lft4TTzxx8LGvLXculSSpobElHhYekiQ1NLbCwy+JkyRJU2PiIUlSQyYekiRJAzHxkCSpETcQkyRJGpCJhyRJDY0t8bDwkCSpobEVHk61SJKkqTHxkCSpIRMPSZKkgZh4SJLU0NgSDwsPSZIacR8PSZKkAZl4SJLUkImHJEnSQEw8JElqaGyJh4WHJEkNja3wcKpFkiRNjYmHJEmN+HFaSZKkAZl4SJLUkImHJEnSQEw8JElqaGyJh4WHJEkNja3wcKpFkiRNjYmHJEkNmXhIkiQNxMRDkqRGxriBmIWHJEkNja3wcKpFkiRNjYmHJEkNmXhIkiQNxMRDkqSGxpZ4WHhIktTQ2AoPp1okSdLUmHhIktTIGPfxMPGQJElTY+IhSVJDJh6SJEkDMfGQJKmhsSUeFh6SJDU0tsLDqRZJkjQ1Jh6SJDVk4iFJkjQQEw9JkhpxAzFJkjRVM8XHYt4WcM23JbkgyXcn2m6W5KQkZ/Z/btW3J8lrk6xMckaS3Saec2jf/8wkhy7k9Vp4SJI0Pu8ADpjV9hzg5KraCTi5fwxwILBTfzsSeCN0hQpwFLAXsCdw1EyxMh8LD0mSGmqReFTVF4CLZjUfDBzb3z8WeMhE+zurcwqwZZJbAw8ATqqqi6rqYuAkrl/MXI9rPCRJWn62TnLqxOMVVbXiBp6zTVWdD1BV5ye5Zd++LXDuRL9Vfdvq2udl4SFJUkMDLS69sKr2WKRzzTXAmqd9Xk61SJLUUIupltX4ZT+FQv/nBX37KmD7iX7bAefN0z4vCw9JkgRwPDDzyZRDgY9NtD++/3TL3sAl/ZTMicD+SbbqF5Xu37fNy6kWSZIaabWPR5L3AfvSrQVZRffplJcCH0hyBPAz4BF99xOAg4CVwGXA4QBVdVGSFwHf6Pu9sKpmL1i9HgsPSZJGpqoOWc2h/eboW8ATV3OetwFvW5NrW3hIktSQO5dKkiQNxMRDkqSGxpZ4WHhIktTQ2AoPp1okSdLUmHhIktSQiYckSdJATDwkSWqk1QZiLVl4SJLU0NgKD6daJEnS1Jh4SJLUkImHJEnSQEw8JElqaGyJh4WHJEkNja3wcKpFkiRNjYmHJEmNjHEfDxMPSZI0NSYekiQ1NLbEw8JDkqSGxlZ4ONUiSZKmxsRDkqSGTDwkSZIGYuIhSVJDJh6SJEkDMfGQJKmRMW4gZuEhSVJDFh69JB8HanXHq+rBg4xIkiQtW/MlHq+c2igkSRopE49eVf3vNAciSZKWvxtc45FkJ+A/gLsAm8y0V9XtBhyXJEmjYOJxfW8HjgJeDdwHOBwY19+SJEkDGVvhsZB9PDatqpOBVNU5VXU0cN9hhyVJkpajhSQeVyRZDzgzyZOAnwO3HHZYkiQtf2Pcx2MhicdTgc2AfwZ2Bx4HHDrkoCRJ0vJ0g4lHVX2jv/t7uvUdkiRpkYwt8VjIp1o+xxwbiVWV6zwkSVpHFh7X98yJ+5sADwOuHmY4kiRpOVvIVMtps5q+nMTNxSRJWgQmHrMkudnEw/XoFpjearARLZKdd96ZFStWtB6GtGTtuuuurYcgaYQWMtVyGt0aj9BNsZwNHDHkoCRJGgsTj+u7c1VdMdmQZOOBxiNJkpaxhezj8ZU52r662AORJGlsZjYQW+zbUrbaxCPJrYBtgU2T7Mqfvp/lpnQbikmSpHW01AuFxTbfVMsDgMOA7YBX8afC47fA84YdliRJWo5WW3hU1bHAsUkeVlUfmuKYJEkajbElHgtZ47F7ki1nHiTZKsmLBxyTJElaphZSeBxYVb+ZeVBVFwMHDTckSZLGw8Wl17d+ko2r6g8ASTYF/DitJEmLYKkXCottIYXHu4GTk7y9f3w4cOxwQ5IkScvVQr6r5eVJzgDuR/fJlk8Btx16YJIkLXc3hqmRxbaQNR4AvwCupftm2v2AHww2IkmStGzNt4HYzsCjgUOAXwPHAamq+0xpbJIkLXtjSzzmm2r5IfBF4EFVtRIgydOmMipJkkZibIXHfFMtD6ObYvlckrck2Y8/7V4qSZK0xlZbeFTVR6rqUcCdgM8DTwO2SfLGJPtPaXySJC1rY9vH4wYXl1bVpVX1nqr6a7rvbTkdeM7gI5MkScvOQvbx+KOqugh4c3+TJEnraKknFIttoR+nlSRJWmdrlHhIkqTFc2NYk7HYLDwkSWpobIWHUy2SJGlqTDwkSWrIxEOSJC17SZ6W5HtJvpvkfUk2SbJjkq8lOTPJcUk26vtu3D9e2R/fYW2va+EhSVJDLTYQS7It8M/AHlV1V2B9uu9nexnw6qraCbgYOKJ/yhHAxVV1B+DVfb+1YuEhSVJDDXcu3QDYNMkGwGbA+cB9gQ/2x48FHtLfP7h/TH98v6zlHJGFhyRJy8/WSU6duB05ebCqfg68EvgZXcFxCXAa8JuqurrvtgrYtr+/LXBu/9yr+/43X5uBubhUkqRGBtzH48Kq2mOe625Fl2LsCPwG+G/gwDm61sxT5jm2Rkw8JEkan/sBZ1fVr6rqKuDDwD2BLfupF+i+n+28/v4qYHuA/vgWwEVrc2ELD0mSGmq0xuNnwN5JNuvXauwHfB/4HPDwvs+hwMf6+8f3j+mPf7aq1irxcKpFkqSGWuzjUVVfS/JB4JvA1cC3gBXAJ4H3J3lx33ZM/5RjgHclWUmXdDx6ba9t4SFJ0ghV1VHAUbOazwL2nKPvFcAjFuO6Fh6SJDXkzqWSJEkDMfGQJKkhEw9JkqSBmHhIktTIgBuILVkWHpIkNTS2wsOpFkmSNDUmHpIkNWTiIUmSNBATD0mSGhpb4mHhIUlSQ2MrPJxqkSRJU2PiIUlSI2Pcx8PEQ5IkTY2JhyRJDY0t8bDwkCSpobEVHk61SJKkqTHxkCSpIRMPSZKkgZh4SJLUkImHJEnSQEw8JElqZIwbiFl4SJLU0NgKD6daJEnS1Jh4SJLUkImHJEnSQEw8JElqaGyJh4WHJEmNjPFTLU61SJKkqTHxkCSpIRMPSZKkgZh4SJLU0NgSDwsPSZIaGlvh4VSLJEmaGhMPSZIaMvGQJEkaiImHJEmNuIGYJEnSgEw8JElqaGyJh4WHJEkNja3wcKpFkiRNjYmHJEkNmXhIkiQNxMRDkqSGxpZ4WHhIktSI+3hIkiQNyMRDkqSGTDwkSZIGYuIhSVJDY0s8LDwkSWpobIWHUy2SJGlqTDwkSWrIxEOSJGkgJh6SJDXiBmKSJEkDMvGQJKmhsSUeFh6SJDU0tsLDqRZJkjQ1Jh6SJDVk4iFJkjQQEw9JkhoaW+Jh4SFJUiPu4yFJkjQgCw9JkhqaST0W87bA626Z5INJfpjkB0n2SXKzJCclObP/c6u+b5K8NsnKJGck2W1tX6+FhyRJ4/Qa4FNVdSfg7sAPgOcAJ1fVTsDJ/WOAA4Gd+tuRwBvX9qJTWeOR5OZ0LwDgVsA1wK/6x3tW1ZXTGIckSUtNizUeSW4K/CVwGED/e/jKJAcD+/bdjgU+DzwbOBh4Z1UVcEqflty6qs5f02tPpfCoql8DuwAkORr4fVW9crJPur/5VNW10xiTJElLwUCFx9ZJTp14vKKqVkw8vh1dAPD2JHcHTgOeAmwzU0xU1flJbtn33xY4d+L5q/q2NS48mk61JLlDku8meRPwTWD7JL+ZOP7oJG/t72+T5MNJTk3y9SR7txq3JElL3IVVtcfEbcWs4xsAuwFvrKpdgUv507TKXOaqjmptBrYU1njcBTimf+E/n6ffa4GXV9UewCOBt87ukOTIvjA59ZJLLhlmtJIkLaJGi0tXAauq6mv94w/SFSK/THLrfly3Bi6Y6L/9xPO3A85bm9e7FAqPn1TVNxbQ737Am5KcDnwU2CrJppMdqmrFTHW3xRZbDDFWSZJu9KrqF8C5Se7YN+0HfB84Hji0bzsU+Fh//3jg8f2nW/YGLlmb9R2wNDYQu3Ti/rVcN87ZZOJ+cCGqJGkZabyB2JOB9yTZCDgLOJwukPhAkiOAnwGP6PueABwErAQu6/uulaVQePxRVV2b5OIkOwE/Af6GP3365TPAE4FXAyTZpapObzNSSZIWR6vCo/8duscch/abo2/R/Q5eZ0thqmW2ZwOfovv47aqJ9icC9+o3Lvk+8A8tBidJktbe1BOPqjp64v5K+o/ZTrQdBxw3x/N+BTx86PFJkjRNfleLJEnSQJbUGg9JksbGxEOSJGkgJh6SJDU0tsTDwkOSpEYa7+PRhFMtkiRpakw8JElqyMRDkiRpICYekiQ1NLbEw8JDkqSGxlZ4ONUiSZKmxsRDkqSGTDwkSZIGYuIhSVIjY9xAzMJDkqSGxlZ4ONUiSZKmxsRDkqSGTDwkSZIGYuIhSVJDJh6SJEkDMfGQJKmhsSUeFh6SJDUyxn08nGqRJElTY+IhSVJDJh6SJEkDMfGQJKmhsSUeFh6SJDU0tsLDqRZJkjQ1Jh6SJDVk4iFJkjQQEw9JkhoZ4wZiFh6SJDU0tsLDqRZJkjQ1Jh6SJDVk4iFJkjQQEw9Jkhoy8ZAkSRqIiYckSQ2NLfGw8JAkqZEx7uPhVIskSZoaEw9Jkhoy8ZAkSRqIiYckSQ2NLfGw8JAkqaGxFR5OtUiSpKkx8ZAkqSETD0mSpIGYeEiS1MgYNxCz8JAkqaGxFR5OtUiSpKkx8ZAkqSETD0mSpIGYeEiS1JCJhyRJ0kBMPCRJamhsiYeFhyRJjYxxHw+nWiRJ0tSYeEiS1JCJhyRJ0kBMPCRJasjEQ5IkTc3MAtPFvC3wuusn+VaST/SPd0zytSRnJjkuyUZ9+8b945X98R3W5fVaeEiSNE5PAX4w8fhlwKuraifgYuCIvv0I4OKqugPw6r7fWrPwkCSpoRaJR5LtgAcCb+0fB7gv8MG+y7HAQ/r7B/eP6Y/vl3WYH7LwkCRp+dk6yakTtyNnHf9P4FnAtf3jmwO/qaqr+8ergG37+9sC5wL0xy/p+68VF5dKktTIgBuIXVhVe6zmmn8NXFBVpyXZd6Z5jq61gGNrzMJDkqSGGnyq5V7Ag5McBGwC3JQuAdkyyQZ9qrEdcF7ffxWwPbAqyQbAFsBFa3txp1okSRqRqnpuVW1XVTsAjwY+W1WPAT4HPLzvdijwsf7+8f1j+uOfrSoTD0mSboyW0D4ezwben+TFwLeAY/r2Y4B3JVlJl3Q8el0uYuEhSdJIVdXngc/3988C9pyjzxXAIxbrmhYekiQ1tIQSj6lwjYckSZoaEw9JkhoaW+Jh4SFJUiMD7uOxZDnVIkmSpsbEQ5Kkhkw8JEmSBmLiIUlSQ2NLPCw8JElqaGyFh1MtkiRpakw8JElqyMRDkiRpICYekiQ1MsYNxCw8JElqaGyFh1MtkiRpakw8JElqyMRDkiRpICYekiQ1ZOIhSZI0EBMPSZIa8eO0kiRpqsZWeDjVIkmSpsbEQ5Kkhkw8JEmSBmLiIUlSQ2NLPJZt4fHjH//4wn333fec1uPQdWwNXNh6ENIS5ntkabntNC5i4bFMVNUtWo9B15Xk1Krao/U4pKXK94jGYNkWHpIkLXVj3MfDxaWSJGlqTDw0TStaD0Ba4nyPjNDYEg8LD01NVfmPqjQP3yPjNLbCw6kWSZI0NSYekiQ1ZOIhSZI0EBMPSZIaMvGQ1lDG9q6R1sDq3h++bzRWJh5aJ0lSVdXffyBQwC+Bb860S2M16/3xD8CmwBZV9SLfH4JxbiBm4aF1MvGP6jOBBwJfAfYCXgac1HBoUnMT748nAH8L/CNwRpJfVdWbmg5OS8bYCg+nWrTOktwW2Kuq7gP8AbgCODnJJm1HJrUxM42SZL0kmwK7Aw8D/go4EXhrko0aDlFqxsRDa2wyPu79AbgyyVuAWwMPq6prkxyU5JSqOq/NSKU2Jt4fN6mqS5JcBfw/YBO698fVSZ6R5EdV9Yl2I9VSYOIhzWPWnPXjk9yD7mu8zwF2BZ5eVX9I8nfAUcC17UYrtZNkT+A1SW4GfIluquXZVXV5kkcBjwO+33KMUgsmHlpT6wHXJHkS8A/AQ/v/vX2Srsh4e5JvAPcHHllVv2g4VmlqZoryWYngL4B/A54LPAv4QJIfATsCj62qsxoNV0vI2BKPuLBaC5Fkd+AHVXVZkjsBx9IVFuckeQBdEftruih5s77v2e1GLLWRZJ+q+mp/fzfgb4AtgGcCt6B7j1zuFKQAknwK2HqAU19YVQcMcN51ZuGhG9QvlHsjcFdgf+BK4DV0Hw0EuA3dOo8PV9WxTQYpLQFJbg78EHhnVT2jb9sb+Hfg58DRVfWzhkOUmnONh25QHxs/FfgW8CFkqNWQAAAFEklEQVQgwAfo5qdf2VfVpwD3ADdG0ngk2WHi/hOAw4A9gAcneSlAVZ0CrAR+R1e0S6Nm4qHVmv3plf7jf28AtqGbZrm8b38sXYx8SFX9oMlgpSlLchBd8rcbcCBwX+DlVXVWkm3pFpR+lC4BeRTdmg6nVzR6Jh6aU5L1Jj69snOSHavqyqr6e7qdST+aZNN+D4/96f5RtejQKPTrml4JPK6qfgc8BHgocAFAVf0c2AfYnC4JfKpFh9Qx8dC8kjwFeDjd/PTv+8KDJG+iW/NxX2D9mfRDWu6S7A+8C/gi8Lyq+nGSmwLvAa6qqodO9F2P7t/Za9qMVlp6TDx0HUluNXH/McAj6D4aezZwWJKPA1TVE+jWfGxj0aGxSLIf8Hrg6cBXgSOS/EVV/RZ4DHBpkvfPrHOqqmstOqTrsvDQH/Vf8nZ8klv0TT+iKzyOAO5M9zHAu08UH0+uqnObDFZq47fAYVX1HuATdItFH5jkXn3x8US698nbG45RWtKcahEASQ4Ang+8pKo+lWSDfmOwjYG3Au+oqpOTvISuGNnXOWuNVb8G6tokO9HtQLoRcHxVfSXJTei2Svf9Ic3BxEP0WzqfALyqLzpuDxzT70lQdLsv7p3kecAOwL39R1VjVlXX9n+eSbfe43LgkCR7VdXvfH9Iq2fhIarqIuBBwL8luRuwAvhWVf26qq7kT19vf2/gpVV1QaOhSktOX3wcB5xHtxZK0jycatEf9dMtJ9Ct1H/pzHTLxPENq+qqdiOUli7fH9LCWHjoOpLcH3gdsFf/dd4b9amHJEnrzMJD15PkQOA/gX36aRhJkhbFBq0HoKWnqv6n3x79M0n26JqsUCVJ687EQ6uVZPOq+n3rcUiSlg8LD0mSNDV+nFaSJE2NhYckSZoaCw9JkjQ1Fh6SJGlqLDykJS7JNUlOT/LdJP+dZLN1ONe+ST7R339wkufM03fLJP+0Ftc4Oskz13aMkpY3Cw9p6bu8qnapqrvSfQ37EyYPprPG7+WqOr6qXjpPly2BNS48JGk+Fh7SjcsXgTsk2SHJD5K8AfgmsH2S/ZN8Nck3+2Rkc+i+gyfJD5N8CXjozImSHJbk9f39bZJ8JMm3+9s9gZcCt+/Tllf0/f4lyTeSnJHk3yfO9fwkP0ryGeCOU/vbkHSjY+Eh3Ugk2QA4EPhO33RH4J1VtStwKfAC4H5VtRtwKvD0JJsAb6H79uG/AG61mtO/Fvjfqro7sBvwPeA5wE/6tOVfkuwP7ATsCewC7J7kL5PsDjwa2JWusLnHIr90ScuIW6ZLS9+mSU7v738ROAa4DXBOVZ3St+8N3AX4chKAjYCvAncCzu6/up0k7waOnOMa9wUeD1BV1wCXJNlqVp/9+9u3+seb0xUiNwE+UlWX9dc4fp1eraRlzcJDWvour6pdJhv64uLSySbgpKo6ZFa/XYDF2p44wH9U1ZtnXeOpi3gNScucUy3S8nAKcK8kdwBIslmSnYEfAjsmuX3f75DVPP9k4B/7566f5KbA7+jSjBknAn83sXZk2yS3BL4A/E2STZPchG5aR5LmZOEhLQNV9SvgMOB9Sc6gK0TuVFVX0E2tfLJfXHrOak7xFOA+Sb4DnAb8eVX9mm7q5rtJXlFVnwbeC3y17/dB4CZV9U3gOOB04EN000GSNCe/JE6SJE2NiYckSZoaCw9JkjQ1Fh6SJGlqLDwkSdLUWHhIkqSpsfCQJElTY+EhSZKm5v8DZrAkEf8UhjEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 648x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Confusion Matrix\n",
    "\n",
    "confusion_matrix = ConfusionMatrix(y_test, rounded_predictions)\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix)\n",
    "confusion_matrix.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC:  0.8414138792000793\n"
     ]
    }
   ],
   "source": [
    "# ROC AUC\n",
    "print('ROC AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-204-440e5fd394b4>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-204-440e5fd394b4>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for a in i\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Error out to stop notebook\n",
    "for a in i\n",
    "def \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Examine the predictions\n",
    "Let's look at the predictions the NN gets wrong, see if there's a pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df with the relevant data\n",
    "test_set = df1.loc[test_rows]\n",
    "test_set['Predictions'] = predictions\n",
    "test_set['RoundPredictions'] = rounded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimise memory --> set col types for the incoming CSV\n",
    "cds_cols = ['# ChemicalName', 'ChemicalID', 'DiseaseName', 'DiseaseID', 'DirectEvidence']\n",
    "cd_col_types = {   \n",
    "    '# ChemicalName': 'category',\n",
    "    'ChemicalID': 'category',\n",
    "    'DiseaseName': 'category',\n",
    "    'DiseaseID': 'category',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the disease and chemical names back! For the sake of eyeballing for patterns\n",
    "# Read in CTD csv, skipping the intro rows\n",
    "df_cd = pd.read_csv('../ctd-to-nt/csvs/CTD_chemicals_diseases.csv', usecols=cds_cols, dtype=cd_col_types, skiprows=27)\n",
    "df_cd = df_cd.drop(0)\n",
    "df_cd = df_cd.dropna(subset=['DirectEvidence']) # drop if it doesn't have direct evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set.DiseaseID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['Correlation'] = test_set.Correlation.astype(np.uint8)\n",
    "print(mem_usage(test_set['RoundPredictions']))\n",
    "test_set['RoundPredictions'] = test_set.RoundPredictions.astype(np.uint8)\n",
    "print(mem_usage(test_set['RoundPredictions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [chem_dis, df, df_d, df_c, Dvecs, Cvecs]\n",
    "del lst\n",
    "test_set = test_set.drop(['DVec', 'CVec', 'index'], axis=1) # memory intensive\n",
    "for col in ['DiseaseID', 'ChemicalID', 'DiseaseName', '# ChemicalName', 'DirectEvidence']:\n",
    "    print(col,  df_cd.columns)\n",
    "    if str(col) in df_cd.columns: print('sd') # df_cd[col] = df_cd[col].astype('category')\n",
    "    if col in test_set.columns: test_set[col] = test_set[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_usage(df_cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in the names\n",
    "\n",
    "# Because this weirdly requires a tonne of memory, let's optimise (for stupid terrible top-of-range dell laptop)\n",
    "# lst = [chem_dis, df, df_d, df_c, Dvecs, Cvecs]\n",
    "# del lst\n",
    "# test_set = test_set.drop(['DVec', 'CVec', 'index'], axis=1) # memory intensive\n",
    "# for col in ['DiseaseID', 'ChemicalID', 'DiseaseName', '# ChemicalName', 'DirectEvidence']:\n",
    "#     if col in df_cd.columns: df_cd[col] = df_cd[col].astype('category')\n",
    "#     if col in test_set.columns: test_set[col] = test_set[col].astype('category')\n",
    "\n",
    "test_set = pd.merge(test_set, df_cd[['DiseaseID', 'DiseaseName']], on='DiseaseID')\n",
    "test_set = pd.merge(test_set, df_cd[['# ChemicalName', 'ChemicalID']], on='ChemicalID')\n",
    "\n",
    "# weirdly these operations introduce millions of duplicate rows, so delete duplicates:\n",
    "test_set = test_set.drop_duplicates(list(set(test_set.columns.values))) #- set(['DVec','CVec'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd.ChemicalID = df_cd.ChemicalID.astype('category')\n",
    "type(df_cd.ChemicalID[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[['DiseaseName', '# ChemicalName', 'Correlation', 'Predictions', 'RoundPredictions']].to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import gofunction counts (for each disease and each chem). This csv was output in opa2vec.ipynb\n",
    "gofunc_counts = pd.read_csv('gofunc_counts.csv')\n",
    "test_set = pd.merge(test_set, gofunc_counts[['ChemicalID', 'gofunc']], on='ChemicalID')\n",
    "test_set = test_set.rename(columns = {'gofunc':'ChemGoFuncs'})\n",
    "test_set = pd.merge(test_set, gofunc_counts[['DiseaseID', 'gofunc']], on='DiseaseID')\n",
    "test_set = test_set.rename(columns = {'gofunc':'DisGoFuncs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This cell is pointless - manually verifying accuracy test\n",
    "# # Round predictions to int based on threshold, run accuracy-test manually\n",
    "# predictions = model.predict(X_test)\n",
    "# threshold = predictions[:].sum()/len(predictions) # Threshold is the mean value of predictions\n",
    "# predictions = [float(round(x[0]-threshold+0.5)) for x in predictions]\n",
    "# manual_accuracy = sklearn.metrics.accuracy_score(y_test, predictions, normalize=True, sample_weight=None)\n",
    "# print(manual_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate out the cosine similarity and see if there's a difference between groups\n",
    "# def cosine_sim (row):\n",
    "#     return cosine_similarity(np.array(row.DVec).reshape(1, -1), np.array(row.CVec).reshape(1, -1))[0][0]\n",
    "\n",
    "# df1['cosine_sim'] = df1.apply(lambda row: cosine_sim(row), axis=1)\n",
    "\n",
    "# # Compare cosine sim of correlated and uncorrelated groups\n",
    "# print('Cosine mean with no correlation: ', df1[df1.Correlation == 1 ].cosine_sim.mean())\n",
    "# print('Cosine mean with correlation: ', df1[df1.Correlation == 0 ].cosine_sim.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model (in two files, one for weights and one for json)\n",
    "# json_string = model.to_json()\n",
    "# model.save_weights(\"model2-0.82.h5\")\n",
    "# with open('model2-0.82.json', 'w') as outfile:\n",
    "#     json.dump(json_string, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

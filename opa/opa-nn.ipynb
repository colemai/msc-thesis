{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Use NN to predict disease from chemicals using Opa2Vec vectors\n",
    "<b> Author: </b> Ian Coleman <br>\n",
    "<b> Purpose: </b> Take the vectors created in the opa2vec notebook. This took chemical go functions\n",
    "    and disease go function, creating vectors for each. Train a NN to predict positive chem-dis relationships from these vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from pandas_ml import ConfusionMatrix\n",
    "import json\n",
    "import subprocess\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "#Set random seed\n",
    "np.random.seed(1606)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_usage(pandas_obj):\n",
    "    if isinstance(pandas_obj,pd.DataFrame):\n",
    "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "    else: # we assume if not a df it's a series\n",
    "        usage_b = pandas_obj.memory_usage(deep=True)\n",
    "    usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes\n",
    "    return \"{:03.2f} MB\".format(usage_mb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Vectors and Pre-Process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gofunc vec file\n",
    "with open('go-gofuncs.lst', 'r') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "# Strip and split vector data into list of lists [chem, vec]\n",
    "text = text.replace('\\n', '')\n",
    "text = text.split(']')\n",
    "text = [item.strip().split(' [') for item in text]\n",
    "\n",
    "# Turn it into a data frame\n",
    "df = pd.DataFrame(text)\n",
    "df.columns = ['ID', 'Vector']\n",
    "\n",
    "# Clean\n",
    "df = df.dropna()\n",
    "df['Vector'] = df.Vector.map(lambda x: x.rstrip().lstrip().replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n",
    "\n",
    "# Turn vector column into a list\n",
    "df['Vector'] = df.Vector.map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH:D012559</td>\n",
       "      <td>[1.76247600e-02, -1.05403718e-02, -4.61959302e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESH:D009404</td>\n",
       "      <td>[0.01795662, 0.13640046, 0.03051887, -0.100085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESH:D001749</td>\n",
       "      <td>[-8.68742093e-02, 8.83234814e-02, -2.54237115e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESH:D011471</td>\n",
       "      <td>[-0.00926186, 0.04098112, -0.4911138, -0.22025...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MESH:D008106</td>\n",
       "      <td>[-0.12722802, 0.07976454, -0.5775048, -0.28237...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                             Vector\n",
       "0  MESH:D012559  [1.76247600e-02, -1.05403718e-02, -4.61959302e...\n",
       "1  MESH:D009404  [0.01795662, 0.13640046, 0.03051887, -0.100085...\n",
       "2  MESH:D001749  [-8.68742093e-02, 8.83234814e-02, -2.54237115e...\n",
       "3  MESH:D011471  [-0.00926186, 0.04098112, -0.4911138, -0.22025...\n",
       "4  MESH:D008106  [-0.12722802, 0.07976454, -0.5775048, -0.28237..."
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create DF for NN\n",
    "Munge the df into the following columns:<br>\n",
    "ChemID DisID ChemVec DisVec PositiveAssociationExists(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C112297</td>\n",
       "      <td>MESH:D006948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C112297</td>\n",
       "      <td>MESH:D012640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C425777</td>\n",
       "      <td>MESH:D006948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C013567</td>\n",
       "      <td>MESH:D006333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C418863</td>\n",
       "      <td>MESH:D013262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ChemicalID     DiseaseID\n",
       "0    C112297  MESH:D006948\n",
       "1    C112297  MESH:D012640\n",
       "2    C425777  MESH:D006948\n",
       "3    C013567  MESH:D006333\n",
       "4    C418863  MESH:D013262"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Import file of proven chem-dis positive associations (created in ctd-to-nt notebook from ctd data)\n",
    "chem_dis = pd.read_csv('../ctd-to-nt/chem-dis-pos-assocs.csv')\n",
    "chem_dis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of any chems/diseases that don't have a vector\n",
    "chem_dis['DiseaseID'] = chem_dis['DiseaseID'].astype(str)\n",
    "df['ID'] = df['ID'].astype(str)\n",
    "id_list = df.ID.tolist() # list of chems+diseases with vecs\n",
    "\n",
    "chem_dis['hasDVec'] = chem_dis.DiseaseID.map(lambda x: x in id_list)\n",
    "chem_dis['hasCVec'] = chem_dis.ChemicalID.map(lambda x: x in id_list)\n",
    "chem_dis = chem_dis.loc[(chem_dis['hasDVec'] == True) & (chem_dis['hasCVec'] == True)]\n",
    "chem_dis = chem_dis.drop(['hasDVec','hasCVec'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all info into one df\n",
    "# this df now contains only correlated diseases and vecs\n",
    "df_d = df.copy()\n",
    "df_d.columns= ['DiseaseID', 'DVec']\n",
    "df_c = df.copy()\n",
    "df_c.columns= ['ChemicalID', 'CVec']\n",
    "df1 = pd.merge(chem_dis, df_d, on='DiseaseID')\n",
    "df1 = pd.merge(df1, df_c, on='ChemicalID')\n",
    "\n",
    "df1['Correlation'] = 1 # currently only have correlated in there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>DVec</th>\n",
       "      <th>CVec</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C028474</td>\n",
       "      <td>MESH:D006528</td>\n",
       "      <td>[-0.08689959, 0.06080057, -0.04620415, -0.1237...</td>\n",
       "      <td>[0.01018825, 0.08274926, 0.05085841, -0.117527...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C028474</td>\n",
       "      <td>MESH:D005355</td>\n",
       "      <td>[-4.32693306e-03, 1.35906458e-01, -1.91942360e...</td>\n",
       "      <td>[0.01018825, 0.08274926, 0.05085841, -0.117527...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C028474</td>\n",
       "      <td>MESH:D006529</td>\n",
       "      <td>[-0.02542116, 0.0981225, -0.01938446, -0.14929...</td>\n",
       "      <td>[0.01018825, 0.08274926, 0.05085841, -0.117527...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C028474</td>\n",
       "      <td>MESH:D006965</td>\n",
       "      <td>[-0.01135238, 0.143319, 0.04601676, -0.1474806...</td>\n",
       "      <td>[0.01018825, 0.08274926, 0.05085841, -0.117527...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C028474</td>\n",
       "      <td>MESH:D008114</td>\n",
       "      <td>[-0.10265561, 0.03210206, -0.13152453, -0.0728...</td>\n",
       "      <td>[0.01018825, 0.08274926, 0.05085841, -0.117527...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ChemicalID     DiseaseID                                               DVec  \\\n",
       "0    C028474  MESH:D006528  [-0.08689959, 0.06080057, -0.04620415, -0.1237...   \n",
       "1    C028474  MESH:D005355  [-4.32693306e-03, 1.35906458e-01, -1.91942360e...   \n",
       "2    C028474  MESH:D006529  [-0.02542116, 0.0981225, -0.01938446, -0.14929...   \n",
       "3    C028474  MESH:D006965  [-0.01135238, 0.143319, 0.04601676, -0.1474806...   \n",
       "4    C028474  MESH:D008114  [-0.10265561, 0.03210206, -0.13152453, -0.0728...   \n",
       "\n",
       "                                                CVec  Correlation  \n",
       "0  [0.01018825, 0.08274926, 0.05085841, -0.117527...            1  \n",
       "1  [0.01018825, 0.08274926, 0.05085841, -0.117527...            1  \n",
       "2  [0.01018825, 0.08274926, 0.05085841, -0.117527...            1  \n",
       "3  [0.01018825, 0.08274926, 0.05085841, -0.117527...            1  \n",
       "4  [0.01018825, 0.08274926, 0.05085841, -0.117527...            1  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3137"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8651, 2)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chem_dis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate dfs of dis-vecs and chem-vecs ( in order to generate additional rows for df1)\n",
    "dis = df.ID.map(lambda x: ('MESH' in x) | ('OMIM' in x))\n",
    "chems = df.ID.map(lambda x: ('MESH' not in x) & ('OMIM' not in x))\n",
    "\n",
    "df_chems = df[chems]\n",
    "df_dis = df[dis]\n",
    "df_chems = df_chems.reset_index(drop=True)\n",
    "df_dis = df_dis.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  8650\n",
      "(17301, 5)\n",
      "(17145, 5)\n"
     ]
    }
   ],
   "source": [
    "# Add unrelated pairs to df1\n",
    "no_rows = (df1.shape[0]-1)   # This is a parameter to be tuned --> how many uncorrelated pairs do we want\n",
    "print('shape: ', no_rows)\n",
    "\n",
    "# Randomly select chems and diseases (as many as there are related pairs)\n",
    "no_chems = len(df_chems) -1\n",
    "no_dis = len(df_dis) -1\n",
    "rand_chems = np.random.choice(no_chems, no_rows, replace=True)\n",
    "rand_dis = np.random.choice(no_dis, no_rows, replace=True)\n",
    "\n",
    "# Add the new pairs as rows\n",
    "for x in range(0, no_rows):\n",
    "    int1 = rand_chems[x]\n",
    "    int2 = rand_dis[x]\n",
    "    chem, chemvec = df_chems.loc[int1, 'ID'], df_chems.loc[int1, 'Vector']\n",
    "    dis, disvec = df_dis.loc[int2, 'ID'], df_dis.loc[int2, 'Vector']\n",
    "    df1 = df1.append({'ChemicalID':chem, 'DiseaseID':dis, 'CVec':chemvec, 'DVec':disvec, 'Correlation':0}, ignore_index=True)\n",
    "\n",
    "print(df1.shape)\n",
    "# Drop any duplicates (removes known correlated pairs accidentally generated as uncorrelated)\n",
    "df1 = df1.drop_duplicates(subset=['ChemicalID', 'DiseaseID'], keep=False)\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the elements of the vectors to actual numbers\n",
    "df1['DVec'] = df1.DVec.map(lambda x: [float(i) for i in x])\n",
    "df1['CVec'] = df1.CVec.map(lambda x: [float(i) for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Phenotype Vecs\n",
    "Got a list of Chem-Phenotypes from Sara Alth, where did these come from originally?\n",
    "They have CID identifiers (Pubchem). Need to convert CTD ID to CID ID\n",
    "Use API like so \n",
    "http://pubchem.ncbi.nlm.nih.gov/rest/pug/substance/sourceid/Comparative%20Toxicogenomics%20Database/C533207/cids/TXT/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First we'll add DOIDs for diseases and CIDs for chemicals as an intermediate for adding phenotypes\n",
    "# Read in CSV mapping chems to CID and dis to DOID --> This file is created by phens-opa2vec.ipynb\n",
    "mapper = pd.read_csv('entities.lst')\n",
    "\n",
    "# Make the maps from this\n",
    "dis_map = dict(zip(mapper.ID, mapper.DOID))\n",
    "chem_map = dict(zip(mapper.ID, mapper.CID))\n",
    "\n",
    "# Apply the maps to df1\n",
    "df1['DOID'] = df1.DiseaseID.map(lambda x: dis_map.get(x))\n",
    "df1['CID'] = df1.ChemicalID.map(lambda x: chem_map.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the association files from Sara\n",
    "dis_phens = pd.read_csv('Disease-PhenotypeAssocation.txt', sep=' ', names=['DOID', 'Phenotype'])\n",
    "chem_phens =  pd.read_csv('Drug-PhenotypeAssocation.txt', sep=' ', names=['CID', 'Phenotype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The association files have a different format for each ID system than mine, homogenise these\n",
    "# first chem\n",
    "def cid_standardiser (cid):\n",
    "    # Must be format CID + 9 int chars, starting with 1 seemingly\n",
    "    cid = int(cid)\n",
    "    output = 'CID1' + '0' * (8 - len(str(cid))) + str(cid)\n",
    "    return output\n",
    "\n",
    "df1['CID'] = df1.CID.map(lambda x: np.nan if math.isnan(x) else cid_standardiser(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now disease \n",
    "def doid_standardiser (doid):\n",
    "    # Must be format DOID_ + ...\n",
    "    # I'm unsure about how well this is working so print out the DOIDs that don't match\n",
    "    doid = doid.replace(':', '_')\n",
    "#     output = 'CID1' + '0' * (8 - len(str(cid))) + str(cid)\n",
    "    return doid\n",
    "\n",
    "df1['DOID'] = df1.DOID.map(lambda x: np.nan if isinstance(x, float) else doid_standardiser(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't uncomment, unnceessary\n",
    "# # Now that the DOIDs and CIDs are theoretically standardised we can chuck in the phens to df1\n",
    "\n",
    "# # First though check which DOIDs and CIDs do not match up --> SEEMS OK\n",
    "# test_doids = df1[df1.DOID.map(lambda x: isinstance(x, str))].DOID.tolist()\n",
    "# imported_doids = dis_phens.DOID.tolist()\n",
    "# for item in test_doids:\n",
    "#     if item not in imported_doids:\n",
    "#         print(item)                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create one associations file for each ontology (I believe we need to run HP and MP separately)\n",
    "chem_phens.columns = ['ID', 'Phen']\n",
    "dis_phens.columns = ['ID', 'Phen']\n",
    "\n",
    "# Maps for Split into MP/HP\n",
    "hp_df_crit_d = dis_phens.Phen.map(lambda x: 'obolibrary.org/obo/HP' in str(x))\n",
    "mp_df_crit_d = dis_phens.Phen.map(lambda x: 'obolibrary.org/obo/MP' in str(x))\n",
    "hp_df_crit_c = chem_phens.Phen.map(lambda x: 'obolibrary.org/obo/HP' in str(x))\n",
    "mp_df_crit_c = chem_phens.Phen.map(lambda x: 'obolibrary.org/obo/MP' in str(x))\n",
    "\n",
    "total_hp = chem_phens[hp_df_crit_c].append(dis_phens[hp_df_crit_d], ignore_index=True)\n",
    "total_mp = chem_phens[mp_df_crit_c].append(dis_phens[mp_df_crit_d], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num HP associations:  277300\n",
      "Num MP associations:  111742\n",
      "Num ents with MP phen assocs:  8942\n",
      "Num ents with HP phen assocs:  9126\n"
     ]
    }
   ],
   "source": [
    "# Export the association files and print some stats (more stats later)\n",
    "np.savetxt(r'associations_hp.txt', total_hp.values, fmt='%s')\n",
    "np.savetxt(r'associations_mp.txt', total_mp.values, fmt='%s')\n",
    "\n",
    "print('Num HP associations: ', total_hp.shape[0])\n",
    "print('Num MP associations: ', total_mp.shape[0])\n",
    "print('Num ents with MP phen assocs: ', len(total_mp.ID.unique()))\n",
    "print('Num ents with HP phen assocs: ', len(total_hp.ID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create entities.lst to inform opa2vec which entities we want vectors for\n",
    "entities = total_mp.ID.unique().tolist()\n",
    "np.savetxt(r'entities_mp.lst', entities, fmt='%s')\n",
    "\n",
    "entities = total_hp.ID.unique().tolist()\n",
    "np.savetxt(r'entities_hp.lst', entities, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run OPA2VEC for entity-phens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HP --> takes ages so commenting out\n",
    "# subprocess.check_output('(cd ../../opa2vec/ ; python2 runOPA2Vec.py -ontology ../ontologies/hp.owl -associations ../msc-thesis/opa/associations_hp.txt -entities ../msc-thesis/opa/entities_hp.lst -outfile ../msc-thesis/opa/hpvecs.lst)', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MP --> takes ages so commenting out\n",
    "# subprocess.check_output('(cd ../../opa2vec/ ; python2 runOPA2Vec.py -ontology ../ontologies/mp.owl -associations ../msc-thesis/opa/associations_mp.txt -entities ../msc-thesis/opa/entities_mp.lst -outfile ../msc-thesis/opa/mpvecs.lst)', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now import and integrate the vecs (all phen stuff above here should be in its own notebook )\n",
    "# Import vec file\n",
    "with open('hpvecs.lst', 'r') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "# Strip and split vector data into list of lists [chem, vec]\n",
    "text = text.replace('\\n', '')\n",
    "text = text.split(']')\n",
    "text = [item.strip().split(' [') for item in text]\n",
    "\n",
    "# Turn it into a data frame\n",
    "hp_vecs = pd.DataFrame(text)\n",
    "hp_vecs.columns = ['ID', 'Vector']\n",
    "\n",
    "# Clean\n",
    "hp_vecs = hp_vecs.dropna()\n",
    "hp_vecs['Vector'] = hp_vecs.Vector.map(lambda x: x.rstrip().lstrip().replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n",
    "\n",
    "# Turn vector column into a list\n",
    "hp_vecs['Vector'] = hp_vecs.Vector.map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now import and integrate the mp vecs\n",
    "# Import vec file\n",
    "with open('mpvecs.lst', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Strip and split vector data into list of lists [chem, vec]\n",
    "text = text.replace('\\n', '')\n",
    "text = text.split(']')\n",
    "text = [item.strip().split(' [') for item in text]\n",
    "\n",
    "# Turn it into a data frame\n",
    "mp_vecs = pd.DataFrame(text)\n",
    "mp_vecs.columns = ['ID', 'Vector']\n",
    "\n",
    "# Clean\n",
    "mp_vecs = mp_vecs.dropna()\n",
    "mp_vecs['Vector'] = mp_vecs.Vector.map(lambda x: x.rstrip().lstrip().replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n",
    "\n",
    "# Turn vector column into a list\n",
    "mp_vecs['Vector'] = mp_vecs.Vector.map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right, now I have hp and mp vecs, match them up into df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Maps:\n",
    "mp_ent_to_vec = dict(zip(mp_vecs.ID, mp_vecs.Vector))\n",
    "hp_ent_to_vec = dict(zip(hp_vecs.ID, hp_vecs.Vector))\n",
    "\n",
    "# Map entities to vecs (one set of vecs for mp and another for hp)\n",
    "df1['disPhenVecMP'] = df1.DOID.map(lambda x: mp_ent_to_vec.get(x))\n",
    "df1['disPhenVecHP'] = df1.DOID.map(lambda x: hp_ent_to_vec.get(x))\n",
    "\n",
    "df1['chemPhenVecHP'] = df1.CID.map(lambda x: hp_ent_to_vec.get(x))\n",
    "df1['chemPhenVecMP'] = df1.CID.map(lambda x: mp_ent_to_vec.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note these numbers include both correlated and uncorrelated pairs\n",
      "Number of rows with gofuncs:  17145\n",
      "Number of rows with dis mp vec:  7079\n",
      "Number of rows with dis hp vec:  7088\n",
      "Number of rows with chem mp vec:  2770\n",
      "Number of rows with chem hp vec:  2846\n",
      "Number of rows with no phen vecs:  8529\n",
      "Number of rows with everything 1279\n",
      "Number of correlated pairs with phenvecs 3027\n",
      "Number of uncorrelated pairs with phenvecs 5502\n",
      "Number of correlated pairs with everything 1059\n",
      "Number of uncorrelated pairs with everything 220\n",
      "total pos corr 8595\n",
      "total neg corr 8550\n"
     ]
    }
   ],
   "source": [
    "## TODO note that I have removed rows without gofuncVecs, maybe now they should be kept\n",
    "# Print Stats\n",
    "print('Note these numbers include both correlated and uncorrelated pairs')\n",
    "print('Number of rows with gofuncs: ', df1.shape[0]) ##NB change this if keeping rows w/o gofunc vecs\n",
    "print('Number of rows with dis mp vec: ', df1[df1.disPhenVecMP.map(lambda x: x is not None)].shape[0])\n",
    "print('Number of rows with dis hp vec: ', df1[df1.disPhenVecHP.map(lambda x: x is not None)].shape[0])\n",
    "print('Number of rows with chem mp vec: ', df1[df1.chemPhenVecMP.map(lambda x: x is not None)].shape[0])\n",
    "print('Number of rows with chem hp vec: ', df1[df1.chemPhenVecHP.map(lambda x: x is not None)].shape[0])\n",
    "no_dis_phen_vecs = df1.disPhenVecHP.map(lambda x: x is None) & df1.disPhenVecMP.map(lambda x: x is None)\n",
    "no_chem_phen_vecs = df1.chemPhenVecHP.map(lambda x: x is None) & df1.chemPhenVecMP.map(lambda x: x is None)\n",
    "no_phen_vecs = no_dis_phen_vecs & no_chem_phen_vecs\n",
    "print('Number of rows with no phen vecs: ', df1[no_phen_vecs].shape[0])\n",
    "all_dis_phen_vecs = df1.disPhenVecHP.map(lambda x: x is not None) & df1.disPhenVecMP.map(lambda x: x is not None)\n",
    "all_chem_phen_vecs = df1.chemPhenVecHP.map(lambda x: x is not None) & df1.chemPhenVecMP.map(lambda x: x is not None)\n",
    "all_vecs = all_dis_phen_vecs & all_chem_phen_vecs\n",
    "all_vecs_pos_corr = all_vecs & df1.Correlation.map(lambda x: x == 1)\n",
    "all_vecs_neg_corr = all_vecs & df1.Correlation.map(lambda x: x == 0)\n",
    "no_phen_vecs_corr = no_phen_vecs & df1.Correlation.map(lambda x: x == 1)\n",
    "no_phen_vecs_uncorr = no_phen_vecs & df1.Correlation.map(lambda x: x == 0)\n",
    "\n",
    "\n",
    "\n",
    "print('Number of rows with everything', df1[all_vecs].shape[0])\n",
    "\n",
    "print('Number of correlated pairs with phenvecs', df1[no_phen_vecs_corr].shape[0])\n",
    "print('Number of uncorrelated pairs with phenvecs', df1[no_phen_vecs_uncorr].shape[0])\n",
    "\n",
    "\n",
    "print('Number of correlated pairs with everything', df1[all_vecs_pos_corr].shape[0])\n",
    "print('Number of uncorrelated pairs with everything', df1[all_vecs_neg_corr].shape[0])\n",
    "\n",
    "print('total pos corr', df1[df1.Correlation.map(lambda x: x == 1)].shape[0])\n",
    "print('total neg corr', df1[df1.Correlation.map(lambda x: x == 0)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add empty vecs for rows that don't have phen vecs\n",
    "empty_vec = [0] * 200\n",
    "\n",
    "for col in ['disPhenVecMP', 'disPhenVecHP', 'chemPhenVecHP', 'chemPhenVecMP']:\n",
    "    df1[col] = df1[col].map(lambda x: empty_vec if x is None else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Phen vec elements from string to floats\n",
    "df1['disPhenVecHP'] = df1.disPhenVecHP.map(lambda x: [float(i) for i in x])\n",
    "df1['disPhenVecMP'] = df1.disPhenVecMP.map(lambda x: [float(i) for i in x])\n",
    "df1['chemPhenVecHP'] = df1.chemPhenVecHP.map(lambda x: [float(i) for i in x])\n",
    "df1['chemPhenVecMP'] = df1.chemPhenVecMP.map(lambda x: [float(i) for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add CHEBI Vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First add CHEBI IDs for each chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chem_names = df1.ChemicalID.unique().tolist()\n",
    "# np.savetxt(r'chem_names', total_hp.values, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add chebi first need CID for ALL Chems so I made this comprehensive map:\n",
    "# Load the map from pickle object\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "ctd_cid_map = load_obj('ctd_cid_map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['CID'] = df1.ChemicalID.map(lambda x: ctd_cid_map.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>DVec</th>\n",
       "      <th>CVec</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>DOID</th>\n",
       "      <th>CID</th>\n",
       "      <th>disPhenVecMP</th>\n",
       "      <th>disPhenVecHP</th>\n",
       "      <th>chemPhenVecHP</th>\n",
       "      <th>chemPhenVecMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>C017947</td>\n",
       "      <td>MESH:D008175</td>\n",
       "      <td>[-0.0498087, 0.08013102, -0.21025404, -0.14221...</td>\n",
       "      <td>[-0.0531880707, 0.0433869548, -0.196800679, -0...</td>\n",
       "      <td>1</td>\n",
       "      <td>DOID_3905</td>\n",
       "      <td>b'443495'</td>\n",
       "      <td>[0.0438675731, 0.153149575, 0.0684680566, -0.1...</td>\n",
       "      <td>[0.03999165, 0.145569, 0.0636293, -0.1037104, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>C582340</td>\n",
       "      <td>MESH:D013617</td>\n",
       "      <td>[0.05696682, 0.09369084, -0.0048688, -0.089769...</td>\n",
       "      <td>[0.03923435, 0.10083519, 0.0233496, -0.1123369...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8458</th>\n",
       "      <td>D014673</td>\n",
       "      <td>MESH:D007022</td>\n",
       "      <td>[-0.07060508, 0.08438816, -0.0596953, -0.07784...</td>\n",
       "      <td>[0.0453479178, 0.138363615, -0.0531766899, -0....</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'39764'</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.02038578, 0.11926291, 0.05529715, -0.122521...</td>\n",
       "      <td>[0.03689281, 0.13800456, 0.05547665, -0.123047...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ChemicalID     DiseaseID  \\\n",
       "1341    C017947  MESH:D008175   \n",
       "9741    C582340  MESH:D013617   \n",
       "8458    D014673  MESH:D007022   \n",
       "\n",
       "                                                   DVec  \\\n",
       "1341  [-0.0498087, 0.08013102, -0.21025404, -0.14221...   \n",
       "9741  [0.05696682, 0.09369084, -0.0048688, -0.089769...   \n",
       "8458  [-0.07060508, 0.08438816, -0.0596953, -0.07784...   \n",
       "\n",
       "                                                   CVec  Correlation  \\\n",
       "1341  [-0.0531880707, 0.0433869548, -0.196800679, -0...            1   \n",
       "9741  [0.03923435, 0.10083519, 0.0233496, -0.1123369...            0   \n",
       "8458  [0.0453479178, 0.138363615, -0.0531766899, -0....            1   \n",
       "\n",
       "           DOID        CID                                       disPhenVecMP  \\\n",
       "1341  DOID_3905  b'443495'  [0.0438675731, 0.153149575, 0.0684680566, -0.1...   \n",
       "9741        NaN       None  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8458        NaN   b'39764'  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                           disPhenVecHP  \\\n",
       "1341  [0.03999165, 0.145569, 0.0636293, -0.1037104, ...   \n",
       "9741  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8458  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                          chemPhenVecHP  \\\n",
       "1341  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9741  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8458  [0.02038578, 0.11926291, 0.05529715, -0.122521...   \n",
       "\n",
       "                                          chemPhenVecMP  \n",
       "1341  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "9741  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8458  [0.03689281, 0.13800456, 0.05547665, -0.123047...  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CIDS from bytes to strings and export in order to make a map from CID to CHEBI ID\n",
    "df1['CID'] = df1.CID.str.decode(\"utf-8\")\n",
    "np.savetxt(r'allCIDs.txt', df1.CID.unique(), fmt='%s')\n",
    "\n",
    "## NOTE the next step is MANUAL you need to upload this allCIDs.txt to http://cts.fiehnlab.ucdavis.edu/batch \n",
    "# and download it as ctd_chebi.csv to the current folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV mapping CID to CHEBI\n",
    "ctdChebdf = pd.read_csv('ctd_chebi.csv')\n",
    "\n",
    "# Turn it into a dict\n",
    "ctd_chebi = dict(zip(ctdChebdf['PubChem CID'], ctdChebdf['ChEBI']))\n",
    "\n",
    "# Map the cids to chebis\n",
    "df1['CHEBI'] = df1.CID.map(lambda x: ctd_chebi.get(x))\n",
    "df1['CHEBI'] = df1.CHEBI.map(lambda x: None if x == 'No result' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now make CHEBI vecs using the CHEBI IDs\n",
    "# First an association file - just linking each chebi to its own chebi entity\n",
    "\n",
    "# add uri col\n",
    "df1['CHEBI_uri'] = df1.dropna(subset=['CHEBI']).CHEBI.map(lambda x: '<http://purl.obolibrary.org/obo/' + x.replace(':', '_') + '>')\n",
    "\n",
    "# export association file from df\n",
    "np.savetxt(r'CHEBIassociations.txt', df1[['ChemicalID', 'CHEBI_uri']].dropna().drop_duplicates().values, fmt='%s')\n",
    "\n",
    "# Now an entities file\n",
    "chems_for_cheb = df1[['ChemicalID', 'CHEBI_uri']].dropna().drop_duplicates().ChemicalID.tolist()\n",
    "np.savetxt(r'CHEBIentities.txt', chems_for_cheb, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commenting this out now that I already have the vectors, you'll need it if you don't have them\n",
    "# # Now run opa2vec on it \n",
    "# subprocess.check_output('(cd ../../opa2vec/ ; python2 runOPA2Vec.py -ontology ../ontologies/chebi.owl -associations ../msc-thesis/opa/CHEBIassociations.txt -entities ../msc-thesis/opa/CHEBIentities.txt -outfile ../msc-thesis/opa/chebi-vecs.lst)', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gofunc vec file\n",
    "with open('chebi-vecs.lst', 'r') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "# Strip and split vector data into list of lists [chem, vec]\n",
    "text = text.replace('\\n', '')\n",
    "text = text.split(']')\n",
    "text = [item.strip().split(' [') for item in text]\n",
    "\n",
    "# Turn it into a data frame\n",
    "df = pd.DataFrame(text)\n",
    "df.columns = ['ID', 'Vector']\n",
    "\n",
    "# Clean\n",
    "df = df.dropna()\n",
    "df['Vector'] = df.Vector.map(lambda x: x.rstrip().lstrip().replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n",
    "\n",
    "# Turn vector column into a list\n",
    "df['Vector'] = df.Vector.map(lambda x: x.split(','))\n",
    "\n",
    "# Make a map of it (ChemID to CHEBIvec)\n",
    "chem_to_chebi_vec = dict(zip(df.ID, df.Vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['CHEBIvec'] = df1.ChemicalID.map(lambda x: chem_to_chebi_vec.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows 17145\n",
      "Total Correlated Rows 8595\n",
      "Total CHEBI vec rows 10660\n",
      "Total CHEBI vec correlated rows 5894\n",
      "Total Chems 570\n",
      "Total Chems with CHEBI Vec 316\n"
     ]
    }
   ],
   "source": [
    "# How many rows have CHEBI Vecs?\n",
    "print('Total Rows', df1.shape[0])\n",
    "print('Total Correlated Rows', df1[df1.Correlation == 1].shape[0])\n",
    "print('Total CHEBI vec rows', df1.dropna(subset=['CHEBIvec']).shape[0])\n",
    "print('Total CHEBI vec correlated rows', df1[df1.Correlation == 1].dropna(subset=['CHEBIvec']).shape[0])\n",
    "print('Total Chems', len(df1.ChemicalID.unique()))\n",
    "print('Total Chems with CHEBI Vec', len(df1.dropna(subset=['CHEBIvec']).ChemicalID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>DVec</th>\n",
       "      <th>CVec</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>DOID</th>\n",
       "      <th>CID</th>\n",
       "      <th>disPhenVecMP</th>\n",
       "      <th>disPhenVecHP</th>\n",
       "      <th>chemPhenVecHP</th>\n",
       "      <th>chemPhenVecMP</th>\n",
       "      <th>CHEBI</th>\n",
       "      <th>CHEBI_uri</th>\n",
       "      <th>CHEBIvec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7769</th>\n",
       "      <td>D011794</td>\n",
       "      <td>MESH:D009133</td>\n",
       "      <td>[0.03116769, 0.13587785, 0.04433348, -0.132408...</td>\n",
       "      <td>[-0.02145532, 0.06948259, -0.1081144, -0.14960...</td>\n",
       "      <td>1</td>\n",
       "      <td>DOID_767</td>\n",
       "      <td>5280343</td>\n",
       "      <td>[0.025967028, 0.142268777, 0.066210404, -0.147...</td>\n",
       "      <td>[0.04816369, 0.14606375, 0.05307954, -0.107326...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>CHEBI:16243</td>\n",
       "      <td>&lt;http://purl.obolibrary.org/obo/CHEBI_16243&gt;</td>\n",
       "      <td>[0.01221674, 0.05984232, 0.03748447, -0.071131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13468</th>\n",
       "      <td>C012655</td>\n",
       "      <td>MESH:D012608</td>\n",
       "      <td>[0.01731185, 0.11330543, 0.07036374, -0.148131...</td>\n",
       "      <td>[0.00528433267, 0.0889950693, 0.0519304797, -0...</td>\n",
       "      <td>0</td>\n",
       "      <td>DOID_5434</td>\n",
       "      <td>4495</td>\n",
       "      <td>[0.03662067, 0.14778006, 0.05885815, -0.139689...</td>\n",
       "      <td>[0.03258642, 0.12822168, 0.05323575, -0.108937...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15111</th>\n",
       "      <td>C509592</td>\n",
       "      <td>MESH:C535780</td>\n",
       "      <td>[0.01960866, 0.12501125, 0.04490718, -0.128422...</td>\n",
       "      <td>[0.00356502, 0.11017938, -0.02927761, -0.08686...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ChemicalID     DiseaseID  \\\n",
       "7769     D011794  MESH:D009133   \n",
       "13468    C012655  MESH:D012608   \n",
       "15111    C509592  MESH:C535780   \n",
       "\n",
       "                                                    DVec  \\\n",
       "7769   [0.03116769, 0.13587785, 0.04433348, -0.132408...   \n",
       "13468  [0.01731185, 0.11330543, 0.07036374, -0.148131...   \n",
       "15111  [0.01960866, 0.12501125, 0.04490718, -0.128422...   \n",
       "\n",
       "                                                    CVec  Correlation  \\\n",
       "7769   [-0.02145532, 0.06948259, -0.1081144, -0.14960...            1   \n",
       "13468  [0.00528433267, 0.0889950693, 0.0519304797, -0...            0   \n",
       "15111  [0.00356502, 0.11017938, -0.02927761, -0.08686...            0   \n",
       "\n",
       "            DOID      CID                                       disPhenVecMP  \\\n",
       "7769    DOID_767  5280343  [0.025967028, 0.142268777, 0.066210404, -0.147...   \n",
       "13468  DOID_5434     4495  [0.03662067, 0.14778006, 0.05885815, -0.139689...   \n",
       "15111        NaN     None  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                            disPhenVecHP  \\\n",
       "7769   [0.04816369, 0.14606375, 0.05307954, -0.107326...   \n",
       "13468  [0.03258642, 0.12822168, 0.05323575, -0.108937...   \n",
       "15111  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                           chemPhenVecHP  \\\n",
       "7769   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "13468  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "15111  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                           chemPhenVecMP        CHEBI  \\\n",
       "7769   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  CHEBI:16243   \n",
       "13468  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...         None   \n",
       "15111  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...         None   \n",
       "\n",
       "                                          CHEBI_uri  \\\n",
       "7769   <http://purl.obolibrary.org/obo/CHEBI_16243>   \n",
       "13468                                           NaN   \n",
       "15111                                           NaN   \n",
       "\n",
       "                                                CHEBIvec  \n",
       "7769   [0.01221674, 0.05984232, 0.03748447, -0.071131...  \n",
       "13468                                               None  \n",
       "15111                                               None  "
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add empty vecs for rows that don't have Chebi vecs\n",
    "empty_vec = [0] * 200\n",
    "df1['CHEBIvec'] = df1['CHEBIvec'].map(lambda x: empty_vec if x is None else x)\n",
    "\n",
    "# Change the Chebi vec elements from string to floats\n",
    "df1['CHEBIvec'] = df1.CHEBIvec.map(lambda x: [float(i) for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add DO Vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gofunc vec file\n",
    "with open('do-vecs.lst', 'r') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "# Strip and split vector data into list of lists [disease, vec]\n",
    "text = text.replace('\\n', '')\n",
    "text = text.split(']')\n",
    "text = [item.strip().split(' [') for item in text]\n",
    "\n",
    "# Turn it into a data frame\n",
    "df = pd.DataFrame(text)\n",
    "df.columns = ['ID', 'Vector']\n",
    "\n",
    "# Clean\n",
    "df = df.dropna()\n",
    "df['Vector'] = df.Vector.map(lambda x: x.rstrip().lstrip().replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n",
    "\n",
    "# Turn vector column into a list\n",
    "df['Vector'] = df.Vector.map(lambda x: x.split(','))\n",
    "\n",
    "# Make a map of it (DisID to DOvec)\n",
    "dis_to_DOvec = dict(zip(df.ID, df.Vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['DOvec'] = df1.DiseaseID.map(lambda x: dis_to_DOvec.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the DO vec elements from string to floats\n",
    "df1['DOvec'] = df1.DOvec.map(lambda x: [float(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df1['chemPhenVecHP'][0][0]))\n",
    "print(type(df1.CHEBIvec[17115][0]))\n",
    "print(type(df1.DOvec[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0155570945"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.CHEBIvec.iloc[17115][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00653758785"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.DOvec.iloc[17115][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess\n",
    "Now that we have the df ready, let's split it into train/test/validation sets and convert it into numpy arrays so it can be consumed by a Keras NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8595\n",
      "(17145, 15)\n"
     ]
    }
   ],
   "source": [
    "print(df1[df1.Correlation == 1].shape[0])\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>DVec</th>\n",
       "      <th>CVec</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>DOID</th>\n",
       "      <th>CID</th>\n",
       "      <th>disPhenVecMP</th>\n",
       "      <th>disPhenVecHP</th>\n",
       "      <th>chemPhenVecHP</th>\n",
       "      <th>chemPhenVecMP</th>\n",
       "      <th>CHEBI</th>\n",
       "      <th>CHEBI_uri</th>\n",
       "      <th>CHEBIvec</th>\n",
       "      <th>DOvec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8456</th>\n",
       "      <td>D014673</td>\n",
       "      <td>MESH:D009336</td>\n",
       "      <td>[-0.0526574999, 0.0888598338, -0.0274056457, -...</td>\n",
       "      <td>[0.0453479178, 0.138363615, -0.0531766899, -0....</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39764</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.02038578, 0.11926291, 0.05529715, -0.122521...</td>\n",
       "      <td>[0.03689281, 0.13800456, 0.05547665, -0.123047...</td>\n",
       "      <td>CHEBI:9940</td>\n",
       "      <td>&lt;http://purl.obolibrary.org/obo/CHEBI_9940&gt;</td>\n",
       "      <td>[0.021671124, 0.054821689, 0.015866555, -0.062...</td>\n",
       "      <td>[0.00657024048, 0.0294857603, 0.0133342622, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9347</th>\n",
       "      <td>D014800</td>\n",
       "      <td>MESH:D006106</td>\n",
       "      <td>[-0.00255577127, 0.137570068, 0.0328803249, -0...</td>\n",
       "      <td>[-0.032665316, 0.00784736034, -0.240696847, -0...</td>\n",
       "      <td>0</td>\n",
       "      <td>DOID_2999</td>\n",
       "      <td>73357729</td>\n",
       "      <td>[0.03042895, 0.15250877, 0.08092121, -0.129971...</td>\n",
       "      <td>[0.04462426, 0.15155883, 0.0598216, -0.1149215...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.01823139, 0.07595742, 0.03893859, -0.067706...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ChemicalID     DiseaseID  \\\n",
       "8456    D014673  MESH:D009336   \n",
       "9347    D014800  MESH:D006106   \n",
       "\n",
       "                                                   DVec  \\\n",
       "8456  [-0.0526574999, 0.0888598338, -0.0274056457, -...   \n",
       "9347  [-0.00255577127, 0.137570068, 0.0328803249, -0...   \n",
       "\n",
       "                                                   CVec  Correlation  \\\n",
       "8456  [0.0453479178, 0.138363615, -0.0531766899, -0....            1   \n",
       "9347  [-0.032665316, 0.00784736034, -0.240696847, -0...            0   \n",
       "\n",
       "           DOID       CID                                       disPhenVecMP  \\\n",
       "8456        NaN     39764  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9347  DOID_2999  73357729  [0.03042895, 0.15250877, 0.08092121, -0.129971...   \n",
       "\n",
       "                                           disPhenVecHP  \\\n",
       "8456  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9347  [0.04462426, 0.15155883, 0.0598216, -0.1149215...   \n",
       "\n",
       "                                          chemPhenVecHP  \\\n",
       "8456  [0.02038578, 0.11926291, 0.05529715, -0.122521...   \n",
       "9347  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                          chemPhenVecMP       CHEBI  \\\n",
       "8456  [0.03689281, 0.13800456, 0.05547665, -0.123047...  CHEBI:9940   \n",
       "9347  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        None   \n",
       "\n",
       "                                        CHEBI_uri  \\\n",
       "8456  <http://purl.obolibrary.org/obo/CHEBI_9940>   \n",
       "9347                                          NaN   \n",
       "\n",
       "                                               CHEBIvec  \\\n",
       "8456  [0.021671124, 0.054821689, 0.015866555, -0.062...   \n",
       "9347  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                  DOvec  \n",
       "8456  [0.00657024048, 0.0294857603, 0.0133342622, -0...  \n",
       "9347  [0.01823139, 0.07595742, 0.03893859, -0.067706...  "
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Version for phen and gofunc vecs\n",
    "# # For Keras, need to turn inputs into numpy arrays instead of pandas df\n",
    "# # First create single np array of all vecs... not pretty:\n",
    "# Dvecs = pd.DataFrame(df1.DVec.values.tolist(), index= df1.index)\n",
    "# Cvecs = pd.DataFrame(df1.CVec.values.tolist(), index= df1.index)\n",
    "# gofuncs = Dvecs.merge(Cvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# DMPvecs = pd.DataFrame(df1.disPhenVecHP.values.tolist(), index= df1.index)\n",
    "# DHPvecs = pd.DataFrame(df1.disPhenVecMP.values.tolist(), index= df1.index)\n",
    "# disPvecs = DMPvecs.merge(DHPvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# CMPvecs = pd.DataFrame(df1.chemPhenVecHP.values.tolist(), index= df1.index)\n",
    "# CHPvecs = pd.DataFrame(df1.chemPhenVecMP.values.tolist(), index= df1.index)\n",
    "# chemPvecs = CMPvecs.merge(CHPvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# phenVecs = disPvecs.merge(chemPvecs, how='outer', left_index=True, right_index=True)\n",
    "# all_X = phenVecs.merge(gofuncs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# all_X = np.array(all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Version for just gofunc vecs\n",
    "# # For Keras, need to turn inputs into numpy arrays instead of pandas df\n",
    "# # First create single np array of all vecs... not pretty:\n",
    "# Dvecs = pd.DataFrame(df1.DVec.values.tolist(), index= df1.index)\n",
    "# Cvecs = pd.DataFrame(df1.CVec.values.tolist(), index= df1.index)\n",
    "# all_X = Dvecs.merge(Cvecs, how='outer', left_index=True, right_index=True)\n",
    "# all_X = np.array(all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Version for Chebi vecs with gofuncs\n",
    "# # For Keras, need to turn inputs into numpy arrays instead of pandas df\n",
    "# # First create single np array of all vecs... not pretty:\n",
    "# Dvecs = pd.DataFrame(df1.DVec.values.tolist(), index= df1.index)\n",
    "# Cvecs = pd.DataFrame(df1.CVec.values.tolist(), index= df1.index)\n",
    "# CHEBvecs = pd.DataFrame(df1.CHEBIvec.values.tolist(), index = df1.index)\n",
    "# gofuncs = Dvecs.merge(Cvecs, how='outer', left_index=True, right_index=True)\n",
    "# all_X = gofuncs.merge(CHEBvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# all_X = np.array(all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ## Version for just CHEBI vecs\n",
    "# # For Keras, need to turn inputs into numpy arrays instead of pandas df\n",
    "# # First create single np array of all vecs... not pretty:\n",
    "# CHEBvecs = pd.DataFrame(df1.CHEBIvec.values.tolist(), index = df1.index)\n",
    "# all_X = np.array(CHEBvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Version for GoFuncs, Phens, CHEBI\n",
    "# # For Keras, need to turn inputs into numpy arrays instead of pandas df\n",
    "# # First create single np array of all vecs... not pretty:\n",
    "# Dvecs = pd.DataFrame(df1.DVec.values.tolist(), index= df1.index)\n",
    "# Cvecs = pd.DataFrame(df1.CVec.values.tolist(), index= df1.index)\n",
    "# gofuncs = Dvecs.merge(Cvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# DMPvecs = pd.DataFrame(df1.disPhenVecHP.values.tolist(), index= df1.index)\n",
    "# DHPvecs = pd.DataFrame(df1.disPhenVecMP.values.tolist(), index= df1.index)\n",
    "# disPvecs = DMPvecs.merge(DHPvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# CMPvecs = pd.DataFrame(df1.chemPhenVecHP.values.tolist(), index= df1.index)\n",
    "# CHPvecs = pd.DataFrame(df1.chemPhenVecMP.values.tolist(), index= df1.index)\n",
    "# chemPvecs = CMPvecs.merge(CHPvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# phenVecs = disPvecs.merge(chemPvecs, how='outer', left_index=True, right_index=True)\n",
    "# all_X = phenVecs.merge(gofuncs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# CHEBvecs = pd.DataFrame(df1.CHEBIvec.values.tolist(), index = df1.index)\n",
    "# all_X = CHEBvecs.merge(all_X, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# all_X = np.array(all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Version for GoFuncs, Phens, CHEBI, DO incl chem phen\n",
    "# # For Keras, need to turn inputs into numpy arrays instead of pandas df\n",
    "# # First create single np array of all vecs... not pretty:\n",
    "# Dvecs = pd.DataFrame(df1.DVec.values.tolist(), index= df1.index)\n",
    "# Cvecs = pd.DataFrame(df1.CVec.values.tolist(), index= df1.index)\n",
    "# gofuncs = Dvecs.merge(Cvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# DMPvecs = pd.DataFrame(df1.disPhenVecHP.values.tolist(), index= df1.index)\n",
    "# DHPvecs = pd.DataFrame(df1.disPhenVecMP.values.tolist(), index= df1.index)\n",
    "# disPvecs = DMPvecs.merge(DHPvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# CMPvecs = pd.DataFrame(df1.chemPhenVecHP.values.tolist(), index= df1.index)\n",
    "# CHPvecs = pd.DataFrame(df1.chemPhenVecMP.values.tolist(), index= df1.index)\n",
    "# chemPvecs = CMPvecs.merge(CHPvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# phenVecs = disPvecs.merge(chemPvecs, how='outer', left_index=True, right_index=True)\n",
    "# all_X = phenVecs.merge(gofuncs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# CHEBvecs = pd.DataFrame(df1.CHEBIvec.values.tolist(), index = df1.index)\n",
    "# all_X = CHEBvecs.merge(all_X, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# DOvecs = pd.DataFrame(df1.DOvec.values.tolist(), index = df1.index)\n",
    "# all_X = DOvecs.merge(all_X, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# all_X = np.array(all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version for GoFuncs, Phens, CHEBI, DO EXCL chem phen\n",
    "# For Keras, need to turn inputs into numpy arrays instead of pandas df\n",
    "# First create single np array of all vecs... not pretty:\n",
    "Dvecs = pd.DataFrame(df1.DVec.values.tolist(), index= df1.index)\n",
    "Cvecs = pd.DataFrame(df1.CVec.values.tolist(), index= df1.index)\n",
    "gofuncs = Dvecs.merge(Cvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "DMPvecs = pd.DataFrame(df1.disPhenVecHP.values.tolist(), index= df1.index)\n",
    "DHPvecs = pd.DataFrame(df1.disPhenVecMP.values.tolist(), index= df1.index)\n",
    "disPvecs = DMPvecs.merge(DHPvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "all_X = disPvecs.merge(gofuncs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "CHEBvecs = pd.DataFrame(df1.CHEBIvec.values.tolist(), index = df1.index)\n",
    "all_X = CHEBvecs.merge(all_X, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "DOvecs = pd.DataFrame(df1.DOvec.values.tolist(), index = df1.index)\n",
    "all_X = DOvecs.merge(all_X, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "all_X = np.array(all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create np array of the y output\n",
    "all_y = np.array(df1.Correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  (17145,)\n",
      "X shape:  (17145, 1200)\n"
     ]
    }
   ],
   "source": [
    "print('y shape: ', all_y.shape)\n",
    "print('X shape: ', all_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create training, test, val set in a way that we can later look at the rows of each BY ROWS\n",
    "# total_rows = len(all_X)\n",
    "# row_numbers = list(range(0, total_rows))\n",
    "\n",
    "# training_rows = random.sample(row_numbers, int(round(total_rows * .6)))\n",
    "# row_numbers = set(row_numbers) - set(training_rows)\n",
    "\n",
    "# test_rows = random.sample(row_numbers, int(round(total_rows * .2)))\n",
    "# row_numbers = set(row_numbers) - set(test_rows)\n",
    "\n",
    "# val_rows = list(row_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chemicals:  570\n",
      "number of dis:  2501\n",
      "342 114 114\n"
     ]
    }
   ],
   "source": [
    "# Split into train, test, val BY CHEMICAL instead of by random rows\n",
    "print('number of chemicals: ', len(df1.ChemicalID.unique()))\n",
    "print('number of dis: ', len(df1.DiseaseID.unique()))\n",
    "chems = list(df1.ChemicalID.unique())\n",
    "random.shuffle(chems)\n",
    "\n",
    "total_chems = len(chems)\n",
    "train_chems = chems[:round(total_chems * .6)]\n",
    "test_chems = chems[round(total_chems * .6):round(total_chems * .8)]\n",
    "val_chems = chems[round(total_chems * .8):]\n",
    "\n",
    "print(len(train_chems), len(test_chems), len(val_chems))\n",
    "\n",
    "# Now get the row numbers for each set of chemicals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['train'] = df1.ChemicalID.isin(train_chems)\n",
    "df1['test'] = df1.ChemicalID.isin(test_chems)\n",
    "df1['val'] = df1.ChemicalID.isin(val_chems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chemicals:  570\n",
      "number of dis:  2501\n"
     ]
    }
   ],
   "source": [
    "# Split by CHEMICAL instead of by random rows\n",
    "print('number of chemicals: ', len(df1.ChemicalID.unique()))\n",
    "print('number of dis: ', len(df1.DiseaseID.unique()))\n",
    "chems = list(df1.ChemicalID.unique())\n",
    "df1 = df1.reset_index()\n",
    "training_rows = df1.index[df1.train == True].tolist()\n",
    "test_rows = df1.index[df1.test == True].tolist()\n",
    "val_rows = df1.index[df1.val == True].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10166 3671 3308\n"
     ]
    }
   ],
   "source": [
    "# Split into train, test, val\n",
    "X_train, X_test, X_val = all_X[training_rows], all_X[test_rows], all_X[val_rows]\n",
    "y_train, y_test, y_val = all_y[training_rows], all_y[test_rows], all_y[val_rows]\n",
    "\n",
    "print(len(training_rows), len(test_rows), len(val_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split into train, test, val --> OLD WAY\n",
    "# X_train, X_test, y_train, y_test = train_test_split(all_X, all_y, test_size=0.2, random_state=1606)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1606)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Establish NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Establish the model architecture\n",
    "#it's safe to say that I don't know what I'm doing here\n",
    "model = keras.Sequential([\n",
    "#     keras.layers.Dense(400, activation=tf.nn.relu), \n",
    "    keras.layers.Dense(200, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(60, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compile the model (give it loss func, optimise func and eval metric)\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), # determines how the model is adapted based on loss func\n",
    "              loss='binary_crossentropy', # measure of accuracy during training\n",
    "              metrics=['accuracy']) # measure for train and testing steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-training, set up training params\n",
    "earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10166 samples, validate on 3308 samples\n",
      "Epoch 1/120\n",
      "10166/10166 [==============================] - 1s 131us/step - loss: 0.5284 - acc: 0.7401 - val_loss: 0.5183 - val_acc: 0.7479\n",
      "Epoch 2/120\n",
      "10166/10166 [==============================] - 1s 108us/step - loss: 0.4935 - acc: 0.7596 - val_loss: 0.5947 - val_acc: 0.7288\n",
      "Epoch 3/120\n",
      "10166/10166 [==============================] - 1s 127us/step - loss: 0.4627 - acc: 0.7859 - val_loss: 0.5922 - val_acc: 0.7222\n",
      "Epoch 4/120\n",
      "10166/10166 [==============================] - 1s 135us/step - loss: 0.4465 - acc: 0.7917 - val_loss: 0.4959 - val_acc: 0.7666\n",
      "Epoch 5/120\n",
      "10166/10166 [==============================] - 1s 135us/step - loss: 0.4212 - acc: 0.8107 - val_loss: 0.4796 - val_acc: 0.7790\n",
      "Epoch 6/120\n",
      "10166/10166 [==============================] - 1s 135us/step - loss: 0.4057 - acc: 0.8169 - val_loss: 0.4964 - val_acc: 0.7781\n",
      "Epoch 7/120\n",
      "10166/10166 [==============================] - 1s 135us/step - loss: 0.3943 - acc: 0.8246 - val_loss: 0.4679 - val_acc: 0.7836\n",
      "Epoch 8/120\n",
      "10166/10166 [==============================] - 1s 135us/step - loss: 0.3724 - acc: 0.8372 - val_loss: 0.5048 - val_acc: 0.7802\n",
      "Epoch 9/120\n",
      "10166/10166 [==============================] - 1s 134us/step - loss: 0.3674 - acc: 0.8406 - val_loss: 0.4945 - val_acc: 0.7775\n",
      "Epoch 10/120\n",
      "10166/10166 [==============================] - 1s 132us/step - loss: 0.3542 - acc: 0.8469 - val_loss: 0.4448 - val_acc: 0.7996\n",
      "Epoch 11/120\n",
      "10166/10166 [==============================] - 1s 134us/step - loss: 0.3513 - acc: 0.8491 - val_loss: 0.4462 - val_acc: 0.8029\n",
      "Epoch 12/120\n",
      "10166/10166 [==============================] - 1s 133us/step - loss: 0.3363 - acc: 0.8573 - val_loss: 0.4735 - val_acc: 0.7963\n",
      "Epoch 13/120\n",
      "10166/10166 [==============================] - 1s 132us/step - loss: 0.3324 - acc: 0.8560 - val_loss: 0.4577 - val_acc: 0.7990\n",
      "Epoch 14/120\n",
      "10166/10166 [==============================] - 1s 132us/step - loss: 0.3225 - acc: 0.8630 - val_loss: 0.4399 - val_acc: 0.8105\n",
      "Epoch 15/120\n",
      "10166/10166 [==============================] - 1s 131us/step - loss: 0.3149 - acc: 0.8672 - val_loss: 0.4621 - val_acc: 0.7911\n",
      "Epoch 16/120\n",
      "10166/10166 [==============================] - 1s 134us/step - loss: 0.3102 - acc: 0.8683 - val_loss: 0.4397 - val_acc: 0.8071\n",
      "Epoch 17/120\n",
      "10166/10166 [==============================] - 1s 131us/step - loss: 0.3019 - acc: 0.8759 - val_loss: 0.5839 - val_acc: 0.7482\n",
      "Epoch 18/120\n",
      "10166/10166 [==============================] - 1s 130us/step - loss: 0.3051 - acc: 0.8722 - val_loss: 0.4380 - val_acc: 0.8126\n",
      "Epoch 19/120\n",
      "10166/10166 [==============================] - 1s 130us/step - loss: 0.3053 - acc: 0.8748 - val_loss: 0.4634 - val_acc: 0.7851\n",
      "Epoch 20/120\n",
      "10166/10166 [==============================] - 1s 132us/step - loss: 0.2859 - acc: 0.8799 - val_loss: 0.4954 - val_acc: 0.7826\n",
      "Epoch 21/120\n",
      "10166/10166 [==============================] - 1s 132us/step - loss: 0.2922 - acc: 0.8790 - val_loss: 0.4314 - val_acc: 0.8111\n",
      "Epoch 22/120\n",
      "10166/10166 [==============================] - 1s 132us/step - loss: 0.2814 - acc: 0.8847 - val_loss: 0.4190 - val_acc: 0.8195\n",
      "Epoch 23/120\n",
      "10166/10166 [==============================] - 1s 130us/step - loss: 0.2791 - acc: 0.8826 - val_loss: 0.5059 - val_acc: 0.7920\n",
      "Epoch 24/120\n",
      "10166/10166 [==============================] - 1s 132us/step - loss: 0.2699 - acc: 0.8861 - val_loss: 0.5870 - val_acc: 0.7563\n",
      "Epoch 25/120\n",
      "10166/10166 [==============================] - 1s 130us/step - loss: 0.2691 - acc: 0.8861 - val_loss: 0.4449 - val_acc: 0.8108\n",
      "Epoch 26/120\n",
      "10166/10166 [==============================] - 1s 141us/step - loss: 0.2543 - acc: 0.8962 - val_loss: 0.5097 - val_acc: 0.8017\n",
      "Epoch 27/120\n",
      "10166/10166 [==============================] - 1s 131us/step - loss: 0.2663 - acc: 0.8911 - val_loss: 0.4243 - val_acc: 0.8159\n",
      "Epoch 28/120\n",
      "10166/10166 [==============================] - 1s 140us/step - loss: 0.2581 - acc: 0.8944 - val_loss: 0.5270 - val_acc: 0.8020\n",
      "Epoch 29/120\n",
      "10166/10166 [==============================] - 2s 153us/step - loss: 0.2601 - acc: 0.8920 - val_loss: 0.4743 - val_acc: 0.8056\n",
      "Epoch 30/120\n",
      "10166/10166 [==============================] - 1s 137us/step - loss: 0.2522 - acc: 0.8964 - val_loss: 0.4841 - val_acc: 0.8077\n",
      "Epoch 31/120\n",
      "10166/10166 [==============================] - 1s 140us/step - loss: 0.2503 - acc: 0.8968 - val_loss: 0.4653 - val_acc: 0.7966\n",
      "Epoch 32/120\n",
      "10166/10166 [==============================] - 4s 351us/step - loss: 0.2421 - acc: 0.9034 - val_loss: 0.4629 - val_acc: 0.8099\n",
      "Epoch 33/120\n",
      "10166/10166 [==============================] - 2s 239us/step - loss: 0.2384 - acc: 0.9014 - val_loss: 0.4116 - val_acc: 0.8271\n",
      "Epoch 34/120\n",
      "10166/10166 [==============================] - 2s 175us/step - loss: 0.2325 - acc: 0.9049 - val_loss: 0.4535 - val_acc: 0.8153\n",
      "Epoch 35/120\n",
      "10166/10166 [==============================] - 1s 133us/step - loss: 0.2365 - acc: 0.9024 - val_loss: 0.4659 - val_acc: 0.7966\n",
      "Epoch 36/120\n",
      "10166/10166 [==============================] - 1s 131us/step - loss: 0.2200 - acc: 0.9115 - val_loss: 0.6043 - val_acc: 0.7473\n",
      "Epoch 37/120\n",
      "10166/10166 [==============================] - 1s 133us/step - loss: 0.2322 - acc: 0.9051 - val_loss: 0.4264 - val_acc: 0.8180\n",
      "Epoch 38/120\n",
      "10166/10166 [==============================] - 1s 137us/step - loss: 0.2199 - acc: 0.9093 - val_loss: 0.5474 - val_acc: 0.7899\n",
      "Epoch 39/120\n",
      "10166/10166 [==============================] - 1s 139us/step - loss: 0.2231 - acc: 0.9084 - val_loss: 0.4412 - val_acc: 0.8186\n",
      "Epoch 40/120\n",
      "10166/10166 [==============================] - 1s 131us/step - loss: 0.2174 - acc: 0.9140 - val_loss: 0.4410 - val_acc: 0.8171\n",
      "Epoch 41/120\n",
      "10166/10166 [==============================] - 1s 129us/step - loss: 0.2220 - acc: 0.9072 - val_loss: 0.4332 - val_acc: 0.8235\n",
      "Epoch 42/120\n",
      "10166/10166 [==============================] - 1s 146us/step - loss: 0.2079 - acc: 0.9151 - val_loss: 0.4350 - val_acc: 0.8274\n",
      "Epoch 43/120\n",
      "10166/10166 [==============================] - 2s 151us/step - loss: 0.2137 - acc: 0.9146 - val_loss: 0.4196 - val_acc: 0.8244\n",
      "Epoch 44/120\n",
      "10166/10166 [==============================] - 2s 162us/step - loss: 0.2085 - acc: 0.9156 - val_loss: 0.5224 - val_acc: 0.7618\n",
      "Epoch 45/120\n",
      "10166/10166 [==============================] - 1s 139us/step - loss: 0.2202 - acc: 0.9088 - val_loss: 0.4525 - val_acc: 0.8153\n",
      "Epoch 46/120\n",
      "10166/10166 [==============================] - 2s 153us/step - loss: 0.2042 - acc: 0.9162 - val_loss: 0.5232 - val_acc: 0.7950\n",
      "Epoch 47/120\n",
      "10166/10166 [==============================] - 2s 181us/step - loss: 0.2014 - acc: 0.9182 - val_loss: 0.4384 - val_acc: 0.8204\n",
      "Epoch 48/120\n",
      "10166/10166 [==============================] - 2s 196us/step - loss: 0.2015 - acc: 0.9172 - val_loss: 0.4605 - val_acc: 0.8271\n",
      "Epoch 49/120\n",
      "10166/10166 [==============================] - 2s 149us/step - loss: 0.2019 - acc: 0.9180 - val_loss: 0.4509 - val_acc: 0.8265\n",
      "Epoch 50/120\n",
      "10166/10166 [==============================] - 2s 221us/step - loss: 0.1981 - acc: 0.9219 - val_loss: 0.4392 - val_acc: 0.8174\n",
      "Epoch 51/120\n",
      "10166/10166 [==============================] - 2s 148us/step - loss: 0.1947 - acc: 0.9203 - val_loss: 0.4860 - val_acc: 0.8111\n",
      "Epoch 52/120\n",
      "10166/10166 [==============================] - 1s 137us/step - loss: 0.1843 - acc: 0.9247 - val_loss: 0.5745 - val_acc: 0.7896\n",
      "Epoch 53/120\n",
      "10166/10166 [==============================] - 1s 145us/step - loss: 0.1903 - acc: 0.9222 - val_loss: 0.4976 - val_acc: 0.8002\n",
      "Epoch 54/120\n",
      "10166/10166 [==============================] - 1s 134us/step - loss: 0.2020 - acc: 0.9182 - val_loss: 0.5708 - val_acc: 0.7999\n",
      "Epoch 55/120\n",
      "10166/10166 [==============================] - 1s 144us/step - loss: 0.1826 - acc: 0.9257 - val_loss: 0.5728 - val_acc: 0.7730\n",
      "Epoch 56/120\n",
      "10166/10166 [==============================] - 2s 194us/step - loss: 0.1858 - acc: 0.9247 - val_loss: 0.7311 - val_acc: 0.7403\n",
      "Epoch 57/120\n",
      "10166/10166 [==============================] - 3s 292us/step - loss: 0.1841 - acc: 0.9288 - val_loss: 0.4946 - val_acc: 0.8222\n",
      "Epoch 58/120\n",
      "10166/10166 [==============================] - 2s 177us/step - loss: 0.1729 - acc: 0.9312 - val_loss: 0.5259 - val_acc: 0.7869\n",
      "Epoch 59/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10166/10166 [==============================] - 2s 237us/step - loss: 0.1768 - acc: 0.9277 - val_loss: 0.5204 - val_acc: 0.8144\n",
      "Epoch 60/120\n",
      "10166/10166 [==============================] - 2s 156us/step - loss: 0.1748 - acc: 0.9285 - val_loss: 0.5661 - val_acc: 0.7830\n",
      "Epoch 61/120\n",
      "10166/10166 [==============================] - 2s 195us/step - loss: 0.1796 - acc: 0.9279 - val_loss: 0.6120 - val_acc: 0.7648\n",
      "Epoch 62/120\n",
      "10166/10166 [==============================] - 3s 313us/step - loss: 0.1725 - acc: 0.9317 - val_loss: 0.5348 - val_acc: 0.7917\n",
      "Epoch 63/120\n",
      "10166/10166 [==============================] - 3s 258us/step - loss: 0.1734 - acc: 0.9308 - val_loss: 0.5775 - val_acc: 0.8150\n",
      "Epoch 64/120\n",
      "10166/10166 [==============================] - 4s 394us/step - loss: 0.1761 - acc: 0.9282 - val_loss: 0.5152 - val_acc: 0.7969\n",
      "Epoch 65/120\n",
      "10166/10166 [==============================] - 2s 211us/step - loss: 0.1670 - acc: 0.9334 - val_loss: 0.5699 - val_acc: 0.8029\n",
      "Epoch 66/120\n",
      "10166/10166 [==============================] - 2s 157us/step - loss: 0.1758 - acc: 0.9269 - val_loss: 0.6419 - val_acc: 0.7491\n",
      "Epoch 67/120\n",
      "10166/10166 [==============================] - 2s 173us/step - loss: 0.1690 - acc: 0.9335 - val_loss: 0.5187 - val_acc: 0.8077\n",
      "Epoch 68/120\n",
      "10166/10166 [==============================] - 2s 166us/step - loss: 0.1651 - acc: 0.9356 - val_loss: 0.4792 - val_acc: 0.8216\n",
      "Epoch 69/120\n",
      "10166/10166 [==============================] - 2s 157us/step - loss: 0.1580 - acc: 0.9362 - val_loss: 0.4997 - val_acc: 0.8343\n",
      "Epoch 70/120\n",
      "10166/10166 [==============================] - 2s 189us/step - loss: 0.1638 - acc: 0.9347 - val_loss: 0.7833 - val_acc: 0.7437\n",
      "Epoch 71/120\n",
      "10166/10166 [==============================] - 2s 198us/step - loss: 0.1640 - acc: 0.9341 - val_loss: 0.5572 - val_acc: 0.8099\n",
      "Epoch 72/120\n",
      "10166/10166 [==============================] - 2s 170us/step - loss: 0.1526 - acc: 0.9384 - val_loss: 0.5645 - val_acc: 0.8059\n",
      "Epoch 73/120\n",
      "10166/10166 [==============================] - 2s 166us/step - loss: 0.1643 - acc: 0.9349 - val_loss: 0.5400 - val_acc: 0.8171\n",
      "Epoch 74/120\n",
      "10166/10166 [==============================] - 2s 154us/step - loss: 0.1688 - acc: 0.9321 - val_loss: 0.4814 - val_acc: 0.8286\n",
      "Epoch 75/120\n",
      "10166/10166 [==============================] - 2s 166us/step - loss: 0.1482 - acc: 0.9410 - val_loss: 0.5079 - val_acc: 0.7947\n",
      "Epoch 76/120\n",
      "10166/10166 [==============================] - 2s 157us/step - loss: 0.1460 - acc: 0.9435 - val_loss: 0.4935 - val_acc: 0.8183\n",
      "Epoch 77/120\n",
      "10166/10166 [==============================] - 2s 158us/step - loss: 0.1505 - acc: 0.9393 - val_loss: 0.6654 - val_acc: 0.7772\n",
      "Epoch 78/120\n",
      "10166/10166 [==============================] - 3s 290us/step - loss: 0.1480 - acc: 0.9408 - val_loss: 0.5118 - val_acc: 0.8283\n",
      "Epoch 79/120\n",
      "10166/10166 [==============================] - 2s 169us/step - loss: 0.1568 - acc: 0.9358 - val_loss: 0.7549 - val_acc: 0.7527\n",
      "Epoch 80/120\n",
      "10166/10166 [==============================] - 3s 264us/step - loss: 0.1430 - acc: 0.9451 - val_loss: 0.5081 - val_acc: 0.8120\n",
      "Epoch 81/120\n",
      "10166/10166 [==============================] - 2s 236us/step - loss: 0.1430 - acc: 0.9433 - val_loss: 0.6084 - val_acc: 0.8002\n",
      "Epoch 82/120\n",
      "10166/10166 [==============================] - 2s 150us/step - loss: 0.1394 - acc: 0.9442 - val_loss: 0.5635 - val_acc: 0.8083\n",
      "Epoch 83/120\n",
      "10166/10166 [==============================] - 2s 153us/step - loss: 0.1444 - acc: 0.9434 - val_loss: 0.4847 - val_acc: 0.8319\n",
      "Epoch 84/120\n",
      "10166/10166 [==============================] - 2s 161us/step - loss: 0.1300 - acc: 0.9493 - val_loss: 0.5464 - val_acc: 0.7984\n",
      "Epoch 85/120\n",
      "10166/10166 [==============================] - 2s 164us/step - loss: 0.1404 - acc: 0.9438 - val_loss: 0.6450 - val_acc: 0.7950\n",
      "Epoch 86/120\n",
      "10166/10166 [==============================] - 2s 166us/step - loss: 0.1418 - acc: 0.9446 - val_loss: 0.7984 - val_acc: 0.7551\n",
      "Epoch 87/120\n",
      "10166/10166 [==============================] - 2s 188us/step - loss: 0.1339 - acc: 0.9482 - val_loss: 0.5849 - val_acc: 0.8126\n",
      "Epoch 88/120\n",
      "10166/10166 [==============================] - 2s 167us/step - loss: 0.1332 - acc: 0.9474 - val_loss: 0.5907 - val_acc: 0.8186\n",
      "Epoch 89/120\n",
      "10166/10166 [==============================] - 2s 152us/step - loss: 0.1328 - acc: 0.9490 - val_loss: 0.5509 - val_acc: 0.8147\n",
      "Epoch 90/120\n",
      "10166/10166 [==============================] - 2s 161us/step - loss: 0.1319 - acc: 0.9495 - val_loss: 0.5858 - val_acc: 0.8147\n",
      "Epoch 91/120\n",
      "10166/10166 [==============================] - 2s 148us/step - loss: 0.1333 - acc: 0.9465 - val_loss: 0.5505 - val_acc: 0.8210\n",
      "Epoch 92/120\n",
      "10166/10166 [==============================] - 1s 146us/step - loss: 0.1212 - acc: 0.9518 - val_loss: 0.6766 - val_acc: 0.8020\n",
      "Epoch 93/120\n",
      "10166/10166 [==============================] - 2s 151us/step - loss: 0.1300 - acc: 0.9488 - val_loss: 0.5949 - val_acc: 0.8232\n",
      "Epoch 94/120\n",
      "10166/10166 [==============================] - 2s 160us/step - loss: 0.1261 - acc: 0.9516 - val_loss: 0.6158 - val_acc: 0.8180\n",
      "Epoch 95/120\n",
      "10166/10166 [==============================] - 2s 174us/step - loss: 0.1347 - acc: 0.9446 - val_loss: 0.6256 - val_acc: 0.8129\n",
      "Epoch 96/120\n",
      "10166/10166 [==============================] - 2s 180us/step - loss: 0.1218 - acc: 0.9540 - val_loss: 0.5789 - val_acc: 0.8283\n",
      "Epoch 97/120\n",
      "10166/10166 [==============================] - 2s 168us/step - loss: 0.1310 - acc: 0.9461 - val_loss: 0.6793 - val_acc: 0.7972\n",
      "Epoch 98/120\n",
      "10166/10166 [==============================] - 2s 157us/step - loss: 0.1252 - acc: 0.9492 - val_loss: 0.5679 - val_acc: 0.8286\n",
      "Epoch 99/120\n",
      "10166/10166 [==============================] - 2s 160us/step - loss: 0.1171 - acc: 0.9532 - val_loss: 0.5794 - val_acc: 0.8286\n",
      "Epoch 100/120\n",
      "10166/10166 [==============================] - 2s 156us/step - loss: 0.1213 - acc: 0.9526 - val_loss: 0.6385 - val_acc: 0.8014\n",
      "Epoch 101/120\n",
      "10166/10166 [==============================] - 2s 159us/step - loss: 0.1260 - acc: 0.9501 - val_loss: 0.7986 - val_acc: 0.7687\n",
      "Epoch 102/120\n",
      "10166/10166 [==============================] - 2s 173us/step - loss: 0.1178 - acc: 0.9528 - val_loss: 0.6047 - val_acc: 0.8289\n",
      "Epoch 103/120\n",
      "10166/10166 [==============================] - 2s 164us/step - loss: 0.1145 - acc: 0.9557 - val_loss: 0.6801 - val_acc: 0.8011\n",
      "Epoch 104/120\n",
      "10166/10166 [==============================] - 2s 159us/step - loss: 0.1182 - acc: 0.9521 - val_loss: 0.5825 - val_acc: 0.8307\n",
      "Epoch 105/120\n",
      "10166/10166 [==============================] - 2s 148us/step - loss: 0.1215 - acc: 0.9521 - val_loss: 0.6095 - val_acc: 0.8023\n",
      "Epoch 106/120\n",
      "10166/10166 [==============================] - 2s 169us/step - loss: 0.1161 - acc: 0.9537 - val_loss: 0.6444 - val_acc: 0.8229\n",
      "Epoch 107/120\n",
      "10166/10166 [==============================] - 2s 165us/step - loss: 0.1121 - acc: 0.9571 - val_loss: 0.6627 - val_acc: 0.8077\n",
      "Epoch 108/120\n",
      "10166/10166 [==============================] - 2s 181us/step - loss: 0.1082 - acc: 0.9550 - val_loss: 0.6012 - val_acc: 0.8319\n",
      "Epoch 109/120\n",
      "10166/10166 [==============================] - 2s 204us/step - loss: 0.1124 - acc: 0.9543 - val_loss: 0.6893 - val_acc: 0.8062\n",
      "Epoch 110/120\n",
      "10166/10166 [==============================] - 2s 176us/step - loss: 0.1092 - acc: 0.9567 - val_loss: 0.6235 - val_acc: 0.8250\n",
      "Epoch 111/120\n",
      "10166/10166 [==============================] - 2s 190us/step - loss: 0.1056 - acc: 0.9593 - val_loss: 0.7070 - val_acc: 0.8183\n",
      "Epoch 112/120\n",
      "10166/10166 [==============================] - 2s 210us/step - loss: 0.1124 - acc: 0.9530 - val_loss: 0.8136 - val_acc: 0.8062\n",
      "Epoch 113/120\n",
      "10166/10166 [==============================] - 2s 203us/step - loss: 0.1101 - acc: 0.9558 - val_loss: 0.7459 - val_acc: 0.7935\n",
      "Epoch 114/120\n",
      "10166/10166 [==============================] - 2s 170us/step - loss: 0.1058 - acc: 0.9594 - val_loss: 0.6325 - val_acc: 0.8222\n",
      "Epoch 115/120\n",
      "10166/10166 [==============================] - 2s 157us/step - loss: 0.0999 - acc: 0.9608 - val_loss: 0.6470 - val_acc: 0.8259\n",
      "Epoch 116/120\n",
      "10166/10166 [==============================] - 2s 195us/step - loss: 0.0999 - acc: 0.9607 - val_loss: 0.6443 - val_acc: 0.8247\n",
      "Epoch 117/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10166/10166 [==============================] - 2s 175us/step - loss: 0.1145 - acc: 0.9503 - val_loss: 0.6684 - val_acc: 0.8099\n",
      "Epoch 118/120\n",
      "10166/10166 [==============================] - 2s 175us/step - loss: 0.1005 - acc: 0.9616 - val_loss: 0.6430 - val_acc: 0.8186\n",
      "Epoch 119/120\n",
      "10166/10166 [==============================] - 2s 162us/step - loss: 0.1052 - acc: 0.9573 - val_loss: 0.6501 - val_acc: 0.8180\n",
      "Epoch 120/120\n",
      "10166/10166 [==============================] - 2s 151us/step - loss: 0.1111 - acc: 0.9560 - val_loss: 0.8082 - val_acc: 0.7763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe3bb82e3c8>"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Train\n",
    "model.fit(X_train, y_train, epochs=120, validation_data=(X_val, y_val) ) #, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3671/3671 [==============================] - 0s 75us/step\n",
      "Test accuracy: 0.7311359300856303\n"
     ]
    }
   ],
   "source": [
    "# 4. Evaluate\n",
    "# Accuracy\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get actual predictions for test set\n",
    "predictions = model.predict(X_test)\n",
    "rounded_predictions = [int(float(round(x[0]))) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "Predicted  False  True  __all__\n",
      "Actual                         \n",
      "False       1570   128     1698\n",
      "True         859  1114     1973\n",
      "__all__     2429  1242     3671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe3592e5e10>"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Confusion Matrix\n",
    "\n",
    "confusion_matrix = ConfusionMatrix(y_test, rounded_predictions)\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix)\n",
    "confusion_matrix.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC:  0.9013375206035305\n"
     ]
    }
   ],
   "source": [
    "# ROC AUC\n",
    "print('ROC AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-380-440e5fd394b4>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-380-440e5fd394b4>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for a in i\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Error out to stop notebook\n",
    "for a in i\n",
    "def \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Examine the predictions\n",
    "Let's look at the predictions the NN gets wrong, see if there's a pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df with the relevant data\n",
    "test_set = df1.loc[test_rows]\n",
    "test_set['Predictions'] = predictions\n",
    "test_set['RoundPredictions'] = rounded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimise memory --> set col types for the incoming CSV\n",
    "cds_cols = ['# ChemicalName', 'ChemicalID', 'DiseaseName', 'DiseaseID', 'DirectEvidence']\n",
    "cd_col_types = {   \n",
    "    '# ChemicalName': 'category',\n",
    "    'ChemicalID': 'category',\n",
    "    'DiseaseName': 'category',\n",
    "    'DiseaseID': 'category',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the disease and chemical names back! For the sake of eyeballing for patterns\n",
    "# Read in CTD csv, skipping the intro rows\n",
    "df_cd = pd.read_csv('../ctd-to-nt/csvs/CTD_chemicals_diseases.csv', usecols=cds_cols, dtype=cd_col_types, skiprows=27)\n",
    "df_cd = df_cd.drop(0)\n",
    "df_cd = df_cd.dropna(subset=['DirectEvidence']) # drop if it doesn't have direct evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set.DiseaseID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['Correlation'] = test_set.Correlation.astype(np.uint8)\n",
    "print(mem_usage(test_set['RoundPredictions']))\n",
    "test_set['RoundPredictions'] = test_set.RoundPredictions.astype(np.uint8)\n",
    "print(mem_usage(test_set['RoundPredictions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [chem_dis, df, df_d, df_c, Dvecs, Cvecs]\n",
    "del lst\n",
    "test_set = test_set.drop(['DVec', 'CVec', 'index'], axis=1) # memory intensive\n",
    "for col in ['DiseaseID', 'ChemicalID', 'DiseaseName', '# ChemicalName', 'DirectEvidence']:\n",
    "    print(col,  df_cd.columns)\n",
    "    if str(col) in df_cd.columns: print('sd') # df_cd[col] = df_cd[col].astype('category')\n",
    "    if col in test_set.columns: test_set[col] = test_set[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_usage(df_cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in the names\n",
    "\n",
    "# Because this weirdly requires a tonne of memory, let's optimise (for stupid terrible top-of-range dell laptop)\n",
    "# lst = [chem_dis, df, df_d, df_c, Dvecs, Cvecs]\n",
    "# del lst\n",
    "# test_set = test_set.drop(['DVec', 'CVec', 'index'], axis=1) # memory intensive\n",
    "# for col in ['DiseaseID', 'ChemicalID', 'DiseaseName', '# ChemicalName', 'DirectEvidence']:\n",
    "#     if col in df_cd.columns: df_cd[col] = df_cd[col].astype('category')\n",
    "#     if col in test_set.columns: test_set[col] = test_set[col].astype('category')\n",
    "\n",
    "test_set = pd.merge(test_set, df_cd[['DiseaseID', 'DiseaseName']], on='DiseaseID')\n",
    "test_set = pd.merge(test_set, df_cd[['# ChemicalName', 'ChemicalID']], on='ChemicalID')\n",
    "\n",
    "# weirdly these operations introduce millions of duplicate rows, so delete duplicates:\n",
    "test_set = test_set.drop_duplicates(list(set(test_set.columns.values))) #- set(['DVec','CVec'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd.ChemicalID = df_cd.ChemicalID.astype('category')\n",
    "type(df_cd.ChemicalID[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[['DiseaseName', '# ChemicalName', 'Correlation', 'Predictions', 'RoundPredictions']].to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import gofunction counts (for each disease and each chem). This csv was output in opa2vec.ipynb\n",
    "gofunc_counts = pd.read_csv('gofunc_counts.csv')\n",
    "test_set = pd.merge(test_set, gofunc_counts[['ChemicalID', 'gofunc']], on='ChemicalID')\n",
    "test_set = test_set.rename(columns = {'gofunc':'ChemGoFuncs'})\n",
    "test_set = pd.merge(test_set, gofunc_counts[['DiseaseID', 'gofunc']], on='DiseaseID')\n",
    "test_set = test_set.rename(columns = {'gofunc':'DisGoFuncs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This cell is pointless - manually verifying accuracy test\n",
    "# # Round predictions to int based on threshold, run accuracy-test manually\n",
    "# predictions = model.predict(X_test)\n",
    "# threshold = predictions[:].sum()/len(predictions) # Threshold is the mean value of predictions\n",
    "# predictions = [float(round(x[0]-threshold+0.5)) for x in predictions]\n",
    "# manual_accuracy = sklearn.metrics.accuracy_score(y_test, predictions, normalize=True, sample_weight=None)\n",
    "# print(manual_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate out the cosine similarity and see if there's a difference between groups\n",
    "# def cosine_sim (row):\n",
    "#     return cosine_similarity(np.array(row.DVec).reshape(1, -1), np.array(row.CVec).reshape(1, -1))[0][0]\n",
    "\n",
    "# df1['cosine_sim'] = df1.apply(lambda row: cosine_sim(row), axis=1)\n",
    "\n",
    "# # Compare cosine sim of correlated and uncorrelated groups\n",
    "# print('Cosine mean with no correlation: ', df1[df1.Correlation == 1 ].cosine_sim.mean())\n",
    "# print('Cosine mean with correlation: ', df1[df1.Correlation == 0 ].cosine_sim.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model (in two files, one for weights and one for json)\n",
    "# json_string = model.to_json()\n",
    "# model.save_weights(\"model2-0.82.h5\")\n",
    "# with open('model2-0.82.json', 'w') as outfile:\n",
    "#     json.dump(json_string, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

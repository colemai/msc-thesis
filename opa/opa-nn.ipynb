{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Use NN to predict disease from chemicals using Opa2Vec vectors\n",
    "<b> Author: </b> Ian Coleman <br>\n",
    "<b> Purpose: </b> Take the vectors created in the opa2vec notebook. This took chemical go functions\n",
    "    and disease go function, creating vectors for each. Train a NN to predict positive chem-dis relationships from these vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from pandas_ml import ConfusionMatrix\n",
    "import json\n",
    "import subprocess\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "#Set random seed\n",
    "np.random.seed(1606)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_usage(pandas_obj):\n",
    "    if isinstance(pandas_obj,pd.DataFrame):\n",
    "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "    else: # we assume if not a df it's a series\n",
    "        usage_b = pandas_obj.memory_usage(deep=True)\n",
    "    usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes\n",
    "    return \"{:03.2f} MB\".format(usage_mb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Vectors and Pre-Process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gofunc vec file\n",
    "with open('go-gofuncs.lst', 'r') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "# Strip and split vector data into list of lists [chem, vec]\n",
    "text = text.replace('\\n', '')\n",
    "text = text.split(']')\n",
    "text = [item.strip().split(' [') for item in text]\n",
    "\n",
    "# Turn it into a data frame\n",
    "df = pd.DataFrame(text)\n",
    "df.columns = ['ID', 'Vector']\n",
    "\n",
    "# Clean\n",
    "df = df.dropna()\n",
    "df['Vector'] = df.Vector.map(lambda x: x.rstrip().lstrip().replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n",
    "\n",
    "# Turn vector column into a list\n",
    "df['Vector'] = df.Vector.map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH:D012559</td>\n",
       "      <td>[1.76247600e-02, -1.05403718e-02, -4.61959302e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESH:D009404</td>\n",
       "      <td>[0.01795662, 0.13640046, 0.03051887, -0.100085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESH:D001749</td>\n",
       "      <td>[-8.68742093e-02, 8.83234814e-02, -2.54237115e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESH:D011471</td>\n",
       "      <td>[-0.00926186, 0.04098112, -0.4911138, -0.22025...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MESH:D008106</td>\n",
       "      <td>[-0.12722802, 0.07976454, -0.5775048, -0.28237...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                             Vector\n",
       "0  MESH:D012559  [1.76247600e-02, -1.05403718e-02, -4.61959302e...\n",
       "1  MESH:D009404  [0.01795662, 0.13640046, 0.03051887, -0.100085...\n",
       "2  MESH:D001749  [-8.68742093e-02, 8.83234814e-02, -2.54237115e...\n",
       "3  MESH:D011471  [-0.00926186, 0.04098112, -0.4911138, -0.22025...\n",
       "4  MESH:D008106  [-0.12722802, 0.07976454, -0.5775048, -0.28237..."
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create DF for NN\n",
    "Munge the df into the following columns:<br>\n",
    "ChemID DisID ChemVec DisVec PositiveAssociationExists(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C112297</td>\n",
       "      <td>MESH:D006948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C112297</td>\n",
       "      <td>MESH:D012640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C425777</td>\n",
       "      <td>MESH:D006948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C013567</td>\n",
       "      <td>MESH:D006333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C418863</td>\n",
       "      <td>MESH:D013262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ChemicalID     DiseaseID\n",
       "0    C112297  MESH:D006948\n",
       "1    C112297  MESH:D012640\n",
       "2    C425777  MESH:D006948\n",
       "3    C013567  MESH:D006333\n",
       "4    C418863  MESH:D013262"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Import file of proven chem-dis positive associations (created in ctd-to-nt notebook from ctd data)\n",
    "chem_dis = pd.read_csv('../ctd-to-nt/chem-dis-pos-assocs.csv')\n",
    "chem_dis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of any chems/diseases that don't have a vector\n",
    "chem_dis['DiseaseID'] = chem_dis['DiseaseID'].astype(str)\n",
    "df['ID'] = df['ID'].astype(str)\n",
    "id_list = df.ID.tolist() # list of chems+diseases with vecs\n",
    "\n",
    "chem_dis['hasDVec'] = chem_dis.DiseaseID.map(lambda x: x in id_list)\n",
    "chem_dis['hasCVec'] = chem_dis.ChemicalID.map(lambda x: x in id_list)\n",
    "chem_dis = chem_dis.loc[(chem_dis['hasDVec'] == True) & (chem_dis['hasCVec'] == True)]\n",
    "chem_dis = chem_dis.drop(['hasDVec','hasCVec'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all info into one df\n",
    "# this df now contains only correlated diseases and vecs\n",
    "df_d = df.copy()\n",
    "df_d.columns= ['DiseaseID', 'DVec']\n",
    "df_c = df.copy()\n",
    "df_c.columns= ['ChemicalID', 'CVec']\n",
    "df1 = pd.merge(chem_dis, df_d, on='DiseaseID')\n",
    "df1 = pd.merge(df1, df_c, on='ChemicalID')\n",
    "\n",
    "df1['Correlation'] = 1 # currently only have correlated in there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>DVec</th>\n",
       "      <th>CVec</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C028474</td>\n",
       "      <td>MESH:D006528</td>\n",
       "      <td>[-0.08689959, 0.06080057, -0.04620415, -0.1237...</td>\n",
       "      <td>[0.01018825, 0.08274926, 0.05085841, -0.117527...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C028474</td>\n",
       "      <td>MESH:D005355</td>\n",
       "      <td>[-4.32693306e-03, 1.35906458e-01, -1.91942360e...</td>\n",
       "      <td>[0.01018825, 0.08274926, 0.05085841, -0.117527...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C028474</td>\n",
       "      <td>MESH:D006529</td>\n",
       "      <td>[-0.02542116, 0.0981225, -0.01938446, -0.14929...</td>\n",
       "      <td>[0.01018825, 0.08274926, 0.05085841, -0.117527...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C028474</td>\n",
       "      <td>MESH:D006965</td>\n",
       "      <td>[-0.01135238, 0.143319, 0.04601676, -0.1474806...</td>\n",
       "      <td>[0.01018825, 0.08274926, 0.05085841, -0.117527...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C028474</td>\n",
       "      <td>MESH:D008114</td>\n",
       "      <td>[-0.10265561, 0.03210206, -0.13152453, -0.0728...</td>\n",
       "      <td>[0.01018825, 0.08274926, 0.05085841, -0.117527...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ChemicalID     DiseaseID                                               DVec  \\\n",
       "0    C028474  MESH:D006528  [-0.08689959, 0.06080057, -0.04620415, -0.1237...   \n",
       "1    C028474  MESH:D005355  [-4.32693306e-03, 1.35906458e-01, -1.91942360e...   \n",
       "2    C028474  MESH:D006529  [-0.02542116, 0.0981225, -0.01938446, -0.14929...   \n",
       "3    C028474  MESH:D006965  [-0.01135238, 0.143319, 0.04601676, -0.1474806...   \n",
       "4    C028474  MESH:D008114  [-0.10265561, 0.03210206, -0.13152453, -0.0728...   \n",
       "\n",
       "                                                CVec  Correlation  \n",
       "0  [0.01018825, 0.08274926, 0.05085841, -0.117527...            1  \n",
       "1  [0.01018825, 0.08274926, 0.05085841, -0.117527...            1  \n",
       "2  [0.01018825, 0.08274926, 0.05085841, -0.117527...            1  \n",
       "3  [0.01018825, 0.08274926, 0.05085841, -0.117527...            1  \n",
       "4  [0.01018825, 0.08274926, 0.05085841, -0.117527...            1  "
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3137"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8651, 2)"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chem_dis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate dfs of dis-vecs and chem-vecs ( in order to generate additional rows for df1)\n",
    "dis = df.ID.map(lambda x: ('MESH' in x) | ('OMIM' in x))\n",
    "chems = df.ID.map(lambda x: ('MESH' not in x) & ('OMIM' not in x))\n",
    "\n",
    "df_chems = df[chems]\n",
    "df_dis = df[dis]\n",
    "df_chems = df_chems.reset_index(drop=True)\n",
    "df_dis = df_dis.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  8650\n",
      "(17301, 5)\n",
      "(17145, 5)\n"
     ]
    }
   ],
   "source": [
    "# Add unrelated pairs to df1\n",
    "no_rows = (df1.shape[0]-1)   # This is a parameter to be tuned --> how many uncorrelated pairs do we want\n",
    "print('shape: ', no_rows)\n",
    "\n",
    "# Randomly select chems and diseases (as many as there are related pairs)\n",
    "no_chems = len(df_chems) -1\n",
    "no_dis = len(df_dis) -1\n",
    "rand_chems = np.random.choice(no_chems, no_rows, replace=True)\n",
    "rand_dis = np.random.choice(no_dis, no_rows, replace=True)\n",
    "\n",
    "# Add the new pairs as rows\n",
    "for x in range(0, no_rows):\n",
    "    int1 = rand_chems[x]\n",
    "    int2 = rand_dis[x]\n",
    "    chem, chemvec = df_chems.loc[int1, 'ID'], df_chems.loc[int1, 'Vector']\n",
    "    dis, disvec = df_dis.loc[int2, 'ID'], df_dis.loc[int2, 'Vector']\n",
    "    df1 = df1.append({'ChemicalID':chem, 'DiseaseID':dis, 'CVec':chemvec, 'DVec':disvec, 'Correlation':0}, ignore_index=True)\n",
    "\n",
    "print(df1.shape)\n",
    "# Drop any duplicates (removes known correlated pairs accidentally generated as uncorrelated)\n",
    "df1 = df1.drop_duplicates(subset=['ChemicalID', 'DiseaseID'], keep=False)\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the elements of the vectors to actual numbers\n",
    "df1['DVec'] = df1.DVec.map(lambda x: [float(i) for i in x])\n",
    "df1['CVec'] = df1.CVec.map(lambda x: [float(i) for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Phenotype Vecs\n",
    "Got a list of Chem-Phenotypes from Sara Alth, where did these come from originally?\n",
    "They have CID identifiers (Pubchem). Need to convert CTD ID to CID ID\n",
    "Use API like so \n",
    "http://pubchem.ncbi.nlm.nih.gov/rest/pug/substance/sourceid/Comparative%20Toxicogenomics%20Database/C533207/cids/TXT/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## First we'll add DOIDs for diseases and CIDs for chemicals as an intermediate for adding phenotypes\n",
    "# # Read in CSV mapping chems to CID and dis to DOID --> This file is created by phens-opa2vec.ipynb\n",
    "# mapper = pd.read_csv('entities.lst')\n",
    "\n",
    "# # Make the maps from this\n",
    "# dis_map = dict(zip(mapper.ID, mapper.DOID))\n",
    "# chem_map = dict(zip(mapper.ID, mapper.CID))\n",
    "\n",
    "# # Apply the maps to df1\n",
    "# df1['DOID'] = df1.DiseaseID.map(lambda x: dis_map.get(x))\n",
    "# df1['CID'] = df1.ChemicalID.map(lambda x: chem_map.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in the association files from Sara\n",
    "# dis_phens = pd.read_csv('Disease-PhenotypeAssocation.txt', sep=' ', names=['DOID', 'Phenotype'])\n",
    "# chem_phens =  pd.read_csv('Drug-PhenotypeAssocation.txt', sep=' ', names=['CID', 'Phenotype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The association files have a different format for each ID system than mine, homogenise these\n",
    "# # first chem\n",
    "# def cid_standardiser (cid):\n",
    "#     # Must be format CID + 9 int chars, starting with 1 seemingly\n",
    "#     cid = int(cid)\n",
    "#     output = 'CID1' + '0' * (8 - len(str(cid))) + str(cid)\n",
    "#     return output\n",
    "\n",
    "# df1['CID'] = df1.CID.map(lambda x: np.nan if math.isnan(x) else cid_standardiser(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # and now disease \n",
    "# def doid_standardiser (doid):\n",
    "#     # Must be format DOID_ + ...\n",
    "#     # I'm unsure about how well this is working so print out the DOIDs that don't match\n",
    "#     doid = doid.replace(':', '_')\n",
    "# #     output = 'CID1' + '0' * (8 - len(str(cid))) + str(cid)\n",
    "#     return doid\n",
    "\n",
    "# df1['DOID'] = df1.DOID.map(lambda x: np.nan if isinstance(x, float) else doid_standardiser(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now that the DOIDs and CIDs are theoretically standardised we can chuck in the phens to df1\n",
    "\n",
    "# First though check which DOIDs and CIDs do not match up --> SEEMS OK\n",
    "# test_doids = df1[df1.DOID.map(lambda x: isinstance(x, str))].DOID.tolist()\n",
    "# imported_doids = dis_phens.DOID.tolist()\n",
    "# for item in test_doids:\n",
    "#     if item not in imported_doids:\n",
    "#         print(item)                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's create one associations file for each ontology (I believe we need to run HP and MP separately)\n",
    "# chem_phens.columns = ['ID', 'Phen']\n",
    "# dis_phens.columns = ['ID', 'Phen']\n",
    "\n",
    "# # Maps for Split into MP/HP\n",
    "# hp_df_crit_d = dis_phens.Phen.map(lambda x: 'obolibrary.org/obo/HP' in str(x))\n",
    "# mp_df_crit_d = dis_phens.Phen.map(lambda x: 'obolibrary.org/obo/MP' in str(x))\n",
    "# hp_df_crit_c = chem_phens.Phen.map(lambda x: 'obolibrary.org/obo/HP' in str(x))\n",
    "# mp_df_crit_c = chem_phens.Phen.map(lambda x: 'obolibrary.org/obo/MP' in str(x))\n",
    "\n",
    "# total_hp = chem_phens[hp_df_crit_c].append(dis_phens[hp_df_crit_d], ignore_index=True)\n",
    "# total_mp = chem_phens[mp_df_crit_c].append(dis_phens[mp_df_crit_d], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export the association files and print some stats (more stats later)\n",
    "# np.savetxt(r'associations_hp.txt', total_hp.values, fmt='%s')\n",
    "# np.savetxt(r'associations_mp.txt', total_mp.values, fmt='%s')\n",
    "\n",
    "# print('Num HP associations: ', total_hp.shape[0])\n",
    "# print('Num MP associations: ', total_mp.shape[0])\n",
    "# print('Num ents with MP phen assocs: ', len(total_mp.ID.unique()))\n",
    "# print('Num ents with HP phen assocs: ', len(total_hp.ID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create entities.lst to inform opa2vec which entities we want vectors for\n",
    "# entities = total_mp.ID.unique().tolist()\n",
    "# np.savetxt(r'entities_mp.lst', entities, fmt='%s')\n",
    "\n",
    "# entities = total_hp.ID.unique().tolist()\n",
    "# np.savetxt(r'entities_hp.lst', entities, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run OPA2VEC for entity-phens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HP --> takes ages so commenting out\n",
    "# subprocess.check_output('(cd ../../opa2vec/ ; python2 runOPA2Vec.py -ontology ../ontologies/hp.owl -associations ../msc-thesis/opa/associations_hp.txt -entities ../msc-thesis/opa/entities_hp.lst -outfile ../msc-thesis/opa/hpvecs.lst)', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MP --> takes ages so commenting out\n",
    "# subprocess.check_output('(cd ../../opa2vec/ ; python2 runOPA2Vec.py -ontology ../ontologies/mp.owl -associations ../msc-thesis/opa/associations_mp.txt -entities ../msc-thesis/opa/entities_mp.lst -outfile ../msc-thesis/opa/mpvecs.lst)', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now import and integrate the vecs\n",
    "# # Import vec file\n",
    "# with open('hpvecs.lst', 'r') as file:\n",
    "#     text = file.read()\n",
    "    \n",
    "# # Strip and split vector data into list of lists [chem, vec]\n",
    "# text = text.replace('\\n', '')\n",
    "# text = text.split(']')\n",
    "# text = [item.strip().split(' [') for item in text]\n",
    "\n",
    "# # Turn it into a data frame\n",
    "# hp_vecs = pd.DataFrame(text)\n",
    "# hp_vecs.columns = ['ID', 'Vector']\n",
    "\n",
    "# # Clean\n",
    "# hp_vecs = hp_vecs.dropna()\n",
    "# hp_vecs['Vector'] = hp_vecs.Vector.map(lambda x: x.rstrip().lstrip().replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n",
    "\n",
    "# # Turn vector column into a list\n",
    "# hp_vecs['Vector'] = hp_vecs.Vector.map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now import and integrate the mp vecs\n",
    "# # Import vec file\n",
    "# with open('mpvecs.lst', 'r') as file:\n",
    "#     text = file.read()\n",
    "\n",
    "# # Strip and split vector data into list of lists [chem, vec]\n",
    "# text = text.replace('\\n', '')\n",
    "# text = text.split(']')\n",
    "# text = [item.strip().split(' [') for item in text]\n",
    "\n",
    "# # Turn it into a data frame\n",
    "# mp_vecs = pd.DataFrame(text)\n",
    "# mp_vecs.columns = ['ID', 'Vector']\n",
    "\n",
    "# # Clean\n",
    "# mp_vecs = mp_vecs.dropna()\n",
    "# mp_vecs['Vector'] = mp_vecs.Vector.map(lambda x: x.rstrip().lstrip().replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n",
    "\n",
    "# # Turn vector column into a list\n",
    "# mp_vecs['Vector'] = mp_vecs.Vector.map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right, now I have hp and mp vecs, match them up into df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make Maps:\n",
    "# mp_ent_to_vec = dict(zip(mp_vecs.ID, mp_vecs.Vector))\n",
    "# hp_ent_to_vec = dict(zip(hp_vecs.ID, hp_vecs.Vector))\n",
    "\n",
    "# # Map entities to vecs (one set of vecs for mp and another for hp)\n",
    "# df1['disPhenVecMP'] = df1.DOID.map(lambda x: mp_ent_to_vec.get(x))\n",
    "# df1['disPhenVecHP'] = df1.DOID.map(lambda x: hp_ent_to_vec.get(x))\n",
    "\n",
    "# df1['chemPhenVecHP'] = df1.CID.map(lambda x: hp_ent_to_vec.get(x))\n",
    "# df1['chemPhenVecMP'] = df1.CID.map(lambda x: mp_ent_to_vec.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TODO note that I have removed rows without gofuncVecs, maybe now they should be kept\n",
    "# # Print Stats\n",
    "# print('Note these numbers include both correlated and uncorrelated pairs')\n",
    "# print('Number of rows with gofuncs: ', df1.shape[0]) ##NB change this if keeping rows w/o gofunc vecs\n",
    "# print('Number of rows with dis mp vec: ', df1[df1.disPhenVecMP.map(lambda x: x is not None)].shape[0])\n",
    "# print('Number of rows with dis hp vec: ', df1[df1.disPhenVecHP.map(lambda x: x is not None)].shape[0])\n",
    "# print('Number of rows with chem mp vec: ', df1[df1.chemPhenVecMP.map(lambda x: x is not None)].shape[0])\n",
    "# print('Number of rows with chem hp vec: ', df1[df1.chemPhenVecHP.map(lambda x: x is not None)].shape[0])\n",
    "# no_dis_phen_vecs = df1.disPhenVecHP.map(lambda x: x is None) & df1.disPhenVecMP.map(lambda x: x is None)\n",
    "# no_chem_phen_vecs = df1.chemPhenVecHP.map(lambda x: x is None) & df1.chemPhenVecMP.map(lambda x: x is None)\n",
    "# no_phen_vecs = no_dis_phen_vecs & no_chem_phen_vecs\n",
    "# print('Number of rows with no phen vecs: ', df1[no_phen_vecs].shape[0])\n",
    "# all_dis_phen_vecs = df1.disPhenVecHP.map(lambda x: x is not None) & df1.disPhenVecMP.map(lambda x: x is not None)\n",
    "# all_chem_phen_vecs = df1.chemPhenVecHP.map(lambda x: x is not None) & df1.chemPhenVecMP.map(lambda x: x is not None)\n",
    "# all_vecs = all_dis_phen_vecs & all_chem_phen_vecs\n",
    "# all_vecs_pos_corr = all_vecs & df1.Correlation.map(lambda x: x == 1)\n",
    "# all_vecs_neg_corr = all_vecs & df1.Correlation.map(lambda x: x == 0)\n",
    "\n",
    "# print('Number of rows with everything', df1[all_vecs].shape[0])\n",
    "\n",
    "# print('Number of correlated pairs with everything', df1[all_vecs_pos_corr].shape[0])\n",
    "# print('Number of uncorrelated pairs with everything', df1[all_vecs_neg_corr].shape[0])\n",
    "\n",
    "# print('total pos corr', df1[df1.Correlation.map(lambda x: x == 1)].shape[0])\n",
    "# print('total neg corr', df1[df1.Correlation.map(lambda x: x == 0)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add empty vecs for rows that don't have phen vecs\n",
    "# empty_vec = [0] * 200\n",
    "\n",
    "# for col in ['disPhenVecMP', 'disPhenVecHP', 'chemPhenVecHP', 'chemPhenVecMP']:\n",
    "#     df1[col] = df1[col].map(lambda x: empty_vec if x is None else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change the Phen vec elements from string to floats\n",
    "# df1['disPhenVecHP'] = df1.disPhenVecHP.map(lambda x: [float(i) for i in x])\n",
    "# df1['disPhenVecMP'] = df1.disPhenVecMP.map(lambda x: [float(i) for i in x])\n",
    "# df1['chemPhenVecHP'] = df1.chemPhenVecHP.map(lambda x: [float(i) for i in x])\n",
    "# df1['chemPhenVecMP'] = df1.chemPhenVecMP.map(lambda x: [float(i) for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add CHEBI Vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First add CHEBI IDs for each chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chem_names = df1.ChemicalID.unique().tolist()\n",
    "# np.savetxt(r'chem_names', total_hp.values, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add chebi first need CID for ALL Chems so I made this comprehensive map:\n",
    "# Load the map from pickle object\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "ctd_cid_map = load_obj('ctd_cid_map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['CID'] = df1.ChemicalID.map(lambda x: ctd_cid_map.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>DVec</th>\n",
       "      <th>CVec</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>CID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>C017947</td>\n",
       "      <td>MESH:D008175</td>\n",
       "      <td>[-0.0498087, 0.08013102, -0.21025404, -0.14221...</td>\n",
       "      <td>[-0.0531880707, 0.0433869548, -0.196800679, -0...</td>\n",
       "      <td>1</td>\n",
       "      <td>b'443495'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>C582340</td>\n",
       "      <td>MESH:D013617</td>\n",
       "      <td>[0.05696682, 0.09369084, -0.0048688, -0.089769...</td>\n",
       "      <td>[0.03923435, 0.10083519, 0.0233496, -0.1123369...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8458</th>\n",
       "      <td>D014673</td>\n",
       "      <td>MESH:D007022</td>\n",
       "      <td>[-0.07060508, 0.08438816, -0.0596953, -0.07784...</td>\n",
       "      <td>[0.0453479178, 0.138363615, -0.0531766899, -0....</td>\n",
       "      <td>1</td>\n",
       "      <td>b'39764'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ChemicalID     DiseaseID  \\\n",
       "1341    C017947  MESH:D008175   \n",
       "9741    C582340  MESH:D013617   \n",
       "8458    D014673  MESH:D007022   \n",
       "\n",
       "                                                   DVec  \\\n",
       "1341  [-0.0498087, 0.08013102, -0.21025404, -0.14221...   \n",
       "9741  [0.05696682, 0.09369084, -0.0048688, -0.089769...   \n",
       "8458  [-0.07060508, 0.08438816, -0.0596953, -0.07784...   \n",
       "\n",
       "                                                   CVec  Correlation  \\\n",
       "1341  [-0.0531880707, 0.0433869548, -0.196800679, -0...            1   \n",
       "9741  [0.03923435, 0.10083519, 0.0233496, -0.1123369...            0   \n",
       "8458  [0.0453479178, 0.138363615, -0.0531766899, -0....            1   \n",
       "\n",
       "            CID  \n",
       "1341  b'443495'  \n",
       "9741       None  \n",
       "8458   b'39764'  "
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CIDS from bytes to strings and export in order to make a map from CID to CHEBI ID\n",
    "df1['CID'] = df1.CID.str.decode(\"utf-8\")\n",
    "np.savetxt(r'allCIDs.txt', df1.CID.unique(), fmt='%s')\n",
    "\n",
    "## NOTE the next step is MANUAL you need to upload this allCIDs.txt to http://cts.fiehnlab.ucdavis.edu/batch \n",
    "# and download it as ctd_chebi.csv to the current folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV mapping CID to CHEBI\n",
    "ctdChebdf = pd.read_csv('ctd_chebi.csv')\n",
    "\n",
    "# Turn it into a dict\n",
    "ctd_chebi = dict(zip(ctdChebdf['PubChem CID'], ctdChebdf['ChEBI']))\n",
    "\n",
    "# Map the cids to chebis\n",
    "df1['CHEBI'] = df1.CID.map(lambda x: ctd_chebi.get(x))\n",
    "df1['CHEBI'] = df1.CHEBI.map(lambda x: None if x == 'No result' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now make CHEBI vecs using the CHEBI IDs\n",
    "# First an association file - just linking each chebi to its own chebi entity\n",
    "\n",
    "# add uri col\n",
    "df1['CHEBI_uri'] = df1.dropna(subset=['CHEBI']).CHEBI.map(lambda x: '<http://purl.obolibrary.org/obo/' + x.replace(':', '_') + '>')\n",
    "\n",
    "# export association file from df\n",
    "np.savetxt(r'CHEBIassociations.txt', df1[['ChemicalID', 'CHEBI_uri']].dropna().drop_duplicates().values, fmt='%s')\n",
    "\n",
    "# Now an entities file\n",
    "chems_for_cheb = df1[['ChemicalID', 'CHEBI_uri']].dropna().drop_duplicates().ChemicalID.tolist()\n",
    "np.savetxt(r'CHEBIentities.txt', chems_for_cheb, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commenting this out now that I already have the vectors, you'll need it if you don't have them\n",
    "# # Now run opa2vec on it \n",
    "# subprocess.check_output('(cd ../../opa2vec/ ; python2 runOPA2Vec.py -ontology ../ontologies/chebi.owl -associations ../msc-thesis/opa/CHEBIassociations.txt -entities ../msc-thesis/opa/CHEBIentities.txt -outfile ../msc-thesis/opa/chebi-vecs.lst)', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gofunc vec file\n",
    "with open('chebi-vecs.lst', 'r') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "# Strip and split vector data into list of lists [chem, vec]\n",
    "text = text.replace('\\n', '')\n",
    "text = text.split(']')\n",
    "text = [item.strip().split(' [') for item in text]\n",
    "\n",
    "# Turn it into a data frame\n",
    "df = pd.DataFrame(text)\n",
    "df.columns = ['ID', 'Vector']\n",
    "\n",
    "# Clean\n",
    "df = df.dropna()\n",
    "df['Vector'] = df.Vector.map(lambda x: x.rstrip().lstrip().replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n",
    "\n",
    "# Turn vector column into a list\n",
    "df['Vector'] = df.Vector.map(lambda x: x.split(','))\n",
    "\n",
    "# Make a map of it (ChemID to CHEBIvec)\n",
    "chem_to_chebi_vec = dict(zip(df.ID, df.Vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a map of it (ChemID to CHEBIvec)\n",
    "chem_to_chebi_vec = dict(zip(df.ID, df.Vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['CHEBIvec'] = df1.ChemicalID.map(lambda x: chem_to_chebi_vec.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows 17145\n",
      "Total Correlated Rows 8595\n",
      "Total CHEBI vec rows 10660\n",
      "Total CHEBI vec correlated rows 5894\n",
      "Total Chems 570\n",
      "Total Chems with CHEBI Vec 316\n"
     ]
    }
   ],
   "source": [
    "# How many rows have CHEBI Vecs?\n",
    "print('Total Rows', df1.shape[0])\n",
    "print('Total Correlated Rows', df1[df1.Correlation == 1].shape[0])\n",
    "print('Total CHEBI vec rows', df1.dropna(subset=['CHEBIvec']).shape[0])\n",
    "print('Total CHEBI vec correlated rows', df1[df1.Correlation == 1].dropna(subset=['CHEBIvec']).shape[0])\n",
    "print('Total Chems', len(df1.ChemicalID.unique()))\n",
    "print('Total Chems with CHEBI Vec', len(df1.dropna(subset=['CHEBIvec']).ChemicalID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>DVec</th>\n",
       "      <th>CVec</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>CID</th>\n",
       "      <th>CHEBI</th>\n",
       "      <th>CHEBI_uri</th>\n",
       "      <th>CHEBIvec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7769</th>\n",
       "      <td>D011794</td>\n",
       "      <td>MESH:D009133</td>\n",
       "      <td>[0.03116769, 0.13587785, 0.04433348, -0.132408...</td>\n",
       "      <td>[-0.02145532, 0.06948259, -0.1081144, -0.14960...</td>\n",
       "      <td>1</td>\n",
       "      <td>5280343</td>\n",
       "      <td>CHEBI:16243</td>\n",
       "      <td>&lt;http://purl.obolibrary.org/obo/CHEBI_16243&gt;</td>\n",
       "      <td>[0.01221674, 0.05984232, 0.03748447, -0.071131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13468</th>\n",
       "      <td>C012655</td>\n",
       "      <td>MESH:D012608</td>\n",
       "      <td>[0.01731185, 0.11330543, 0.07036374, -0.148131...</td>\n",
       "      <td>[0.00528433267, 0.0889950693, 0.0519304797, -0...</td>\n",
       "      <td>0</td>\n",
       "      <td>4495</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15111</th>\n",
       "      <td>C509592</td>\n",
       "      <td>MESH:C535780</td>\n",
       "      <td>[0.01960866, 0.12501125, 0.04490718, -0.128422...</td>\n",
       "      <td>[0.00356502, 0.11017938, -0.02927761, -0.08686...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ChemicalID     DiseaseID  \\\n",
       "7769     D011794  MESH:D009133   \n",
       "13468    C012655  MESH:D012608   \n",
       "15111    C509592  MESH:C535780   \n",
       "\n",
       "                                                    DVec  \\\n",
       "7769   [0.03116769, 0.13587785, 0.04433348, -0.132408...   \n",
       "13468  [0.01731185, 0.11330543, 0.07036374, -0.148131...   \n",
       "15111  [0.01960866, 0.12501125, 0.04490718, -0.128422...   \n",
       "\n",
       "                                                    CVec  Correlation  \\\n",
       "7769   [-0.02145532, 0.06948259, -0.1081144, -0.14960...            1   \n",
       "13468  [0.00528433267, 0.0889950693, 0.0519304797, -0...            0   \n",
       "15111  [0.00356502, 0.11017938, -0.02927761, -0.08686...            0   \n",
       "\n",
       "           CID        CHEBI                                     CHEBI_uri  \\\n",
       "7769   5280343  CHEBI:16243  <http://purl.obolibrary.org/obo/CHEBI_16243>   \n",
       "13468     4495         None                                           NaN   \n",
       "15111     None         None                                           NaN   \n",
       "\n",
       "                                                CHEBIvec  \n",
       "7769   [0.01221674, 0.05984232, 0.03748447, -0.071131...  \n",
       "13468                                               None  \n",
       "15111                                               None  "
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add empty vecs for rows that don't have Chebi vecs\n",
    "empty_vec = [0] * 200\n",
    "df1['CHEBIvec'] = df1['CHEBIvec'].map(lambda x: empty_vec if x is None else x)\n",
    "\n",
    "# Change the Chebi vec elements from string to floats\n",
    "df1['CHEBIvec'] = df1.CHEBIvec.map(lambda x: [float(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess\n",
    "Now that we have the df ready, let's split it into train/test/validation sets and convert it into numpy arrays so it can be consumed by a Keras NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8595\n",
      "(17145, 9)\n"
     ]
    }
   ],
   "source": [
    "print(df1[df1.Correlation == 1].shape[0])\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>DVec</th>\n",
       "      <th>CVec</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>CID</th>\n",
       "      <th>CHEBI</th>\n",
       "      <th>CHEBI_uri</th>\n",
       "      <th>CHEBIvec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8456</th>\n",
       "      <td>D014673</td>\n",
       "      <td>MESH:D009336</td>\n",
       "      <td>[-0.0526574999, 0.0888598338, -0.0274056457, -...</td>\n",
       "      <td>[0.0453479178, 0.138363615, -0.0531766899, -0....</td>\n",
       "      <td>1</td>\n",
       "      <td>39764</td>\n",
       "      <td>CHEBI:9940</td>\n",
       "      <td>&lt;http://purl.obolibrary.org/obo/CHEBI_9940&gt;</td>\n",
       "      <td>[0.021671124, 0.054821689, 0.015866555, -0.062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9347</th>\n",
       "      <td>D014800</td>\n",
       "      <td>MESH:D006106</td>\n",
       "      <td>[-0.00255577127, 0.137570068, 0.0328803249, -0...</td>\n",
       "      <td>[-0.032665316, 0.00784736034, -0.240696847, -0...</td>\n",
       "      <td>0</td>\n",
       "      <td>73357729</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ChemicalID     DiseaseID  \\\n",
       "8456    D014673  MESH:D009336   \n",
       "9347    D014800  MESH:D006106   \n",
       "\n",
       "                                                   DVec  \\\n",
       "8456  [-0.0526574999, 0.0888598338, -0.0274056457, -...   \n",
       "9347  [-0.00255577127, 0.137570068, 0.0328803249, -0...   \n",
       "\n",
       "                                                   CVec  Correlation  \\\n",
       "8456  [0.0453479178, 0.138363615, -0.0531766899, -0....            1   \n",
       "9347  [-0.032665316, 0.00784736034, -0.240696847, -0...            0   \n",
       "\n",
       "           CID       CHEBI                                    CHEBI_uri  \\\n",
       "8456     39764  CHEBI:9940  <http://purl.obolibrary.org/obo/CHEBI_9940>   \n",
       "9347  73357729        None                                          NaN   \n",
       "\n",
       "                                               CHEBIvec  \n",
       "8456  [0.021671124, 0.054821689, 0.015866555, -0.062...  \n",
       "9347  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Version for phen and gofunc vecs\n",
    "# # For Keras, need to turn inputs into numpy arrays instead of pandas df\n",
    "# # First create single np array of all vecs... not pretty:\n",
    "# Dvecs = pd.DataFrame(df1.DVec.values.tolist(), index= df1.index)\n",
    "# Cvecs = pd.DataFrame(df1.CVec.values.tolist(), index= df1.index)\n",
    "# gofuncs = Dvecs.merge(Cvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# DMPvecs = pd.DataFrame(df1.disPhenVecHP.values.tolist(), index= df1.index)\n",
    "# DHPvecs = pd.DataFrame(df1.disPhenVecMP.values.tolist(), index= df1.index)\n",
    "# disPvecs = DMPvecs.merge(DHPvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# CMPvecs = pd.DataFrame(df1.chemPhenVecHP.values.tolist(), index= df1.index)\n",
    "# CHPvecs = pd.DataFrame(df1.chemPhenVecMP.values.tolist(), index= df1.index)\n",
    "# chemPvecs = CMPvecs.merge(CHPvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# phenVecs = disPvecs.merge(chemPvecs, how='outer', left_index=True, right_index=True)\n",
    "# all_X = phenVecs.merge(gofuncs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# all_X = np.array(all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version for just gofunc vecs\n",
    "# For Keras, need to turn inputs into numpy arrays instead of pandas df\n",
    "# First create single np array of all vecs... not pretty:\n",
    "Dvecs = pd.DataFrame(df1.DVec.values.tolist(), index= df1.index)\n",
    "Cvecs = pd.DataFrame(df1.CVec.values.tolist(), index= df1.index)\n",
    "all_X = Dvecs.merge(Cvecs, how='outer', left_index=True, right_index=True)\n",
    "all_X = np.array(all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Version for Chebi vecs with gofuncs\n",
    "# # For Keras, need to turn inputs into numpy arrays instead of pandas df\n",
    "# # First create single np array of all vecs... not pretty:\n",
    "# Dvecs = pd.DataFrame(df1.DVec.values.tolist(), index= df1.index)\n",
    "# Cvecs = pd.DataFrame(df1.CVec.values.tolist(), index= df1.index)\n",
    "# CHEBvecs = pd.DataFrame(df1.CHEBIvec.values.tolist(), index = df1.index)\n",
    "# gofuncs = Dvecs.merge(Cvecs, how='outer', left_index=True, right_index=True)\n",
    "# all_X = gofuncs.merge(CHEBvecs, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# all_X = np.array(all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Version for just CHEBI vecs\n",
    "# For Keras, need to turn inputs into numpy arrays instead of pandas df\n",
    "# First create single np array of all vecs... not pretty:\n",
    "CHEBvecs = pd.DataFrame(df1.CHEBIvec.values.tolist(), index = df1.index)\n",
    "all_X = np.array(CHEBvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create np array of the y output\n",
    "all_y = np.array(df1.Correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  (17145,)\n",
      "X shape:  (17145, 200)\n"
     ]
    }
   ],
   "source": [
    "print('y shape: ', all_y.shape)\n",
    "print('X shape: ', all_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create training, test, val set in a way that we can later look at the rows of each BY ROWS\n",
    "# total_rows = len(all_X)\n",
    "# row_numbers = list(range(0, total_rows))\n",
    "\n",
    "# training_rows = random.sample(row_numbers, int(round(total_rows * .6)))\n",
    "# row_numbers = set(row_numbers) - set(training_rows)\n",
    "\n",
    "# test_rows = random.sample(row_numbers, int(round(total_rows * .2)))\n",
    "# row_numbers = set(row_numbers) - set(test_rows)\n",
    "\n",
    "# val_rows = list(row_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chemicals:  570\n",
      "number of dis:  2501\n",
      "342 114 114\n"
     ]
    }
   ],
   "source": [
    "# Split into train, test, val BY CHEMICAL instead of by random rows\n",
    "print('number of chemicals: ', len(df1.ChemicalID.unique()))\n",
    "print('number of dis: ', len(df1.DiseaseID.unique()))\n",
    "chems = list(df1.ChemicalID.unique())\n",
    "random.shuffle(chems)\n",
    "\n",
    "total_chems = len(chems)\n",
    "train_chems = chems[:round(total_chems * .6)]\n",
    "test_chems = chems[round(total_chems * .6):round(total_chems * .8)]\n",
    "val_chems = chems[round(total_chems * .8):]\n",
    "\n",
    "print(len(train_chems), len(test_chems), len(val_chems))\n",
    "\n",
    "# Now get the row numbers for each set of chemicals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['train'] = df1.ChemicalID.isin(train_chems)\n",
    "df1['test'] = df1.ChemicalID.isin(test_chems)\n",
    "df1['val'] = df1.ChemicalID.isin(val_chems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chemicals:  570\n",
      "number of dis:  2501\n"
     ]
    }
   ],
   "source": [
    "# Split by CHEMICAL instead of by random rows\n",
    "print('number of chemicals: ', len(df1.ChemicalID.unique()))\n",
    "print('number of dis: ', len(df1.DiseaseID.unique()))\n",
    "chems = list(df1.ChemicalID.unique())\n",
    "df1 = df1.reset_index()\n",
    "training_rows = df1.index[df1.train == True].tolist()\n",
    "test_rows = df1.index[df1.test == True].tolist()\n",
    "val_rows = df1.index[df1.val == True].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10490 3430 3225\n"
     ]
    }
   ],
   "source": [
    "# Split into train, test, val\n",
    "X_train, X_test, X_val = all_X[training_rows], all_X[test_rows], all_X[val_rows]\n",
    "y_train, y_test, y_val = all_y[training_rows], all_y[test_rows], all_y[val_rows]\n",
    "\n",
    "print(len(training_rows), len(test_rows), len(val_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split into train, test, val --> OLD WAY\n",
    "# X_train, X_test, y_train, y_test = train_test_split(all_X, all_y, test_size=0.2, random_state=1606)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1606)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Establish NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Establish the model architecture\n",
    "#it's safe to say that I don't know what I'm doing here\n",
    "model = keras.Sequential([\n",
    "#     keras.layers.Dense(400, activation=tf.nn.relu), \n",
    "    keras.layers.Dense(200, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compile the model (give it loss func, optimise func and eval metric)\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), # determines how the model is adapted based on loss func\n",
    "              loss='binary_crossentropy', # measure of accuracy during training\n",
    "              metrics=['accuracy']) # measure for train and testing steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-training, set up training params\n",
    "earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10490 samples, validate on 3225 samples\n",
      "Epoch 1/10\n",
      "10490/10490 [==============================] - 2s 218us/step - loss: 0.6893 - acc: 0.5438 - val_loss: 0.6868 - val_acc: 0.5932\n",
      "Epoch 2/10\n",
      "10490/10490 [==============================] - 2s 185us/step - loss: 0.6849 - acc: 0.5534 - val_loss: 0.6866 - val_acc: 0.5064\n",
      "Epoch 3/10\n",
      "10490/10490 [==============================] - 2s 193us/step - loss: 0.6778 - acc: 0.5734 - val_loss: 0.6871 - val_acc: 0.5203\n",
      "Epoch 4/10\n",
      "10490/10490 [==============================] - 2s 191us/step - loss: 0.6653 - acc: 0.5982 - val_loss: 0.6895 - val_acc: 0.5616\n",
      "Epoch 5/10\n",
      "10490/10490 [==============================] - 2s 192us/step - loss: 0.6514 - acc: 0.6121 - val_loss: 0.6991 - val_acc: 0.5619\n",
      "Epoch 6/10\n",
      "10490/10490 [==============================] - 2s 193us/step - loss: 0.6431 - acc: 0.6155 - val_loss: 0.7242 - val_acc: 0.5287\n",
      "Epoch 7/10\n",
      "10490/10490 [==============================] - 3s 255us/step - loss: 0.6371 - acc: 0.6245 - val_loss: 0.7196 - val_acc: 0.5209\n",
      "Epoch 8/10\n",
      "10490/10490 [==============================] - 1s 143us/step - loss: 0.6304 - acc: 0.6304 - val_loss: 0.7243 - val_acc: 0.5271\n",
      "Epoch 9/10\n",
      "10490/10490 [==============================] - 2s 193us/step - loss: 0.6301 - acc: 0.6296 - val_loss: 0.7467 - val_acc: 0.5340\n",
      "Epoch 10/10\n",
      "10490/10490 [==============================] - 4s 378us/step - loss: 0.6281 - acc: 0.6322 - val_loss: 0.7335 - val_acc: 0.5367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f66950c5c50>"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Train\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val) ) #, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3430/3430 [==============================] - 1s 299us/step\n",
      "Test accuracy: 0.5355685130847786\n"
     ]
    }
   ],
   "source": [
    "# 4. Evaluate\n",
    "# Accuracy\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get actual predictions for test set\n",
    "predictions = model.predict(X_test)\n",
    "rounded_predictions = [int(float(round(x[0]))) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "Predicted  False  True  __all__\n",
      "Actual                         \n",
      "False       1334   385     1719\n",
      "True        1208   503     1711\n",
      "__all__     2542   888     3430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6641335860>"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Confusion Matrix\n",
    "\n",
    "confusion_matrix = ConfusionMatrix(y_test, rounded_predictions)\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix)\n",
    "confusion_matrix.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC:  0.49529887199447564\n"
     ]
    }
   ],
   "source": [
    "# ROC AUC\n",
    "print('ROC AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-739-440e5fd394b4>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-739-440e5fd394b4>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for a in i\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Error out to stop notebook\n",
    "for a in i\n",
    "def \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Examine the predictions\n",
    "Let's look at the predictions the NN gets wrong, see if there's a pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df with the relevant data\n",
    "test_set = df1.loc[test_rows]\n",
    "test_set['Predictions'] = predictions\n",
    "test_set['RoundPredictions'] = rounded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimise memory --> set col types for the incoming CSV\n",
    "cds_cols = ['# ChemicalName', 'ChemicalID', 'DiseaseName', 'DiseaseID', 'DirectEvidence']\n",
    "cd_col_types = {   \n",
    "    '# ChemicalName': 'category',\n",
    "    'ChemicalID': 'category',\n",
    "    'DiseaseName': 'category',\n",
    "    'DiseaseID': 'category',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the disease and chemical names back! For the sake of eyeballing for patterns\n",
    "# Read in CTD csv, skipping the intro rows\n",
    "df_cd = pd.read_csv('../ctd-to-nt/csvs/CTD_chemicals_diseases.csv', usecols=cds_cols, dtype=cd_col_types, skiprows=27)\n",
    "df_cd = df_cd.drop(0)\n",
    "df_cd = df_cd.dropna(subset=['DirectEvidence']) # drop if it doesn't have direct evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set.DiseaseID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['Correlation'] = test_set.Correlation.astype(np.uint8)\n",
    "print(mem_usage(test_set['RoundPredictions']))\n",
    "test_set['RoundPredictions'] = test_set.RoundPredictions.astype(np.uint8)\n",
    "print(mem_usage(test_set['RoundPredictions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [chem_dis, df, df_d, df_c, Dvecs, Cvecs]\n",
    "del lst\n",
    "test_set = test_set.drop(['DVec', 'CVec', 'index'], axis=1) # memory intensive\n",
    "for col in ['DiseaseID', 'ChemicalID', 'DiseaseName', '# ChemicalName', 'DirectEvidence']:\n",
    "    print(col,  df_cd.columns)\n",
    "    if str(col) in df_cd.columns: print('sd') # df_cd[col] = df_cd[col].astype('category')\n",
    "    if col in test_set.columns: test_set[col] = test_set[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_usage(df_cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in the names\n",
    "\n",
    "# Because this weirdly requires a tonne of memory, let's optimise (for stupid terrible top-of-range dell laptop)\n",
    "# lst = [chem_dis, df, df_d, df_c, Dvecs, Cvecs]\n",
    "# del lst\n",
    "# test_set = test_set.drop(['DVec', 'CVec', 'index'], axis=1) # memory intensive\n",
    "# for col in ['DiseaseID', 'ChemicalID', 'DiseaseName', '# ChemicalName', 'DirectEvidence']:\n",
    "#     if col in df_cd.columns: df_cd[col] = df_cd[col].astype('category')\n",
    "#     if col in test_set.columns: test_set[col] = test_set[col].astype('category')\n",
    "\n",
    "test_set = pd.merge(test_set, df_cd[['DiseaseID', 'DiseaseName']], on='DiseaseID')\n",
    "test_set = pd.merge(test_set, df_cd[['# ChemicalName', 'ChemicalID']], on='ChemicalID')\n",
    "\n",
    "# weirdly these operations introduce millions of duplicate rows, so delete duplicates:\n",
    "test_set = test_set.drop_duplicates(list(set(test_set.columns.values))) #- set(['DVec','CVec'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd.ChemicalID = df_cd.ChemicalID.astype('category')\n",
    "type(df_cd.ChemicalID[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[['DiseaseName', '# ChemicalName', 'Correlation', 'Predictions', 'RoundPredictions']].to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import gofunction counts (for each disease and each chem). This csv was output in opa2vec.ipynb\n",
    "gofunc_counts = pd.read_csv('gofunc_counts.csv')\n",
    "test_set = pd.merge(test_set, gofunc_counts[['ChemicalID', 'gofunc']], on='ChemicalID')\n",
    "test_set = test_set.rename(columns = {'gofunc':'ChemGoFuncs'})\n",
    "test_set = pd.merge(test_set, gofunc_counts[['DiseaseID', 'gofunc']], on='DiseaseID')\n",
    "test_set = test_set.rename(columns = {'gofunc':'DisGoFuncs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This cell is pointless - manually verifying accuracy test\n",
    "# # Round predictions to int based on threshold, run accuracy-test manually\n",
    "# predictions = model.predict(X_test)\n",
    "# threshold = predictions[:].sum()/len(predictions) # Threshold is the mean value of predictions\n",
    "# predictions = [float(round(x[0]-threshold+0.5)) for x in predictions]\n",
    "# manual_accuracy = sklearn.metrics.accuracy_score(y_test, predictions, normalize=True, sample_weight=None)\n",
    "# print(manual_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate out the cosine similarity and see if there's a difference between groups\n",
    "# def cosine_sim (row):\n",
    "#     return cosine_similarity(np.array(row.DVec).reshape(1, -1), np.array(row.CVec).reshape(1, -1))[0][0]\n",
    "\n",
    "# df1['cosine_sim'] = df1.apply(lambda row: cosine_sim(row), axis=1)\n",
    "\n",
    "# # Compare cosine sim of correlated and uncorrelated groups\n",
    "# print('Cosine mean with no correlation: ', df1[df1.Correlation == 1 ].cosine_sim.mean())\n",
    "# print('Cosine mean with correlation: ', df1[df1.Correlation == 0 ].cosine_sim.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model (in two files, one for weights and one for json)\n",
    "# json_string = model.to_json()\n",
    "# model.save_weights(\"model2-0.82.h5\")\n",
    "# with open('model2-0.82.json', 'w') as outfile:\n",
    "#     json.dump(json_string, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

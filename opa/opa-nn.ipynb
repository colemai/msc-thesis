{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Use NN to predict disease from chemicals using Opa2Vec vectors\n",
    "<b> Author: </b> Ian Coleman <br>\n",
    "<b> Purpose: </b> Take the vectors created in the opa2vec notebook. This took chemical go functions\n",
    "    and disease go function, creating vectors for each. Train a NN to predict positive chem-dis relationships from these vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "# Hyperparameter tuning:\n",
    "# 1. How many uncorrelated pairs do we want\n",
    "# 2. Epochs\n",
    "# 3. Batch size\n",
    "# 4. Number of layers, number of nodes per layer\n",
    "# 5. Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from pandas_ml import ConfusionMatrix\n",
    "import json\n",
    "import subprocess\n",
    "from correlade import correlade\n",
    "import distcorr\n",
    "\n",
    "#Set random seed\n",
    "np.random.seed(1606)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Vectors and Pre-Process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import vec file\n",
    "with open('../../opa2vec/outter.lst', 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip and split vector data into list of lists [chem, vec]\n",
    "text = text.replace('\\n', '')\n",
    "text = text.split(']')\n",
    "text = [item.strip().split(' [') for item in text]\n",
    "\n",
    "# Turn it into a data frame\n",
    "df = pd.DataFrame(text)\n",
    "df.columns = ['ID', 'Vector']\n",
    "\n",
    "# Clean\n",
    "df = df.dropna()\n",
    "df['Vector'] = df.Vector.map(lambda x: x.rstrip().lstrip().replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n",
    "\n",
    "# Turn vector column into a list\n",
    "df['Vector'] = df.Vector.map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH:D012559</td>\n",
       "      <td>[-1.21924192e-01, 2.81135049e-02, -4.26129699e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESH:D009404</td>\n",
       "      <td>[-0.0037215, 0.13912821, 0.02301073, -0.127558...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESH:D001749</td>\n",
       "      <td>[-1.74852386e-01, 1.51574258e-02, -3.31784695e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESH:D011471</td>\n",
       "      <td>[-0.22845732, 0.04537472, -0.61058366, -0.1743...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MESH:D008106</td>\n",
       "      <td>[-0.30382293, 0.0936749, -0.5634493, -0.197024...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                             Vector\n",
       "0  MESH:D012559  [-1.21924192e-01, 2.81135049e-02, -4.26129699e...\n",
       "1  MESH:D009404  [-0.0037215, 0.13912821, 0.02301073, -0.127558...\n",
       "2  MESH:D001749  [-1.74852386e-01, 1.51574258e-02, -3.31784695e...\n",
       "3  MESH:D011471  [-0.22845732, 0.04537472, -0.61058366, -0.1743...\n",
       "4  MESH:D008106  [-0.30382293, 0.0936749, -0.5634493, -0.197024..."
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2970"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ID.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create DF for NN\n",
    "Munge the df into the following columns:<br>\n",
    "ChemID DisID ChemVec DisVec PositiveAssociationExists(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>DirectEvidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C046983</td>\n",
       "      <td>MESH:D054198</td>\n",
       "      <td>therapeutic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C112297</td>\n",
       "      <td>MESH:D006948</td>\n",
       "      <td>marker/mechanism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C112297</td>\n",
       "      <td>MESH:D012640</td>\n",
       "      <td>marker/mechanism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C039775</td>\n",
       "      <td>MESH:D004827</td>\n",
       "      <td>therapeutic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C425777</td>\n",
       "      <td>MESH:D006948</td>\n",
       "      <td>marker/mechanism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ChemicalID     DiseaseID    DirectEvidence\n",
       "0    C046983  MESH:D054198       therapeutic\n",
       "1    C112297  MESH:D006948  marker/mechanism\n",
       "2    C112297  MESH:D012640  marker/mechanism\n",
       "3    C039775  MESH:D004827       therapeutic\n",
       "4    C425777  MESH:D006948  marker/mechanism"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Import file of proven chem-dis positive associations (created in ctd-to-nt notebook from ctd data)\n",
    "chem_dis = pd.read_csv('../ctd-to-nt/chem-dis-pos-assocs.csv')\n",
    "chem_dis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3191"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chem_dis.DiseaseID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96086, 3)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chem_dis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of any chems/diseases that don't have a vector\n",
    "chem_dis['DiseaseID'] = chem_dis['DiseaseID'].astype(str)\n",
    "df['ID'] = df['ID'].astype(str)\n",
    "id_list = df.ID.tolist() # list of chems+diseases with vecs\n",
    "\n",
    "# chem_dis['DiseaseID'] = chem_dis['DiseaseID'].str.replace('MESH:', '')\n",
    "# chem_dis['DiseaseID'] = chem_dis['DiseaseID'].str.replace('OMIM:', '')\n",
    "\n",
    "chem_dis['hasDVec'] = chem_dis.DiseaseID.map(lambda x: x in id_list)\n",
    "chem_dis['hasCVec'] = chem_dis.ChemicalID.map(lambda x: x in id_list)\n",
    "chem_dis = chem_dis.loc[(chem_dis['hasDVec'] == True) & (chem_dis['hasCVec'] == True)]\n",
    "chem_dis = chem_dis.drop(['hasDVec','hasCVec'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MESH:D012559', 'MESH:D009404', 'MESH:D001749', 'MESH:D011471']"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_list[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2970"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all info into one df\n",
    "# this df now contains only correlated diseases and vecs\n",
    "df_d = df.copy()\n",
    "df_d.columns= ['DiseaseID', 'DVec']\n",
    "df_c = df.copy()\n",
    "df_c.columns= ['ChemicalID', 'CVec']\n",
    "df1 = pd.merge(chem_dis, df_d, on='DiseaseID')\n",
    "df1 = pd.merge(df1, df_c, on='ChemicalID')\n",
    "\n",
    "# df1['Correlation'] = 1 # currently only have correlated in there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Correlation'] = df1.DirectEvidence.map(lambda x: 0 if x == 'therapeutic' else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marker/mechanism    6660\n",
       "therapeutic         3376\n",
       "Name: DirectEvidence, dtype: int64"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['DirectEvidence']] = df1[['DirectEvidence']].fillna(value='Uncorrelated')\n",
    "df1.DirectEvidence.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['target'] = df1.DirectEvidence.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>DirectEvidence</th>\n",
       "      <th>DVec</th>\n",
       "      <th>CVec</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C049584</td>\n",
       "      <td>MESH:D001943</td>\n",
       "      <td>marker/mechanism</td>\n",
       "      <td>[-0.14895332, -0.01025543, -0.25262636, -0.051...</td>\n",
       "      <td>[-1.17902062e-04, 1.11350939e-01, 4.51662578e-...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C049584</td>\n",
       "      <td>MESH:D018270</td>\n",
       "      <td>marker/mechanism</td>\n",
       "      <td>[0.01758267, 0.12877887, 0.04066193, -0.121200...</td>\n",
       "      <td>[-1.17902062e-04, 1.11350939e-01, 4.51662578e-...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C049584</td>\n",
       "      <td>MESH:D019457</td>\n",
       "      <td>marker/mechanism</td>\n",
       "      <td>[-1.41219131e-03, 1.25337347e-01, 6.41415045e-...</td>\n",
       "      <td>[-1.17902062e-04, 1.11350939e-01, 4.51662578e-...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C049584</td>\n",
       "      <td>MESH:D003110</td>\n",
       "      <td>marker/mechanism</td>\n",
       "      <td>[-6.04746304e-02, 1.23549119e-01, -6.85045198e...</td>\n",
       "      <td>[-1.17902062e-04, 1.11350939e-01, 4.51662578e-...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C049584</td>\n",
       "      <td>MESH:D015179</td>\n",
       "      <td>marker/mechanism</td>\n",
       "      <td>[-0.11238139, 0.02963986, -0.21585341, -0.0767...</td>\n",
       "      <td>[-1.17902062e-04, 1.11350939e-01, 4.51662578e-...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ChemicalID     DiseaseID    DirectEvidence  \\\n",
       "0    C049584  MESH:D001943  marker/mechanism   \n",
       "1    C049584  MESH:D018270  marker/mechanism   \n",
       "2    C049584  MESH:D019457  marker/mechanism   \n",
       "3    C049584  MESH:D003110  marker/mechanism   \n",
       "4    C049584  MESH:D015179  marker/mechanism   \n",
       "\n",
       "                                                DVec  \\\n",
       "0  [-0.14895332, -0.01025543, -0.25262636, -0.051...   \n",
       "1  [0.01758267, 0.12877887, 0.04066193, -0.121200...   \n",
       "2  [-1.41219131e-03, 1.25337347e-01, 6.41415045e-...   \n",
       "3  [-6.04746304e-02, 1.23549119e-01, -6.85045198e...   \n",
       "4  [-0.11238139, 0.02963986, -0.21585341, -0.0767...   \n",
       "\n",
       "                                                CVec  Correlation  target  \n",
       "0  [-1.17902062e-04, 1.11350939e-01, 4.51662578e-...            2       0  \n",
       "1  [-1.17902062e-04, 1.11350939e-01, 4.51662578e-...            2       0  \n",
       "2  [-1.17902062e-04, 1.11350939e-01, 4.51662578e-...            2       0  \n",
       "3  [-1.17902062e-04, 1.11350939e-01, 4.51662578e-...            2       0  \n",
       "4  [-1.17902062e-04, 1.11350939e-01, 4.51662578e-...            2       0  "
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate dfs of dis-vecs and chem-vecs ( in order to generate additional rows for df1)\n",
    "dis = df.ID.map(lambda x: ('MESH' in x) | ('OMIM' in x))\n",
    "chems = df.ID.map(lambda x: ('MESH' not in x) & ('OMIM' not in x))\n",
    "\n",
    "df_chems = df[chems]\n",
    "df_dis = df[dis]\n",
    "df_chems = df_chems.reset_index(drop=True)\n",
    "df_dis = df_dis.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  10035\n",
      "(20071, 7)\n",
      "(18508, 7)\n"
     ]
    }
   ],
   "source": [
    "# Add unrelated pairs to df1\n",
    "no_rows = (df1.shape[0]-1)  # This is a parameter to be tuned --> how many uncorrelated pairs do we want\n",
    "print('shape: ', no_rows)\n",
    "\n",
    "# Randomly select chems and diseases (as many as there are related pairs)\n",
    "no_chems = len(df_chems) -1\n",
    "no_dis = len(df_dis) -1\n",
    "rand_chems = np.random.choice(no_chems, no_rows, replace=True)\n",
    "# np.random.seed(1606)\n",
    "rand_dis = np.random.choice(no_dis, no_rows, replace=True)\n",
    "\n",
    "# Add the new pairs as rows\n",
    "for x in range(0, no_rows):\n",
    "    int1 = rand_chems[x]\n",
    "    int2 = rand_dis[x]\n",
    "    chem, chemvec = df_chems.loc[int1, 'ID'], df_chems.loc[int1, 'Vector']\n",
    "    dis, disvec = df_dis.loc[int2, 'ID'], df_dis.loc[int2, 'Vector']\n",
    "    df1 = df1.append({'ChemicalID':chem, 'DiseaseID':dis, 'CVec':chemvec, 'DVec':disvec, 'Correlation':1}, ignore_index=True)\n",
    "\n",
    "print(df1.shape)\n",
    "# Drop any duplicates (removes known correlated pairs accidentally generated as uncorrelated)\n",
    "df1 = df1.drop_duplicates(subset=['ChemicalID', 'DiseaseID'], keep=False)\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the elements of the vectors to actual numbers\n",
    "df1['DVec'] = df1.DVec.map(lambda x: [float(i) for i in x])\n",
    "df1['CVec'] = df1.CVec.map(lambda x: [float(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn correlation into three options\n",
    "# [1,0,0] --> neg corr\n",
    "# [0,1,0] --> no corr\n",
    "# [0,0,1] --> pos corr\n",
    "# Note we can't be certain that the unrelated pairs are actually unrelated\n",
    "\n",
    "df1['y'] = df1.Correlation.map(lambda x: [1,0,0] if x == 0 else ([0,1,0] if x == 1 else [0,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chopping out negatively correlated in order to test the new vectors as compared to original setup\n",
    "# print(df1.shape)\n",
    "# df1 = df1[df1.Correlation != 0]\n",
    "# print(df1.shape)\n",
    "# df1.Correlation = df1.Correlation.map(lambda x: x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9832\n",
       "2    5966\n",
       "0    2710\n",
       "Name: Correlation, dtype: int64"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Correlation.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess\n",
    "Now that we have the df ready, let's split it into train/test/validation sets and convert it into numpy arrays so it can be consumed by a Keras NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966\n",
      "2710\n",
      "9832\n"
     ]
    }
   ],
   "source": [
    "print(len(df1[df1.DirectEvidence =='marker/mechanism']))\n",
    "print(len(df1[df1.DirectEvidence =='therapeutic']))\n",
    "print(len(df1[df1.DirectEvidence.isna()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>DirectEvidence</th>\n",
       "      <th>DVec</th>\n",
       "      <th>CVec</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C049584</td>\n",
       "      <td>MESH:D001943</td>\n",
       "      <td>marker/mechanism</td>\n",
       "      <td>[-0.14895332, -0.01025543, -0.25262636, -0.051...</td>\n",
       "      <td>[-0.000117902062, 0.111350939, 0.0451662578, -...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C049584</td>\n",
       "      <td>MESH:D018270</td>\n",
       "      <td>marker/mechanism</td>\n",
       "      <td>[0.01758267, 0.12877887, 0.04066193, -0.121200...</td>\n",
       "      <td>[-0.000117902062, 0.111350939, 0.0451662578, -...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C049584</td>\n",
       "      <td>MESH:D019457</td>\n",
       "      <td>marker/mechanism</td>\n",
       "      <td>[-0.00141219131, 0.125337347, 0.0641415045, -0...</td>\n",
       "      <td>[-0.000117902062, 0.111350939, 0.0451662578, -...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C049584</td>\n",
       "      <td>MESH:D003110</td>\n",
       "      <td>marker/mechanism</td>\n",
       "      <td>[-0.0604746304, 0.123549119, -0.0685045198, -0...</td>\n",
       "      <td>[-0.000117902062, 0.111350939, 0.0451662578, -...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C049584</td>\n",
       "      <td>MESH:D015179</td>\n",
       "      <td>marker/mechanism</td>\n",
       "      <td>[-0.11238139, 0.02963986, -0.21585341, -0.0767...</td>\n",
       "      <td>[-0.000117902062, 0.111350939, 0.0451662578, -...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ChemicalID     DiseaseID    DirectEvidence  \\\n",
       "0    C049584  MESH:D001943  marker/mechanism   \n",
       "1    C049584  MESH:D018270  marker/mechanism   \n",
       "2    C049584  MESH:D019457  marker/mechanism   \n",
       "3    C049584  MESH:D003110  marker/mechanism   \n",
       "4    C049584  MESH:D015179  marker/mechanism   \n",
       "\n",
       "                                                DVec  \\\n",
       "0  [-0.14895332, -0.01025543, -0.25262636, -0.051...   \n",
       "1  [0.01758267, 0.12877887, 0.04066193, -0.121200...   \n",
       "2  [-0.00141219131, 0.125337347, 0.0641415045, -0...   \n",
       "3  [-0.0604746304, 0.123549119, -0.0685045198, -0...   \n",
       "4  [-0.11238139, 0.02963986, -0.21585341, -0.0767...   \n",
       "\n",
       "                                                CVec  Correlation  target  \n",
       "0  [-0.000117902062, 0.111350939, 0.0451662578, -...            2     0.0  \n",
       "1  [-0.000117902062, 0.111350939, 0.0451662578, -...            2     0.0  \n",
       "2  [-0.000117902062, 0.111350939, 0.0451662578, -...            2     0.0  \n",
       "3  [-0.000117902062, 0.111350939, 0.0451662578, -...            2     0.0  \n",
       "4  [-0.000117902062, 0.111350939, 0.0451662578, -...            2     0.0  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Keras, need to turn inputs into numpy arrays instead of pandas df\n",
    "# First create single np array of the two vectors CONCERN: should these be two separate inputs?\n",
    "Dvecs = pd.DataFrame(df1.DVec.values.tolist(), index= df1.index)\n",
    "Cvecs = pd.DataFrame(df1.CVec.values.tolist(), index= df1.index)\n",
    "all_X = Dvecs.merge(Cvecs, how='outer', left_index=True, right_index=True)\n",
    "all_X = np.array(all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChemicalID</th>\n",
       "      <th>DiseaseID</th>\n",
       "      <th>DirectEvidence</th>\n",
       "      <th>DVec</th>\n",
       "      <th>CVec</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>target</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8345</th>\n",
       "      <td>D014635</td>\n",
       "      <td>MESH:D007021</td>\n",
       "      <td>marker/mechanism</td>\n",
       "      <td>[0.01703165, 0.14660516, 0.05962492, -0.118774...</td>\n",
       "      <td>[-0.18718341, -0.05902867, -1.2147478, -0.0168...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ChemicalID     DiseaseID    DirectEvidence  \\\n",
       "8345    D014635  MESH:D007021  marker/mechanism   \n",
       "\n",
       "                                                   DVec  \\\n",
       "8345  [0.01703165, 0.14660516, 0.05962492, -0.118774...   \n",
       "\n",
       "                                                   CVec  Correlation  target  \\\n",
       "8345  [-0.18718341, -0.05902867, -1.2147478, -0.0168...            2     0.0   \n",
       "\n",
       "              y  \n",
       "8345  [0, 0, 1]  "
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.y = df1.y.map(lambda x: np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create np array of the y output\n",
    "# all_y = np.array(df1.y)\n",
    "all_y = np.array(df1.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  (18508,)\n",
      "X shape:  (18508, 400)\n"
     ]
    }
   ],
   "source": [
    "print('y shape: ', all_y.shape)\n",
    "print('X shape: ', all_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "yby = df1.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I'm going to split y into three columns, model isn't accepting the current col of lists\n",
    "df1[['neg_corr', 'no_corr', 'pos_corr']] = pd.DataFrame(df1.y.values.tolist(), index= df1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create training, test, val set in a way that we can later look at the rows of each BY ROWS\n",
    "# total_rows = len(all_X)\n",
    "# row_numbers = list(range(0, total_rows))\n",
    "\n",
    "# training_rows = random.sample(row_numbers, int(round(total_rows * .6)))\n",
    "# row_numbers = set(row_numbers) - set(training_rows)\n",
    "\n",
    "# test_rows = random.sample(row_numbers, int(round(total_rows * .2)))\n",
    "# row_numbers = set(row_numbers) - set(test_rows)\n",
    "\n",
    "# val_rows = list(row_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chemicals:  412\n",
      "number of dis:  2514\n",
      "247 83 82\n"
     ]
    }
   ],
   "source": [
    "# Split into train, test, val BY CHEMICAL instead of by random rows\n",
    "print('number of chemicals: ', len(df1.ChemicalID.unique()))\n",
    "print('number of dis: ', len(df1.DiseaseID.unique()))\n",
    "chems = list(df1.ChemicalID.unique())\n",
    "random.shuffle(chems)\n",
    "\n",
    "total_chems = len(chems)\n",
    "train_chems = chems[:round(total_chems * .6)]\n",
    "test_chems = chems[round(total_chems * .6):round(total_chems * .8)]\n",
    "val_chems = chems[round(total_chems * .8):]\n",
    "\n",
    "print(len(train_chems), len(test_chems), len(val_chems))\n",
    "\n",
    "# Now get the row numbers for each set of chemicals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['train'] = df1.ChemicalID.isin(train_chems)\n",
    "df1['test'] = df1.ChemicalID.isin(test_chems)\n",
    "df1['val'] = df1.ChemicalID.isin(val_chems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.reset_index()\n",
    "training_rows = df1.index[df1.train == True].tolist()\n",
    "test_rows = df1.index[df1.test == True].tolist()\n",
    "val_rows = df1.index[df1.val == True].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11214 3675 3619\n"
     ]
    }
   ],
   "source": [
    "# Split into train, test, val\n",
    "X_train, X_test, X_val = all_X[training_rows], all_X[test_rows], all_X[val_rows]\n",
    "y_train, y_test, y_val = all_y[training_rows], all_y[test_rows], all_y[val_rows]\n",
    "\n",
    "print(len(training_rows), len(test_rows), len(val_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split into train, test, val --> OLD WAY\n",
    "# X_train, X_test, y_train, y_test = train_test_split(all_X, all_y, test_size=0.2, random_state=1606)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1606)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([0, 0, 1])], dtype=object)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11214, 400)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11214, 400)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Establish NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Establish the model architecture\n",
    "#it's safe to say that I don't know what I'm doing here\n",
    "model = keras.Sequential([\n",
    "#     keras.layers.Dense(400, activation=tf.nn.relu), \n",
    "    keras.layers.Dense(200,  input_dim=400, activation=tf.nn.relu),\n",
    "    keras.layers.Flatten(), \n",
    "#     tf.layers.flatten(inputs),\n",
    "#     keras.layers.Dropout(rate=0.2, noise_shape=None, seed=None),\n",
    "    keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "#     keras.layers.Dropout(rate=0.2, noise_shape=None, seed=None),\n",
    "    keras.layers.Flatten(), \n",
    "    keras.layers.Dense(3, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## This is the old model, purely for comparing new vectors to old\n",
    "\n",
    "# # 1. Establish the model architecture\n",
    "# #it's safe to say that I don't know what I'm doing here\n",
    "# model = keras.Sequential([\n",
    "# #     keras.layers.Dense(400, activation=tf.nn.relu), \n",
    "#     keras.layers.Dense(200, activation=tf.nn.relu),\n",
    "#     keras.layers.Dropout(rate=0.2, noise_shape=None, seed=None),\n",
    "#     keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "#     keras.layers.Dropout(rate=0.2, noise_shape=None, seed=None),\n",
    "#     keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "# ])\n",
    "\n",
    "# # 2. Compile the model (give it loss func, optimise func and eval metric)\n",
    "# model.compile(optimizer=tf.train.AdamOptimizer(), # determines how the model is adapted based on loss func\n",
    "#               loss='binary_crossentropy', # measure of accuracy during training\n",
    "#               metrics=['accuracy']) # measure for train and testing steps\n",
    "\n",
    "# # 3. Train\n",
    "# model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val) ) #, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = 400\n",
    "timesteps = 1\n",
    "num_classes = 3\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(30, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 30\n",
    "model.add(keras.layers.LSTM(30, return_sequences=True))  # returns a sequence of vectors of dimension 30\n",
    "model.add(keras.layers.LSTM(30))  # return a single vector of dimension 30\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "model.fit(X_train, y_train, batch_size = 400, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compile the model (give it loss func, optimise func and eval metric)\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), # determines how the model is adapted based on loss func\n",
    "              loss='categorical_crossentropy', # measure of accuracy during training\n",
    "              metrics=['accuracy']) # measure for train and testing steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-training, set up training params\n",
    "# earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are passing a target array of shape (11214, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-358-e83594fd54e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 3. Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m#, callbacks=[earlystop])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1507\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1509\u001b[0;31m         validation_split=validation_split)\n\u001b[0m\u001b[1;32m   1510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    991\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\n\u001b[0;32m--> 993\u001b[0;31m                                                      class_weight, batch_size)\n\u001b[0m\u001b[1;32m    994\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   1166\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 1168\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   1169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    454\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         raise ValueError('You are passing a target array of shape ' + str(\n\u001b[0;32m--> 456\u001b[0;31m             y.shape) + ' while using as loss `categorical_crossentropy`. '\n\u001b[0m\u001b[1;32m    457\u001b[0m                          \u001b[0;34m'`categorical_crossentropy` expects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                          \u001b[0;34m'targets to be binary matrices (1s and 0s) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are passing a target array of shape (11214, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
     ]
    }
   ],
   "source": [
    "# 3. Train\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val) ) #, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3184/3184 [==============================] - 0s 67us/step\n",
      "Test accuracy: 0.7666457286432161\n"
     ]
    }
   ],
   "source": [
    "# 4. Evaluate\n",
    "# Accuracy\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get actual predictions for test set\n",
    "predictions = model.predict(X_test)\n",
    "rounded_predictions = [int(float(round(x[0]))) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "Predicted  False  True  __all__\n",
      "Actual                         \n",
      "False       1711   241     1952\n",
      "True         502   730     1232\n",
      "__all__     2213   971     3184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f14da8f9a90>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Confusion Matrix\n",
    "\n",
    "confusion_matrix = ConfusionMatrix(y_test, rounded_predictions)\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix)\n",
    "confusion_matrix.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC:  0.8096952675910155\n"
     ]
    }
   ],
   "source": [
    "# ROC AUC\n",
    "print('ROC AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Examine the predictions\n",
    "Let's look at the predictions the NN gets wrong, see if there's a pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df with the relevant data\n",
    "test_set = df1.loc[test_rows]\n",
    "test_set['Predictions'] = predictions\n",
    "test_set['RoundPredictions'] = rounded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimise memory --> set col types for the incoming CSV\n",
    "cds_cols = ['# ChemicalName', 'ChemicalID', 'DiseaseName', 'DiseaseID', 'DirectEvidence']\n",
    "cd_col_types = {   \n",
    "    '# ChemicalName': 'category',\n",
    "    'ChemicalID': 'category',\n",
    "    'DiseaseName': 'category',\n",
    "    'DiseaseID': 'category',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the disease and chemical names back! For the sake of eyeballing for patterns\n",
    "# Read in CTD csv, skipping the intro rows\n",
    "df_cd = pd.read_csv('../ctd-to-nt/csvs/CTD_chemicals_diseases.csv', usecols=cds_cols, dtype=cd_col_types, skiprows=27)\n",
    "df_cd = df_cd.drop(0)\n",
    "df_cd = df_cd.dropna(subset=['DirectEvidence']) # drop if it doesn't have direct evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ready for some memory-optimisation\n",
    "def mem_usage(pandas_obj):\n",
    "    if isinstance(pandas_obj,pd.DataFrame):\n",
    "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "    else: # we assume if not a df it's a series\n",
    "        usage_b = pandas_obj.memory_usage(deep=True)\n",
    "    usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes\n",
    "    return \"{:03.2f} MB\".format(usage_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['Correlation'] = test_set.Correlation.astype(np.uint8)\n",
    "print(mem_usage(test_set['RoundPredictions']))\n",
    "test_set['RoundPredictions'] = test_set.RoundPredictions.astype(np.uint8)\n",
    "print(mem_usage(test_set['RoundPredictions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in the names\n",
    "\n",
    "# Because this weirdly requires a tonne of memory, let's optimise (for stupid terrible top-of-range dell laptop)\n",
    "lst = [chem_dis, df, df_d, df_c, Dvecs, Cvecs]\n",
    "del lst\n",
    "test_set = test_set.drop(['DVec', 'CVec', 'index'], axis=1) # these cols are memory intensive\n",
    "df_cd.ChemicalID = df_cd.ChemicalID.astype('category')\n",
    "for col in ['DiseaseID', 'ChemicalID', 'DiseaseName', '# ChemicalName', 'DirectEvidence']:\n",
    "    if str(col) in df_cd.columns: df_cd[col] = df_cd[col].astype('category')\n",
    "    if col in test_set.columns: test_set[col] = test_set[col].astype('category')\n",
    "        \n",
    "test_set = pd.merge(test_set, df_cd[['DiseaseID', 'DiseaseName']], on='DiseaseID')\n",
    "test_set = pd.merge(test_set, df_cd[['# ChemicalName', 'ChemicalID']], on='ChemicalID')\n",
    "\n",
    "# weirdly these operations introduce millions of duplicate rows, so delete duplicates:\n",
    "test_set = test_set.drop_duplicates(list(set(test_set.columns.values))) #- set(['DVec','CVec'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import gofunction counts (for each disease and each chem). This csv was output in opa2vec.ipynb\n",
    "gofunc_counts = pd.read_csv('gofunc_counts.csv')\n",
    "test_set = pd.merge(test_set, gofunc_counts[['ChemicalID', 'gofunc']], on='ChemicalID')\n",
    "test_set = test_set.rename(columns = {'gofunc':'ChemGoFuncs'})\n",
    "test_set = pd.merge(test_set, gofunc_counts[['DiseaseID', 'gofunc']], on='DiseaseID')\n",
    "test_set = test_set.rename(columns = {'gofunc':'DisGoFuncs'})\n",
    "\n",
    "# Create combined gofunc count col\n",
    "test_set['sumGoFuncs'] = test_set.ChemGoFuncs + test_set.DisGoFuncs\n",
    "test_set['prodGoFuncs'] = test_set.ChemGoFuncs * test_set.DisGoFuncs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create false pos and false neg col\n",
    "test_set['false_pos'] = abs(test_set.RoundPredictions - test_set.Correlation).map(lambda x: 0 if x > 200 else x)\n",
    "test_set['true_pos'] = (test_set.RoundPredictions + test_set.Correlation).map(lambda x: 1 if x==2 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.sample(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v=np.linspace(-1,1,10001)\n",
    "# print (np.corrcoef(v,np.abs(v))[0,1], distcorr.distcorr(v,np.abs(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data for distance correlation\n",
    "data = [[4,10],[4,12],[6,13]]\n",
    "zdf = pd.DataFrame(data,columns=['Name','Age'],dtype=np.int64)\n",
    "type(zdf.Name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlade.dcorr(zdf)\n",
    "zdf.head().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distance Correlation\n",
    "correlade.dcorr(test_set.sample(1300)[['Correlation', 'Predictions', 'RoundPredictions', 'ChemGoFuncs', 'DisGoFuncs', 'sumGoFuncs', 'prodGoFuncs', 'false_pos']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pearson Correlation\n",
    "test_set[['Correlation', 'Predictions', 'RoundPredictions', 'ChemGoFuncs', 'DisGoFuncs', 'sumGoFuncs', 'prodGoFuncs', 'false_pos']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pearson Correlation\n",
    "test_set[['Correlation', 'Predictions', 'RoundPredictions', 'ChemGoFuncs', 'DisGoFuncs', 'sumGoFuncs', 'prodGoFuncs', 'false_pos']].corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[['DiseaseName', '# ChemicalName', 'Correlation', 'Predictions', 'RoundPredictions', 'ChemGoFuncs', 'DisGoFuncs', 'false_pos']].to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This cell is pointless - manually verifying accuracy test\n",
    "# # Round predictions to int based on threshold, run accuracy-test manually\n",
    "# predictions = model.predict(X_test)\n",
    "# threshold = predictions[:].sum()/len(predictions) # Threshold is the mean value of predictions\n",
    "# predictions = [float(round(x[0]-threshold+0.5)) for x in predictions]\n",
    "# manual_accuracy = sklearn.metrics.accuracy_score(y_test, predictions, normalize=True, sample_weight=None)\n",
    "# print(manual_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Calculate Cosine Similary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate out the cosine similarity and see if there's a difference between groups\n",
    "def cosine_sim (row):\n",
    "    return cosine_similarity(np.array(row.DVec).reshape(1, -1), np.array(row.CVec).reshape(1, -1))[0][0]\n",
    "\n",
    "df1['cosine_sim'] = df1.apply(lambda row: cosine_sim(row), axis=1)\n",
    "\n",
    "# Compare cosine sim of correlated and uncorrelated groups\n",
    "print('Cosine mean with no correlation: ', df1[df1.Correlation == 1 ].cosine_sim.mean())\n",
    "print('Cosine mean with correlation: ', df1[df1.Correlation == 0 ].cosine_sim.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model (in two files, one for weights and one for json)\n",
    "# json_string = model.to_json()\n",
    "# model.save_weights(\"model2-0.82.h5\")\n",
    "# with open('model2-0.82.json', 'w') as outfile:\n",
    "#     json.dump(json_string, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
